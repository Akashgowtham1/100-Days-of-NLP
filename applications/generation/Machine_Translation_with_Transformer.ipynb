{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation with Transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRRr60kDfgBAJKjeCyra5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fgeneration/applications/generation/Machine_Translation_with_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCAkehv1btSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import random\n",
        "import math\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IsArf_BcbJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wcmxMkodmcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "61bc3c5d-2187-46b1-e814-b2a1c1ba3989"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=f0a5f92449a1712be2d27ddc48ed6b2926bfc375e69a9c78e01d21efef22b273\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2t_r2x2a/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMt1wbI3drfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_en = spacy.load('en')\n",
        "spacy_de = spacy.load('de')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNJ4w3ksdxbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L58WhvBid8G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC = Field(\n",
        "    tokenize=tokenize_de,\n",
        "    lower=True,\n",
        "    init_token='<sos>',\n",
        "    eos_token='<eos>',\n",
        "    batch_first=True\n",
        ")\n",
        "\n",
        "TRG = Field(\n",
        "    tokenize=tokenize_en,\n",
        "    lower=True,\n",
        "    init_token='<sos>',\n",
        "    eos_token='<eos>',\n",
        "    batch_first=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RGUVl9ReSuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "faa4e88b-fbee-43fe-bae0-1aa4e6221a77"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rtraining.tar.gz:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 4.88MB/s]\n",
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.39MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n",
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.28MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVw34hUxedGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOV3xcgeyCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "689b05e8-ca9b-4dea-8097-71acf795d3e5"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueV7iQCue4K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNpR4NNtejTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeJnl6cue6rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0, \"n_heads must be a factor of d_model\"\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "\n",
        "        self.q = nn.Linear(d_model, d_model)\n",
        "        self.k = nn.Linear(d_model, d_model)\n",
        "        self.v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # query => [batch_size, seq_len, d_model] \n",
        "        # key => [batch_size, seq_len, d_model]\n",
        "        # value => [batch_size, seq_len, d_model]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.q(query)\n",
        "        K = self.k(key)\n",
        "        V = self.v(value)\n",
        "        # Q, K, V => [batch_size, seq_len, d_model]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        # Q, K, V => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0 ,1, 3, 2))\n",
        "        energy = energy / self.scale\n",
        "        # energy => [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        # attention => [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        weighted = torch.matmul(attention, V)\n",
        "        # weighted => [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        weighted = weighted.permute(0, 2, 1, 3).contiguous()\n",
        "        # weighted => [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = weighted.view(batch_size, -1, self.d_model)\n",
        "        # x => [batch_size, query_len, d_model]\n",
        "\n",
        "        x = self.fc(x)\n",
        "        # x => [batch_size, query_len, d_model]\n",
        "        # attention => [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        return x, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vz1NP3akIUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, pff_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(d_model, pff_dim)\n",
        "        self.fc2 = nn.Linear(pff_dim, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        # input => [batch_size, seq_len, d_model]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc1(input)))\n",
        "        # x => [batch_size, seq_len, pff_dim]\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfRvJLgkMis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, pff_dim, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = SelfAttention(d_model, n_heads, dropout, device)\n",
        "        self.pff = PositionWiseFeedForward(d_model, pff_dim, dropout)\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.pff_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # src => [batch_size, src_len, d_model]\n",
        "\n",
        "        # self attention on src\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        # _src => [batch_size, src_len, d_model]\n",
        "\n",
        "        # residual connection and layer normalization\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        # src => [batch_size, src_len, d_model]\n",
        "\n",
        "        # position wise feed forward\n",
        "        _src = self.pff(src)\n",
        "        # _src => [batch_size, src_len, d_model]\n",
        "\n",
        "        # residual connection and layer normalization\n",
        "        src = self.pff_layer_norm(src + self.dropout(_src))\n",
        "        # src => [batch_size, src_len, d_model]\n",
        "\n",
        "        return src"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApyJtPvdkQCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layers, n_heads, pff_dim, dropout, device, max_len=500):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, pff_dim, dropout, device) for _ in range(n_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([d_model])).to(device)\n",
        "    \n",
        "    def forward(self, src, src_mask):\n",
        "        # src => [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        # pos => [batch_size, src_len]\n",
        "\n",
        "        word_embed = self.word_embedding(src)\n",
        "        word_embed = word_embed * self.scale\n",
        "        # word_embed => [batch_size, src_len, d_model]\n",
        "\n",
        "        pos_embed = self.pos_embedding(pos)\n",
        "        # pos_embed => [batch_size, src_len, d_model]\n",
        "\n",
        "        src = self.dropout(word_embed + pos_embed)\n",
        "        # src => [batch_size, src_len, d_model]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        \n",
        "        # src => [batch_size, src_len, d_model]\n",
        "        return src\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJc6NfMDkWpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, pff_dim, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = SelfAttention(d_model, n_heads, dropout, device)\n",
        "        self.enc_attention = SelfAttention(d_model, n_heads, dropout, device)\n",
        "        self.pff = PositionWiseFeedForward(d_model, pff_dim, dropout)\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.pff_layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        # self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        # _trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        # residual connection and layer normalization\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        # trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        # enc_attention\n",
        "        _trg, attention = self.enc_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # _trg => [batch_size, trg_len, d_model]\n",
        "        # attention => [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        # residual connection and layer normalization\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        # trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        # positionwise feed forward\n",
        "        _trg = self.pff(trg)\n",
        "        # _trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        # residual connection and layer normalization\n",
        "        trg = self.pff_layer_norm(trg + self.dropout(_trg))\n",
        "        # trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        return trg, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3w0Ui47ka8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_layers, n_heads, pff_dim, dropout, device, max_len=500):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, pff_dim, dropout, device) for _ in range(n_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([d_model])).to(device)\n",
        "    \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        # pos => [batch_size, trg_len]\n",
        "\n",
        "        word_embedding = self.word_embedding(trg)\n",
        "        word_embedding = word_embedding * self.scale\n",
        "        # word_embedding => [batch_size, trg_len, d_model]\n",
        "\n",
        "        pos_embedding = self.pos_embedding(pos)\n",
        "        # pos_embedding => [batch_size, trg_len, d_model]\n",
        "\n",
        "        trg = self.dropout(word_embedding + pos_embedding)\n",
        "        # trg => [batch_size, trg_len, d_model]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        logits = self.fc_out(trg)\n",
        "        # logits => [batch_size, trg_len, output_dim]\n",
        "        # attention => [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return logits, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2di5Xr1keFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "    \n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2).to(self.device)\n",
        "        # src_mask => [batch_size, 1, 1, src_len]\n",
        "        \n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2).to(self.device)\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        # trg_mask => [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        " \n",
        "    def forward(self, src, trg):\n",
        "        # src => [batch_size, src_len]\n",
        "        # trg => [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClzGYGQVoV6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lbnRuYrodmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1RdG5lhogrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ce74120-8db2-48d8-eba7-b9289ba06f76"
      },
      "source": [
        "def init_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (word_embedding): Embedding(7855, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (word_embedding): Embedding(5893, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (enc_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (enc_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (enc_attention): SelfAttention(\n",
              "          (q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionWiseFeedForward(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (fc_out): Linear(in_features=256, out_features=5893, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPZoHaR8oeH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc89f922-e3e2-46f6-d1b3-e2e896eb86f7"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,243,653 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEVpPmmbopYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPuPSJwOotC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, criterion, optimizer, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(src, trg[:, :-1])\n",
        "        # output => [batch_size, trg_len - 1, output_dim]\n",
        "        # trg => [batch_size, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y8YEYgN_H1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:, :-1])\n",
        "            # output => [batch_size, trg_len - 1, output_dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZzKy8VuAAD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKYvMZdxAXdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "c090d7f7-da4f-41cf-838d-aed7952cf469"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, criterion, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss): 7.3f}\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:.3f} | Valid PPL: {math.exp(valid_loss): 7.3f}\")"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 22.70703125s\n",
            "\tTrain Loss: 0.907 | Train PPL:   2.478\n",
            "\tValid Loss: 1.667 | Valid PPL:   5.298\n",
            "Epoch: 02 | Time: 0m 23.237685203552246s\n",
            "\tTrain Loss: 0.811 | Train PPL:   2.250\n",
            "\tValid Loss: 1.702 | Valid PPL:   5.486\n",
            "Epoch: 03 | Time: 0m 23.206892251968384s\n",
            "\tTrain Loss: 0.729 | Train PPL:   2.073\n",
            "\tValid Loss: 1.746 | Valid PPL:   5.734\n",
            "Epoch: 04 | Time: 0m 23.30341362953186s\n",
            "\tTrain Loss: 0.661 | Train PPL:   1.937\n",
            "\tValid Loss: 1.794 | Valid PPL:   6.015\n",
            "Epoch: 05 | Time: 0m 22.887688398361206s\n",
            "\tTrain Loss: 0.603 | Train PPL:   1.827\n",
            "\tValid Loss: 1.829 | Valid PPL:   6.230\n",
            "Epoch: 06 | Time: 0m 22.6704204082489s\n",
            "\tTrain Loss: 0.551 | Train PPL:   1.734\n",
            "\tValid Loss: 1.883 | Valid PPL:   6.573\n",
            "Epoch: 07 | Time: 0m 22.758988857269287s\n",
            "\tTrain Loss: 0.508 | Train PPL:   1.662\n",
            "\tValid Loss: 1.947 | Valid PPL:   7.010\n",
            "Epoch: 08 | Time: 0m 22.731203317642212s\n",
            "\tTrain Loss: 0.470 | Train PPL:   1.601\n",
            "\tValid Loss: 1.992 | Valid PPL:   7.328\n",
            "Epoch: 09 | Time: 0m 22.872897624969482s\n",
            "\tTrain Loss: 0.434 | Train PPL:   1.544\n",
            "\tValid Loss: 2.039 | Valid PPL:   7.683\n",
            "Epoch: 10 | Time: 0m 22.85939311981201s\n",
            "\tTrain Loss: 0.406 | Train PPL:   1.500\n",
            "\tValid Loss: 2.082 | Valid PPL:   8.024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcsYi5QB_PE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ad22536-3d84-4908-c648-ff8cd0ac9f9e"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "print(f\"\\tTest Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss): 7.3f}\")"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 1.736 | Test PPL:   5.677\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}