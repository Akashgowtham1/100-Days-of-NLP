{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utterance Generation with Beam Search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXRcZh7qBSHd5egOxfVRRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fgeneration/applications/generation/utterance_generation/Utterance_Generation_with_Beam_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKFmIK83nXh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "4206602c-17d1-4585-ba69-cd8a1dc0dce5"
      },
      "source": [
        "TASK_DATA_DIR = 'glue_data/QQP'\n",
        "!test -d glue_data || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git glue_data\n",
        "!test -d $TASK_DATA_DIR || python glue_data/download_glue_data.py --data_dir glue_data --tasks=QQP\n",
        "!ls -alh $TASK_DATA_DIR"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'glue_data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\n",
            "Unpacking objects:   4% (1/21)   \rUnpacking objects:   9% (2/21)   \rUnpacking objects:  14% (3/21)   \rUnpacking objects:  19% (4/21)   \rUnpacking objects:  23% (5/21)   \rUnpacking objects:  28% (6/21)   \rUnpacking objects:  33% (7/21)   \rUnpacking objects:  38% (8/21)   \rUnpacking objects:  42% (9/21)   \rUnpacking objects:  47% (10/21)   \rUnpacking objects:  52% (11/21)   \rUnpacking objects:  57% (12/21)   \rUnpacking objects:  61% (13/21)   \rUnpacking objects:  66% (14/21)   \rUnpacking objects:  71% (15/21)   \rUnpacking objects:  76% (16/21)   \rUnpacking objects:  80% (17/21)   \rUnpacking objects:  85% (18/21)   \rUnpacking objects:  90% (19/21)   \rUnpacking objects:  95% (20/21)   \rUnpacking objects: 100% (21/21)   \rUnpacking objects: 100% (21/21), done.\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "total 104M\n",
            "drwxr-xr-x 3 root root 4.0K Jun 22 15:07 .\n",
            "drwxr-xr-x 4 root root 4.0K Jun 22 15:07 ..\n",
            "-rw-r--r-- 1 root root 5.6M Jun 22 15:07 dev.tsv\n",
            "drwxr-xr-x 2 root root 4.0K Jun 22 15:07 original\n",
            "-rw-r--r-- 1 root root  49M Jun 22 15:07 test.tsv\n",
            "-rw-r--r-- 1 root root  50M Jun 22 15:07 train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXjPwHhsVhf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import data, vocab\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwwZQkS6VjWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o3landwVlH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05b76dbe-a44b-41ae-f97c-2cacbded7875"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEDbqCsfVmpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "eec7cc6b-4660-48ee-fcd8-0907b809136f"
      },
      "source": [
        "train_df = pd.read_csv(TASK_DATA_DIR + '/train.tsv', sep='\\t', error_bad_lines=False)\n",
        "valid_df = pd.read_csv(TASK_DATA_DIR + '/dev.tsv', sep='\\t', error_bad_lines=False)\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133273</td>\n",
              "      <td>213221</td>\n",
              "      <td>213222.0</td>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360472</td>\n",
              "      <td>364011</td>\n",
              "      <td>490273.0</td>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183004</td>\n",
              "      <td>279958</td>\n",
              "      <td>279959.0</td>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... is_duplicate\n",
              "0  133273  ...          0.0\n",
              "1  402555  ...          1.0\n",
              "2  360472  ...          0.0\n",
              "3  150662  ...          1.0\n",
              "4  183004  ...          0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoKRQaFYVn-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfb8f1c9-f023-4ed6-eff0-b6452538db7d"
      },
      "source": [
        "len(train_df), len(valid_df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363192, 40372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZWafkPVpzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1e68776a-70aa-42ca-d332-e2515870759e"
      },
      "source": [
        "sns.countplot(train_df['is_duplicate'])\n",
        "plt.xlabel('Train data distribution')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train data distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATVUlEQVR4nO3df9ClZX3f8fdHFhJiRNDdUmSh6ySbtgQNwg5sTNJimIGFiVnjoGKbsFLq2ohpbDttaf9wKWqrRssETXBI2LCLieCPGDcJSrcrxloFWSrhZww7BMsSfqwsBZGRDPjtH+d65LCc59nDcp3zsM/zfs3c89zne1/3fV1n95n97P3jXCdVhSRJPb1ovgcgSVp4DBdJUneGiySpO8NFktSd4SJJ6m7JfA/ghWLp0qW1YsWK+R6GJO1Xbrzxxu9U1bI964ZLs2LFCrZv3z7fw5Ck/UqSb4+qe1lMktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSdn9Dv6IR/v3m+h6AXoBt/6+z5HoI0dZ65SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLU3cTCJclRSa5NcnuS25L8Zqu/LMnWJHe2n4e1epJcnGRHkpuTHD90rHWt/Z1J1g3VT0hyS9vn4iSZqw9J0nRM8szlSeDfVdUxwGrgvCTHAOcD26pqJbCtvQY4HVjZlvXAJTAICmADcBJwIrBhKCwuAd4+tN+aVp+tD0nSFEwsXKrqvqr6P239u8AdwJHAWmBTa7YJeENbXwtsroHrgEOTHAGcBmytqt1V9TCwFVjTth1SVddVVQGb9zjWqD4kSVMwlXsuSVYArwGuBw6vqvvapvuBw9v6kcA9Q7vtbLW56jtH1Jmjjz3HtT7J9iTbd+3a9dzfmCRppImHS5IfBz4LvLuqHh3e1s44apL9z9VHVV1aVauqatWyZcsmOQxJWlQmGi5JDmQQLH9YVX/cyg+0S1q0nw+2+r3AUUO7L2+1uerLR9Tn6kOSNAWTfFoswGXAHVX134c2bQFmnvhaB3x+qH52e2psNfBIu7R1DXBqksPajfxTgWvatkeTrG59nb3HsUb1IUmagiUTPPbPAb8G3JLkplb7z8AHgE8lORf4NvDmtu1q4AxgB/A4cA5AVe1O8l7ghtbuwqra3dbfCVwOHAx8oS3M0YckaQomFi5V9VUgs2w+ZUT7As6b5VgbgY0j6tuBY0fUHxrVhyRpOvyEviSpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1N7FwSbIxyYNJbh2qXZDk3iQ3teWMoW3/KcmOJN9KctpQfU2r7Uhy/lD9lUmub/WrkhzU6j/SXu9o21dM6j1Kkkab5JnL5cCaEfWLquq4tlwNkOQY4Czgp9s+v5vkgCQHAL8DnA4cA7y1tQX4YDvWTwIPA+e2+rnAw61+UWsnSZqiiYVLVX0F2D1m87XAlVX1RFX9DbADOLEtO6rqrqr6O+BKYG2SAL8IfKbtvwl4w9CxNrX1zwCntPaSpCmZj3su70pyc7tsdlirHQncM9RmZ6vNVn858P+q6sk96s84Vtv+SGv/LEnWJ9meZPuuXbue/zuTJAHTD5dLgJ8AjgPuAz4y5f6foaourapVVbVq2bJl8zkUSVpQphouVfVAVT1VVT8Afo/BZS+Ae4Gjhpoub7XZ6g8BhyZZskf9Gcdq21/a2kuSpmSq4ZLkiKGXvwLMPEm2BTirPen1SmAl8A3gBmBlezLsIAY3/bdUVQHXAme2/dcBnx861rq2fibwpdZekjQlS/beZN8k+SRwMrA0yU5gA3BykuOAAu4G3gFQVbcl+RRwO/AkcF5VPdWO8y7gGuAAYGNV3da6+I/AlUneB3wTuKzVLwOuSLKDwQMFZ03qPUqSRptYuFTVW0eULxtRm2n/fuD9I+pXA1ePqN/F05fVhuvfB970nAYrSerKT+hLkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrqb2Cf0Jb1w/N8LXzXfQ9AL0NHvuWVixx7rzCXJtnFqkiTBXs5ckvwo8GMMJp88DJj5RsdDePrLuSRJeoa9XRZ7B/Bu4BXAjTwdLo8CH5vguCRJ+7E5w6Wqfhv47SS/UVUfndKYJEn7ubFu6FfVR5O8FlgxvE9VbZ7QuCRJ+7GxwiXJFcBPADcBT7VyAYaLJOlZxn0UeRVwjF8XLEkax7gforwV+PuTHIgkaeEY98xlKXB7km8AT8wUq+qXJzIqSdJ+bdxwuWCSg5AkLSzjPi32F5MeiCRp4Rj3abHvMng6DOAg4EDge1V1yKQGJknaf4175vKSmfUkAdYCqyc1KEnS/u05T7lfA38CnDaB8UiSFoBxL4u9cejlixh87uX7ExmRJGm/N+7TYq8fWn8SuJvBpTFJkp5l3Hsu50x6IJKkhWPcLwtbnuRzSR5sy2eTLJ/04CRJ+6dxb+j/AbCFwfe6vAL401aTJOlZxg2XZVX1B1X1ZFsuB5ZNcFySpP3YuOHyUJJfTXJAW34VeGiSA5Mk7b/GDZd/AbwZuB+4DzgTeNuExiRJ2s+N+yjyhcC6qnoYIMnLgA8zCB1Jkp5h3DOXV88EC0BV7QZeM5khSZL2d+OGy4uSHDbzop25jHvWI0laZMYNiI8AX0/y6fb6TcD7JzMkSdL+bqwzl6raDLwReKAtb6yqK+baJ8nG9oHLW4dqL0uyNcmd7edhrZ4kFyfZkeTmJMcP7bOutb8zybqh+glJbmn7XNxma561D0nS9Iw9K3JV3V5VH2vL7WPscjmwZo/a+cC2qloJbGuvAU4HVrZlPXAJ/PDy2wbgJOBEYMNQWFwCvH1ovzV76UOSNCXPecr9cVXVV4Dde5TXApva+ibgDUP1zW06/+uAQ5McwWBa/61Vtbs9ULAVWNO2HVJV11VVAZv3ONaoPiRJUzKxcJnF4VV1X1u/Hzi8rR8J3DPUbmerzVXfOaI+Vx/PkmR9ku1Jtu/atWsf3o4kaZRph8sPtTOO2mvDCfZRVZdW1aqqWrVsmbPZSFIv0w6XB9olLdrPB1v9XuCooXbLW22u+vIR9bn6kCRNybTDZQsw88TXOuDzQ/Wz21Njq4FH2qWta4BTkxzWbuSfClzTtj2aZHV7SuzsPY41qg9J0pRM7IOQST4JnAwsTbKTwVNfHwA+leRc4NsM5isDuBo4A9gBPA6cA4OZAJK8F7ihtbuwzQ4A8E4GT6QdDHyhLczRhyRpSiYWLlX11lk2nTKibQHnzXKcjcDGEfXtwLEj6g+N6kOSND3zdkNfkrRwGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKm7eQmXJHcnuSXJTUm2t9rLkmxNcmf7eVirJ8nFSXYkuTnJ8UPHWdfa35lk3VD9hHb8HW3fTP9dStLiNZ9nLq+rquOqalV7fT6wrapWAtvaa4DTgZVtWQ9cAoMwAjYAJwEnAhtmAqm1efvQfmsm/3YkSTNeSJfF1gKb2vom4A1D9c01cB1waJIjgNOArVW1u6oeBrYCa9q2Q6rquqoqYPPQsSRJUzBf4VLA/0hyY5L1rXZ4Vd3X1u8HDm/rRwL3DO27s9Xmqu8cUZckTcmSeer356vq3iR/D9ia5K+GN1ZVJalJD6IF23qAo48+etLdSdKiMS9nLlV1b/v5IPA5BvdMHmiXtGg/H2zN7wWOGtp9eavNVV8+oj5qHJdW1aqqWrVs2bLn+7YkSc3UwyXJi5O8ZGYdOBW4FdgCzDzxtQ74fFvfApzdnhpbDTzSLp9dA5ya5LB2I/9U4Jq27dEkq9tTYmcPHUuSNAXzcVnscOBz7engJcAfVdUXk9wAfCrJucC3gTe39lcDZwA7gMeBcwCqaneS9wI3tHYXVtXutv5O4HLgYOALbZEkTcnUw6Wq7gJ+ZkT9IeCUEfUCzpvlWBuBjSPq24Fjn/dgJUn75IX0KLIkaYEwXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpuwUbLknWJPlWkh1Jzp/v8UjSYrIgwyXJAcDvAKcDxwBvTXLM/I5KkhaPBRkuwInAjqq6q6r+DrgSWDvPY5KkRWPJfA9gQo4E7hl6vRM4ac9GSdYD69vLx5J8awpjWyyWAt+Z70G8EOTD6+Z7CHomfzdnbEiPo/yDUcWFGi5jqapLgUvnexwLUZLtVbVqvsch7cnfzelYqJfF7gWOGnq9vNUkSVOwUMPlBmBlklcmOQg4C9gyz2OSpEVjQV4Wq6onk7wLuAY4ANhYVbfN87AWGy836oXK380pSFXN9xgkSQvMQr0sJkmaR4aLJKk7w0X7bG9T7CT5kSRXte3XJ1kx/VFqMUqyMcmDSW6dZXuSXNx+N29Ocvy0x7jQGS7aJ2NOsXMu8HBV/SRwEfDB6Y5Si9jlwJo5tp8OrGzLeuCSKYxpUTFctK/GmWJnLbCprX8GOCVJl48ES3Opqq8Au+doshbYXAPXAYcmOWI6o1scDBftq1FT7Bw5W5uqehJ4BHj5VEYnzW2c3189D4aLJKk7w0X7apwpdn7YJskS4KXAQ1MZnTQ3p4iaMMNF+2qcKXa2ADNTAp8JfKn81K5eGLYAZ7enxlYDj1TVffM9qIVkQU7/osmbbYqdJBcC26tqC3AZcEWSHQxurp41fyPWYpLkk8DJwNIkO4ENwIEAVfVx4GrgDGAH8DhwzvyMdOFy+hdJUndeFpMkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hosWhCQvT3JTW+5Pcu/Q64P2su+qJBc/j77fluRje2lzcpLX7msf7RhfTrKqrV+d5NA52r47yY/Nsf33ZyYaTfLYcxzHcUnOGHr9y6Nmxdbi5udctCBU1UPAcQBJLgAeq6oPz2xPsqTNbzZq3+3A9gkP8WTgMeBrPQ5WVWfspcm7gU8w+AzHMyQ5oKr+5fPo/jhgFYPPitA+07TnB2i1yHnmogUryeVJPp7keuBDSU5M8vUk30zytST/sLU7OcmftfUL2neBfDnJXUn+9SzHPifJXyf5BvBzQ/XXt++u+WaS/5nk8PY9Nv8K+DftTOoXRrUb0cfBSa5MckeSzwEHD227O8nSJC9O8udJ/jLJrUne0sb8CuDaJNe29o8l+UiSvwR+dvgsqG2/KMltSbYlWdZqw2dKS1ufBwEXAm9p7+Utw2duSVYk+VL7jpRtSY4e+ru4uP2535XkzH37W9X+wnDRQrcceG1V/Vvgr4BfqKrXAO8B/uss+/wj4DQGXyuwIcmBwxvb1Oz/hUGo/DyD77OZ8VVgdevjSuA/VNXdwMeBi6rquKr6X6PajRjHrwOPV9U/ZvAJ8xNGtFkD/G1V/UxVHQt8saouBv4WeF1Vva61ezFwfWv31T2O8WIGsyr8NPAXra+R2tcrvAe4qr2Xq/Zo8lFgU1W9GvhDYPhy4xEM/rx+CfjAbH1oYfCymBa6T1fVU239pcCmJCuBok0HMsKfV9UTwBNJHgQOZzAl+4yTgC9X1S6AJFcBP9W2LQeuagF0EPA3s/QxTrt/QvvHuapuTnLziDa3AB9J8kHgz1pwjfIU8NlZtv0AmAmJTwB/PEu7cfws8Ma2fgXwoaFtf1JVPwBuH3WmpoXFMxctdN8bWn8vcG37H/7rgR+dZZ8nhtaf4rn9J+yjwMeq6lXAO+boY9x2c6qqvwaOZxAy70vynlmafn8oZPd62PbzSZ7+N2KfxreH4T9XvzRugTNctJi8lKenVX/b8zjO9cA/bU+oHQi8aZY+1g3Vvwu8ZIx2w74C/DOAJMcCr96zQZJXMLh09gngtxgEzaj+5vIiBrNW0/qbuWx2N09fihu+RzLXsb/G0xOU/nNgtjMpLXCGixaTDwH/Lck3eR6XhNvU7BcAXwf+N3DH0OYLgE8nuRH4zlD9T4FfmbmhP0e7YZcAP57kDgY30W8c0eZVwDeS3MTgXsn7Wv1S4IszN/T34nvAiUluBX6x9QXwYeDX25/X0qH21wLHzNzQ3+NYvwGc0y7h/Rrwm2P0rwXIWZElSd155iJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpu/8PZRlraFFX9X0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyjM-KpVrnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ff49802b-894f-4165-d5d1-65a23467f5e4"
      },
      "source": [
        "sns.countplot(valid_df['is_duplicate'])\n",
        "plt.xlabel('Valid data distribution')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Valid data distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNwhS3a9VtX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df[train_df['is_duplicate'] == 1]\n",
        "valid_data = valid_df[valid_df['is_duplicate'] == 1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjt7OatoVvbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6bb38bde-7466-44b1-e040-ff1c6e3191f6"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>106969</td>\n",
              "      <td>147570</td>\n",
              "      <td>787.0</td>\n",
              "      <td>What is the best self help book you have read?...</td>\n",
              "      <td>What are the top self help books I should read?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>233239</td>\n",
              "      <td>71243</td>\n",
              "      <td>177376.0</td>\n",
              "      <td>What will be Hillary Clinton's policy towards ...</td>\n",
              "      <td>What will be Hilary Clinton's policy towards I...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11568</td>\n",
              "      <td>22332</td>\n",
              "      <td>22333.0</td>\n",
              "      <td>Which is the best book to study TENSOR for gen...</td>\n",
              "      <td>Which is the best book for tensor calculus?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... is_duplicate\n",
              "1   402555  ...          1.0\n",
              "3   150662  ...          1.0\n",
              "7   106969  ...          1.0\n",
              "11  233239  ...          1.0\n",
              "13   11568  ...          1.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBFldYzwVxIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "246d7141-53f2-4b12-98fa-af6d1c45a842"
      },
      "source": [
        "len(train_data), len(valid_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134141, 14857)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl3-3WXBVytR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data[['question1', 'question2']]\n",
        "valid_data = valid_data[['question1', 'question2']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leSwCfnBV0gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a1688e42-1a05-4446-e30f-89a2c142a064"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the best self help book you have read?...</td>\n",
              "      <td>What are the top self help books I should read?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What will be Hillary Clinton's policy towards ...</td>\n",
              "      <td>What will be Hilary Clinton's policy towards I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Which is the best book to study TENSOR for gen...</td>\n",
              "      <td>Which is the best book for tensor calculus?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question1                                          question2\n",
              "1                 How do I control my horny emotions?                 How do you control your horniness?\n",
              "3                         What can one do after MBBS?                       What do i do after my MBBS ?\n",
              "7   What is the best self help book you have read?...    What are the top self help books I should read?\n",
              "11  What will be Hillary Clinton's policy towards ...  What will be Hilary Clinton's policy towards I...\n",
              "13  Which is the best book to study TENSOR for gen...        Which is the best book for tensor calculus?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQN3K0mRWShc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_train_data = train_data.sample(50000)\n",
        "sample_valid_data = valid_data.sample(5000)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuTvU9lbV1wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_train_data.to_csv('train_ds.csv')\n",
        "sample_valid_data.to_csv('valid_ds.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyJS5tJ9WUpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "cce59882-e42e-43f6-c293-1f080cd25da5"
      },
      "source": [
        "!ls -lah"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6.1M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 22 15:07 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 22 15:02 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jun 17 16:18 .config\n",
            "drwxr-xr-x 4 root root 4.0K Jun 22 15:07 glue_data\n",
            "drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n",
            "-rw-r--r-- 1 root root 5.5M Jun 22 15:07 train_ds.csv\n",
            "-rw-r--r-- 1 root root 558K Jun 22 15:07 valid_ds.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhthPL4nWV5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = data.get_tokenizer('spacy')\n",
        "TEXT = data.Field(tokenize=tokenizer, lower=True, init_token='<sos>', eos_token='<eos>', include_lengths=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWVdYjDbWYFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = [(None, None), (\"source\", TEXT), (\"target\", TEXT)]\n",
        "\n",
        "train_dataset, valid_dataset = data.TabularDataset.splits(path='.',\n",
        "                                     train='train_ds.csv', validation='valid_ds.csv',\n",
        "                                     format='csv', skip_header=True, fields=fields)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3T_VddNWaEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a0cae43-7a08-4a7d-a87c-6c332738c59b"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation examples: {len(valid_dataset)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 50000\n",
            "Number of validation examples: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA_9KjdOWb9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf42578-6b7a-4536-e6ba-cad9ab9199ad"
      },
      "source": [
        "print(vars(train_dataset.examples[1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': ['what', 'are', 'complex', 'networks', '?'], 'target': ['what', 'defines', 'a', 'complex', 'network', '?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhtkuPlHWdt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_dataset, min_freq=5)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sznI1MgWfV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80734d30-b93e-4fd0-81c4-f1b8d381fc2d"
      },
      "source": [
        "print(f\"Number of tokens in vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens in vocabulary: 8130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk2_eszIWgn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.source),\n",
        "    sort_within_batch=True,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDZn0t4WiaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ccfad5f-c55a-402a-beae-174f2f99d251"
      },
      "source": [
        "# sample checking\n",
        "temp = next(iter(train_iterator))\n",
        "temp_source, temp_source_lengths = temp.source\n",
        "temp_target, temp_target_lengths = temp.target\n",
        "temp_source.shape, temp_source_lengths.shape, temp_target.shape, temp_target_lengths.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([9, 64]), torch.Size([64]), torch.Size([22, 64]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m_PYYmvWklt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, num_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_lengths):\n",
        "        # src => [seq_len, batch_size]\n",
        "        # src_lengths => [batch_size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded => [seq_len, batch_size, hidden_dim]\n",
        "\n",
        "        pack_padded_sequences = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths)\n",
        "        packed_outputs, (hidden, cell) = self.rnn(pack_padded_sequences)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "        # outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # hidden, cell => [num_layers * num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        hidden = hidden.view(self.n_layers, 2,  -1, self.hidden_dim)\n",
        "        cell = cell.view(self.n_layers, 2,  -1, self.hidden_dim)\n",
        "        # hidden, cell => [num_layers, num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        final_forward_hidden = hidden[:, 0, :, :]\n",
        "        final_backward_hidden = hidden[:, 1, :, :]\n",
        "        # final_hiddens => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        final_forward_cell = cell[:, 0, :, :]\n",
        "        final_backward_cell = cell[:, 1, :, :]\n",
        "        # final_cells => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        combined_hidden = torch.cat((final_forward_hidden, final_backward_hidden), dim=2)\n",
        "        combined_cell = torch.cat((final_forward_cell, final_backward_cell), dim=2)\n",
        "        # combined_hidden, combined_cell => [num_layers, batch_size, hidden_dim * 2]\n",
        "\n",
        "        decoder_initial_hidden = self.fc(combined_hidden)\n",
        "        decoder_initial_cell = self.fc(combined_cell)\n",
        "        # decoder_initial_states => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        return outputs, decoder_initial_hidden, decoder_initial_cell"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as28RkMbWsYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "        self.w1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.w2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, mask=None):\n",
        "        # hidden => [batch_size, hidden_dim]\n",
        "        # encoder_outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        seq_len = encoder_outputs.shape[0]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        # hidden => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs => [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        hidden_energy = self.w1(hidden)\n",
        "        # hidden_energy => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        encoder_energy = self.w2(encoder_outputs)\n",
        "        # encoder_energy => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        combined_energy = hidden_energy + encoder_energy\n",
        "        # combined_energy => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        energy = self.v(torch.tanh(combined_energy)).squeeze(2)\n",
        "        # energy => [batch_size, seq_len]\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == self.pad_idx, -1e10)\n",
        "            # energy => [batch_size, seq_len]\n",
        "\n",
        "        return F.softmax(energy, dim=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0bxq4OWzO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, attn, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
        "        self.attn = attn\n",
        "        self.fc = nn.Linear(emb_dim + hidden_dim * 3, input_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, trg, hidden, cell, encoder_outputs, mask):\n",
        "        # trg => [batch_size]\n",
        "        # hidden, cell => [num_layers, batch_size, hidden_dim]\n",
        "        # encoder_outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embedded = self.dropout(trg)\n",
        "        # embedded => [1, batch_size, emb_dim\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        # output => [1, batch_size, hidden_dim]\n",
        "        # hidden, cell => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        attention = self.attn(output.squeeze(0), encoder_outputs, mask)\n",
        "        # attention => [batch_size, seq_len]\n",
        "\n",
        "        attention = attention.unsqueeze(1)\n",
        "        # attention => [batch_size, 1, seq_len]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs => [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        weighted = torch.bmm(attention, encoder_outputs)\n",
        "        # attention       => [batch_size, 1, seq_len]\n",
        "        # encoder_outputs => [batch_size, seq_len, hidden_dim * 2]\n",
        "        # weighted        => [batch_size, 1, hidden_dim * 2]\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        # weighted => [1, batch_size, hidden_dim * 2]\n",
        "\n",
        "        combined_out_input = torch.cat((output, weighted, embedded), dim=2)\n",
        "        # combined_out_input => [1, batch_size, hidden_dim * 3 + emb_dim]\n",
        "\n",
        "        combined_out_input = combined_out_input.squeeze(0)\n",
        "        combined_out_input = self.dropout(combined_out_input)\n",
        "        # combined_out_input => [batch_size, hidden_dim * 3 + emb_dim]\n",
        "\n",
        "        logits = self.fc(combined_out_input)\n",
        "        # logits => [batch_size, output_dim]\n",
        "        \n",
        "        return logits, hidden, cell, attention.squeeze(1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8agGtkSLW6lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.pad_idx = pad_idx\n",
        "    \n",
        "    def make_mask(self, src):\n",
        "        # src => [seq_len, batch_size]\n",
        "\n",
        "        mask = (src == self.pad_idx)\n",
        "        mask = mask.transpose(1, 0)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
        "        # src => [seq_len, batch_size]\n",
        "        # trg => [trg_len, batch_size]\n",
        "\n",
        "        src_mask = self.make_mask(src)\n",
        "        # src_mask => [batch_size, seq_len]\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
        "        # encoder_outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # hidden, cell => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        output_dim = self.decoder.input_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, output_dim).to(self.device)\n",
        "        # outputs => [trg_len, batch_size, output_dim]\n",
        "\n",
        "        dec_inp = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            dec_emb = self.encoder.embedding(dec_inp.unsqueeze(0))\n",
        "            # dec_emb => [1, batch_size, emb_dim]\n",
        "\n",
        "            output, hidden, cell, _ = self.decoder(dec_emb, hidden, cell, encoder_outputs, src_mask)\n",
        "            \n",
        "            # store the output\n",
        "            outputs[t] = output\n",
        "\n",
        "            # to do teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            # get the top prediction\n",
        "            top1 = output.argmax(1)\n",
        "            \n",
        "            # next input to decoder\n",
        "            dec_inp = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eolHplrEXA8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
        "attn = Attention(HID_DIM, PAD_IDX)\n",
        "dec = Decoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, attn, DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device, PAD_IDX).to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj_v5pQ-XCsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4f9d75c5-588d-434c-cd0a-37fb1358fd3a"
      },
      "source": [
        "\n",
        "def init_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(8130, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (attn): Attention(\n",
              "      (w1): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (w2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (fc): Linear(in_features=1792, out_features=8130, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPH9yiEXXEQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f565935-b555-42e6-e15b-32ec34c1e4c7"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model)} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 31102914 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiYYis6HXGMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dU9wru_XIH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, criterion, optimizer, clip):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # keep the model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over train data\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, src_len = batch.source\n",
        "        trg, _ = batch.target\n",
        "        # src => [seq_len, batch_size]\n",
        "        # src_len => [batch_size]\n",
        "        # trg => [seq_len, batch_size]\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        output = model(src, src_len, trg)\n",
        "\n",
        "        # reshaping the output to make it compatible to cal. loss\n",
        "        # can also do without reshaping\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient clipping \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # update the parameters of the model\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the loss\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "074tb7FeXMu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    # keep the model in eval mode\n",
        "    model.eval()\n",
        "    \n",
        "    # do not calculate gradients\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # iterate over the data\n",
        "        for batch in iterator:\n",
        "            src, src_len = batch.source\n",
        "            trg, _ = batch.target\n",
        "            # src => [seq_len, batch_size]\n",
        "            # src_len => [batch_size]\n",
        "            # trg => [seq_len, batch_size]\n",
        "\n",
        "            # forward pass\n",
        "            # make sure the teacher_forcing_ratio is 0 in eval\n",
        "            output = model(src, src_len, trg, 0)\n",
        "\n",
        "            # reshaping for loss calculation\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # loss\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # update loss\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUqsG0Z6XP0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKeMIooWXSAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a2ef27d4-7a92-4b4e-b873-5d265154ad82"
      },
      "source": [
        "N_EPOCHS = 8\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, criterion, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f\"Epoch {epoch + 1} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} |\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:.3f} | Valid PPL: {math.exp(valid_loss):7.3f} |\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Time: 5m 33.4158935546875s\n",
            "\tTrain Loss: 4.442 | Train PPL:  84.930 |\n",
            "\tValid Loss: 4.110 | Valid PPL:  60.977 |\n",
            "Epoch 2 | Time: 5m 32.07571077346802s\n",
            "\tTrain Loss: 3.475 | Train PPL:  32.286 |\n",
            "\tValid Loss: 3.762 | Valid PPL:  43.015 |\n",
            "Epoch 3 | Time: 5m 32.077293157577515s\n",
            "\tTrain Loss: 3.057 | Train PPL:  21.266 |\n",
            "\tValid Loss: 3.557 | Valid PPL:  35.045 |\n",
            "Epoch 4 | Time: 5m 31.61773920059204s\n",
            "\tTrain Loss: 2.809 | Train PPL:  16.593 |\n",
            "\tValid Loss: 3.453 | Valid PPL:  31.608 |\n",
            "Epoch 5 | Time: 5m 31.004390954971313s\n",
            "\tTrain Loss: 2.613 | Train PPL:  13.639 |\n",
            "\tValid Loss: 3.501 | Valid PPL:  33.132 |\n",
            "Epoch 6 | Time: 5m 31.26005530357361s\n",
            "\tTrain Loss: 2.465 | Train PPL:  11.766 |\n",
            "\tValid Loss: 3.446 | Valid PPL:  31.378 |\n",
            "Epoch 7 | Time: 5m 30.851324319839478s\n",
            "\tTrain Loss: 2.369 | Train PPL:  10.689 |\n",
            "\tValid Loss: 3.432 | Valid PPL:  30.935 |\n",
            "Epoch 8 | Time: 5m 29.957483530044556s\n",
            "\tTrain Loss: 2.279 | Train PPL:   9.763 |\n",
            "\tValid Loss: 3.442 | Valid PPL:  31.257 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBSceS79XVIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c862d1de-0f5d-4da3-d3d5-f5c48843a76b"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd1TwXuoXWvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_utterance_greedy(sentence, text_field, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # tokenization        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    tokens = [text_field.init_token] + tokens + [text_field.eos_token]\n",
        "\n",
        "    # convert the tokens to ids  \n",
        "    src_indexes = [text_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    # convert to tensor format\n",
        "    # since the inference is done on single sentence, batch size is 1\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "    # src_tensor => [seq_len, 1]\n",
        "    \n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "    # src_len => [1]\n",
        "\n",
        "    # encode the input sentence\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    # mask of the input sentence\n",
        "    mask = model.make_mask(src_tensor)\n",
        "\n",
        "    # the starting input to decoder is always <sos>\n",
        "    trg_indexes = [text_field.vocab.stoi[text_field.init_token]]\n",
        "\n",
        "    # to store attentions \n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    # attentions => [max_len, 1, src_len]\n",
        "\n",
        "    # decode upto a length of max_len\n",
        "    for i in range(max_len):\n",
        "\n",
        "        # convert the decoder input to tensor format\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "        \n",
        "        # trg input embedding\n",
        "        trg_embed = model.encoder.embedding(trg_tensor.unsqueeze(1))\n",
        "        # trg_embed => [1, 1, emb_dim]\n",
        "\n",
        "        # decode the input\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell, attention = model.decoder(trg_embed, hidden, cell, encoder_outputs, mask)\n",
        "        \n",
        "        # store the attention\n",
        "        attentions[i] = attention\n",
        "\n",
        "        # get the predicted token by considering the token with highest score\n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        # add to predicted tokens\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        # if the predicted token is <eos> means stop the decoding\n",
        "        if pred_token == text_field.vocab.stoi[text_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    # convert the predicted token ids to words\n",
        "    trg_tokens = [text_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return tokens[1:], trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WhLZCRaabk8",
        "colab_type": "text"
      },
      "source": [
        "#### This is not a optimal way to implement Beam Search. I implemented in a naive way in-order to understand it better. Please suggest ways to improve this by raising an issue [here](https://github.com/graviraja/100-Days-of-NLP/issues)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k503JWauF7Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_utterance_beam(sentence, model, device, text_field, max_len=50, beam_size=3):\n",
        "    model.eval()\n",
        "\n",
        "    # tokenization        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    tokens = [text_field.init_token] + tokens + [text_field.eos_token]\n",
        "\n",
        "    # convert the tokens to ids  \n",
        "    src_indexes = [text_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    # convert to tensor format\n",
        "    # since the inference is done on single sentence, batch size is 1\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "    # src_tensor => [seq_len, 1]\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "    # src_len => [1]\n",
        "\n",
        "    # encode the input sentence\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
        "        # encoder_outputs => [src_len, 1, hidden_dim * 2]\n",
        "        # hidden, cell => [num_layers, 1, hidden_dim]\n",
        "    \n",
        "    num_layers, _, hid_dim = list(hidden.size())\n",
        "\n",
        "    # mask of the input sentence\n",
        "    mask = model.make_mask(src_tensor)\n",
        "    # [1, src_len]\n",
        "\n",
        "    # the starting input to decoder is always <sos>\n",
        "    initial_trg_indexes = [text_field.vocab.stoi[text_field.init_token]]\n",
        "\n",
        "    # convert the decoder input to tensor format\n",
        "    trg_tensor = torch.LongTensor([initial_trg_indexes[-1]]).to(device)\n",
        "    \n",
        "    # trg input embedding\n",
        "    trg_embed = model.encoder.embedding(trg_tensor.unsqueeze(1))\n",
        "    # trg_embed => [1, 1, emb_dim]\n",
        "\n",
        "    # decode the input\n",
        "    with torch.no_grad():\n",
        "        output, hidden, cell, _ = model.decoder(trg_embed, hidden, cell, encoder_outputs, mask)\n",
        "\n",
        "    # get the predicted token by considering the token with highest score\n",
        "    pred_token = output.argmax(1).item()\n",
        "    \n",
        "    top_k_scores, top_k_indexes = output.topk(beam_size, 1, True, True)\n",
        "    # top_k_scores => [1, beam_size]\n",
        "    # top_k_indexes => [1, beam_size]\n",
        "\n",
        "    top_k_indexes = top_k_indexes.squeeze().tolist()\n",
        "\n",
        "    # the starting input to decoder is always <sos>\n",
        "    trg_seq_indexes = []\n",
        "    # trg_seq_indexes = list([[text_field.vocab.stoi[text_field.init_token]]] * beam_size)\n",
        "    for i in range(beam_size):\n",
        "        trg_seq_indexes.append([text_field.vocab.stoi[text_field.init_token], top_k_indexes[i]])\n",
        "    # [[<sos>, inital_top1], [<sos>, initial_top2], [<sos>, initial_top3]]\n",
        "\n",
        "    # replicate hidden states so that relevant ones can be used\n",
        "    hidden_states = [hidden] * beam_size\n",
        "    cell_states = [cell] * beam_size\n",
        "\n",
        "    # scores after initial step\n",
        "    scores = top_k_scores.squeeze()\n",
        "    # [beam_size]\n",
        "    completed_seqs = []\n",
        "    eos_encountered = 0\n",
        "\n",
        "    # decode upto a length of max_len\n",
        "    for i in range(max_len-1):\n",
        "        temp_sequences = []\n",
        "        for index, each_seq in enumerate(trg_seq_indexes):\n",
        "            # if the sequence already hits <eos> means then continue decoding the next sequence\n",
        "            if each_seq[-1] == text_field.vocab.stoi[text_field.eos_token]:\n",
        "                continue\n",
        "            # convert the decoder input to tensor format\n",
        "            trg_tensor = torch.LongTensor([each_seq[-1]]).to(device)\n",
        "            \n",
        "            # trg input embedding\n",
        "            trg_embed = model.encoder.embedding(trg_tensor.unsqueeze(1))\n",
        "            # trg_embed => [1, 1, emb_dim]\n",
        "\n",
        "            # get the relevant hidden, cell states\n",
        "            hidden = hidden_states[index].to(device)\n",
        "            cell = cell_states[index].to(device)\n",
        "\n",
        "            # decode the input\n",
        "            with torch.no_grad():\n",
        "                output, hidden, cell, _ = model.decoder(trg_embed, hidden, cell, encoder_outputs, mask)\n",
        "                # output => [1, vocab_size]\n",
        "\n",
        "            # update the hidden and cell states of the sequence accordingly\n",
        "            hidden_states[index] = hidden\n",
        "            cell_states[index] = cell\n",
        "\n",
        "            # get the probability scores of the prediction\n",
        "            prediction_scores = F.softmax(output, dim=1)\n",
        "\n",
        "            top_k_scores, top_k_indexes = prediction_scores.topk(beam_size, 1, True, True)\n",
        "            # top_k_scores => [1, beam_size]\n",
        "            # top_k_indexes => [1, beam_size]\n",
        "\n",
        "            top_k_scores = top_k_scores.squeeze()\n",
        "            top_k_indexes = top_k_indexes.squeeze()\n",
        "            # top_k_scores => [beam_size]\n",
        "            # top_k_indexes => [beam_size]\n",
        "\n",
        "            # length of the sequence\n",
        "            length = len(each_seq)\n",
        "\n",
        "            prev_seq_score = torch.tensor([scores[index]]).to(device)\n",
        "            current_seq_score = (prev_seq_score * length) + top_k_scores\n",
        "            # length penality\n",
        "            current_seq_score = current_seq_score / (length + 1)\n",
        "            # current_seq_score => [beam_size]\n",
        "\n",
        "            for item in range(beam_size):\n",
        "                temp_sequences.append([current_seq_score[item].item(), top_k_indexes[item].item(), hidden, cell])\n",
        "\n",
        "        # order all candidates by score\n",
        "        ordered = sorted(temp_sequences, key=lambda tup:tup[0], reverse=True)\n",
        "        top_results = ordered[:beam_size-eos_encountered]\n",
        "\n",
        "        temp_hidden = []\n",
        "        temp_cell = []\n",
        "        temp_scores = []\n",
        "        temp_trg_indexes = []\n",
        "\n",
        "        for idx, result in enumerate(top_results):\n",
        "            seq_score = result[0]\n",
        "            seq_token = result[1]\n",
        "            hidden = result[2]\n",
        "            cell = result[3]\n",
        "\n",
        "            trg_seq_indexes[idx].append(seq_token)\n",
        "            scores[idx] = seq_score\n",
        "            hidden_states[idx] = hidden\n",
        "            cell_states[idx] = cell\n",
        "\n",
        "            if seq_token == text_field.vocab.stoi[text_field.eos_token]:\n",
        "                eos_encountered += 1\n",
        "                completed_seqs.append(trg_seq_indexes[idx])\n",
        "            \n",
        "            temp_scores.append(seq_score)\n",
        "            temp_hidden.append(hidden)\n",
        "            temp_cell.append(cell)\n",
        "\n",
        "            temp_scores.append(seq_score)\n",
        "            hidden_states.append(hidden)\n",
        "            cell_states.append(cell)\n",
        "            if seq_token != text_field.vocab.stoi[text_field.eos_token]:\n",
        "                temp_trg_indexes.append(trg_seq_indexes[idx])\n",
        "        trg_seq_indexes = temp_trg_indexes\n",
        "        hidden_states = temp_hidden\n",
        "        cell_states = temp_cell\n",
        "        scores = temp_scores\n",
        "        \n",
        "        if eos_encountered == beam_size:\n",
        "            break\n",
        "\n",
        "    # convert the predicted token ids to words\n",
        "    trg_tokens = [[text_field.vocab.itos[i] for i in seq] for seq in completed_seqs]\n",
        "    return trg_tokens"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggIsXc1tGzPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0a5eaf10-0024-4f89-af77-f4e5f1783681"
      },
      "source": [
        "example_idx = 55\n",
        "\n",
        "src = vars(valid_dataset.examples[example_idx])['source']\n",
        "trg = vars(valid_dataset.examples[example_idx])['target']\n",
        "_, greedy_utterance, _ = generate_utterance_greedy(src, TEXT, model, device)\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'generated greedy utterance = {greedy_utterance}')\n",
        "print(f'generated beam utterances:')\n",
        "seq = generate_utterance_beam(src, model, device, TEXT)\n",
        "for s in seq:\n",
        "    print(s[1:-1])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['which', 'book', 'would', 'you', 'recommend', 'to', 'improve', 'english', '?']\n",
            "trg = ['what', 'are', 'the', 'books', 'to', 'improve', 'english', '?']\n",
            "generated greedy utterance = ['what', 'are', 'the', 'best', 'books', 'to', 'learn', 'english', '?', '<eos>']\n",
            "generated beam utterances:\n",
            "['what', 'are', 'the', 'best', 'book', 'to', 'learn', 'english', '?']\n",
            "['which', 'is', 'the', 'best', 'books', 'to', 'learn', 'english', '?']\n",
            "['how', 'books', 'some', 'good', 'books', 'to', 'learn', 'english', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Feq4nYTrZv1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "af9794db-506e-4b44-eff4-333db15cb882"
      },
      "source": [
        "\n",
        "src = \"What can I do after engineering?\"\n",
        "tokens, greedy_utterance, _ = generate_utterance_greedy(src, TEXT, model, device)\n",
        "\n",
        "print(f'src = {tokens}')\n",
        "print(f'generated greedy utterance = {greedy_utterance}')\n",
        "print(f'generated beam utterances:')\n",
        "seq = generate_utterance_beam(src, model, device, TEXT)\n",
        "for s in seq:\n",
        "    print(s[1:-1])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['what', 'can', 'i', 'do', 'after', 'engineering', '?', '<eos>']\n",
            "generated greedy utterance = ['what', 'should', 'i', 'do', 'after', 'engineering', '?', '<eos>']\n",
            "generated beam utterances:\n",
            "['what', 'should', 'i', 'do', 'after', 'engineering', '?']\n",
            "['how', 'can', 'i', 'do', 'after', 'engineering', '?']\n",
            "['i', 'do', 'i', 'do', 'after', 'engineering', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}