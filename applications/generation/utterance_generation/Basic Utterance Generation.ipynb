{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Utterance Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxV4HxUTy2Z5Or4hzOrG9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fgeneration/applications/generation/utterance_generation/Basic%20Utterance%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYpvQLlps4JY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "e7063f09-2c4f-4117-e1ec-86e5710dc0f5"
      },
      "source": [
        "TASK_DATA_DIR = 'glue_data/QQP'\n",
        "!test -d glue_data || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git glue_data\n",
        "!test -d $TASK_DATA_DIR || python glue_data/download_glue_data.py --data_dir glue_data --tasks=QQP\n",
        "!ls -alh $TASK_DATA_DIR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'glue_data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects:   4% (1/21)   \rUnpacking objects:   9% (2/21)   \rUnpacking objects:  14% (3/21)   \rUnpacking objects:  19% (4/21)   \rUnpacking objects:  23% (5/21)   \rUnpacking objects:  28% (6/21)   \rUnpacking objects:  33% (7/21)   \rUnpacking objects:  38% (8/21)   \rUnpacking objects:  42% (9/21)   \rUnpacking objects:  47% (10/21)   \rUnpacking objects:  52% (11/21)   \rUnpacking objects:  57% (12/21)   \rUnpacking objects:  61% (13/21)   \rUnpacking objects:  66% (14/21)   \rUnpacking objects:  71% (15/21)   \rUnpacking objects:  76% (16/21)   \rUnpacking objects:  80% (17/21)   \rUnpacking objects:  85% (18/21)   \rUnpacking objects:  90% (19/21)   \rUnpacking objects:  95% (20/21)   \rUnpacking objects: 100% (21/21)   \rUnpacking objects: 100% (21/21), done.\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "total 104M\n",
            "drwxr-xr-x 3 root root 4.0K Jun 19 15:54 .\n",
            "drwxr-xr-x 4 root root 4.0K Jun 19 15:54 ..\n",
            "-rw-r--r-- 1 root root 5.6M Jun 19 15:54 dev.tsv\n",
            "drwxr-xr-x 2 root root 4.0K Jun 19 15:54 original\n",
            "-rw-r--r-- 1 root root  49M Jun 19 15:54 test.tsv\n",
            "-rw-r--r-- 1 root root  50M Jun 19 15:54 train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJa6-tS-odi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import data, vocab\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiTjJzPQs_r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeMXipYtB__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1034cac9-d330-4b85-8f45-d577a1cead5f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_t6GYCvrbG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "18dd1150-58bf-4eb9-b6f8-989bce55a366"
      },
      "source": [
        "train_df = pd.read_csv(TASK_DATA_DIR + '/train.tsv', sep='\\t', error_bad_lines=False)\n",
        "valid_df = pd.read_csv(TASK_DATA_DIR + '/dev.tsv', sep='\\t', error_bad_lines=False)\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133273</td>\n",
              "      <td>213221</td>\n",
              "      <td>213222.0</td>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360472</td>\n",
              "      <td>364011</td>\n",
              "      <td>490273.0</td>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183004</td>\n",
              "      <td>279958</td>\n",
              "      <td>279959.0</td>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... is_duplicate\n",
              "0  133273  ...          0.0\n",
              "1  402555  ...          1.0\n",
              "2  360472  ...          0.0\n",
              "3  150662  ...          1.0\n",
              "4  183004  ...          0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0lzdtkrp5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9885ba57-a09a-458d-cfc1-aa87e69b0af1"
      },
      "source": [
        "len(train_df), len(valid_df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363192, 40372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D2wLZ7gvWtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ea8f0250-9ae5-4f14-bb35-08f6786f8f16"
      },
      "source": [
        "sns.countplot(train_df['is_duplicate'])\n",
        "plt.xlabel('Train data distribution')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train data distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATVUlEQVR4nO3df9ClZX3f8fdHFhJiRNDdUmSh6ySbtgQNwg5sTNJimIGFiVnjoGKbsFLq2ohpbDttaf9wKWqrRssETXBI2LCLieCPGDcJSrcrxloFWSrhZww7BMsSfqwsBZGRDPjtH+d65LCc59nDcp3zsM/zfs3c89zne1/3fV1n95n97P3jXCdVhSRJPb1ovgcgSVp4DBdJUneGiySpO8NFktSd4SJJ6m7JfA/ghWLp0qW1YsWK+R6GJO1Xbrzxxu9U1bI964ZLs2LFCrZv3z7fw5Ck/UqSb4+qe1lMktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSdn9Dv6IR/v3m+h6AXoBt/6+z5HoI0dZ65SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLU3cTCJclRSa5NcnuS25L8Zqu/LMnWJHe2n4e1epJcnGRHkpuTHD90rHWt/Z1J1g3VT0hyS9vn4iSZqw9J0nRM8szlSeDfVdUxwGrgvCTHAOcD26pqJbCtvQY4HVjZlvXAJTAICmADcBJwIrBhKCwuAd4+tN+aVp+tD0nSFEwsXKrqvqr6P239u8AdwJHAWmBTa7YJeENbXwtsroHrgEOTHAGcBmytqt1V9TCwFVjTth1SVddVVQGb9zjWqD4kSVMwlXsuSVYArwGuBw6vqvvapvuBw9v6kcA9Q7vtbLW56jtH1Jmjjz3HtT7J9iTbd+3a9dzfmCRppImHS5IfBz4LvLuqHh3e1s44apL9z9VHVV1aVauqatWyZcsmOQxJWlQmGi5JDmQQLH9YVX/cyg+0S1q0nw+2+r3AUUO7L2+1uerLR9Tn6kOSNAWTfFoswGXAHVX134c2bQFmnvhaB3x+qH52e2psNfBIu7R1DXBqksPajfxTgWvatkeTrG59nb3HsUb1IUmagiUTPPbPAb8G3JLkplb7z8AHgE8lORf4NvDmtu1q4AxgB/A4cA5AVe1O8l7ghtbuwqra3dbfCVwOHAx8oS3M0YckaQomFi5V9VUgs2w+ZUT7As6b5VgbgY0j6tuBY0fUHxrVhyRpOvyEviSpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1N7FwSbIxyYNJbh2qXZDk3iQ3teWMoW3/KcmOJN9KctpQfU2r7Uhy/lD9lUmub/WrkhzU6j/SXu9o21dM6j1Kkkab5JnL5cCaEfWLquq4tlwNkOQY4Czgp9s+v5vkgCQHAL8DnA4cA7y1tQX4YDvWTwIPA+e2+rnAw61+UWsnSZqiiYVLVX0F2D1m87XAlVX1RFX9DbADOLEtO6rqrqr6O+BKYG2SAL8IfKbtvwl4w9CxNrX1zwCntPaSpCmZj3su70pyc7tsdlirHQncM9RmZ6vNVn858P+q6sk96s84Vtv+SGv/LEnWJ9meZPuuXbue/zuTJAHTD5dLgJ8AjgPuAz4y5f6foaourapVVbVq2bJl8zkUSVpQphouVfVAVT1VVT8Afo/BZS+Ae4Gjhpoub7XZ6g8BhyZZskf9Gcdq21/a2kuSpmSq4ZLkiKGXvwLMPEm2BTirPen1SmAl8A3gBmBlezLsIAY3/bdUVQHXAme2/dcBnx861rq2fibwpdZekjQlS/beZN8k+SRwMrA0yU5gA3BykuOAAu4G3gFQVbcl+RRwO/AkcF5VPdWO8y7gGuAAYGNV3da6+I/AlUneB3wTuKzVLwOuSLKDwQMFZ03qPUqSRptYuFTVW0eULxtRm2n/fuD9I+pXA1ePqN/F05fVhuvfB970nAYrSerKT+hLkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrqb2Cf0Jb1w/N8LXzXfQ9AL0NHvuWVixx7rzCXJtnFqkiTBXs5ckvwo8GMMJp88DJj5RsdDePrLuSRJeoa9XRZ7B/Bu4BXAjTwdLo8CH5vguCRJ+7E5w6Wqfhv47SS/UVUfndKYJEn7ubFu6FfVR5O8FlgxvE9VbZ7QuCRJ+7GxwiXJFcBPADcBT7VyAYaLJOlZxn0UeRVwjF8XLEkax7gforwV+PuTHIgkaeEY98xlKXB7km8AT8wUq+qXJzIqSdJ+bdxwuWCSg5AkLSzjPi32F5MeiCRp4Rj3abHvMng6DOAg4EDge1V1yKQGJknaf4175vKSmfUkAdYCqyc1KEnS/u05T7lfA38CnDaB8UiSFoBxL4u9cejlixh87uX7ExmRJGm/N+7TYq8fWn8SuJvBpTFJkp5l3Hsu50x6IJKkhWPcLwtbnuRzSR5sy2eTLJ/04CRJ+6dxb+j/AbCFwfe6vAL401aTJOlZxg2XZVX1B1X1ZFsuB5ZNcFySpP3YuOHyUJJfTXJAW34VeGiSA5Mk7b/GDZd/AbwZuB+4DzgTeNuExiRJ2s+N+yjyhcC6qnoYIMnLgA8zCB1Jkp5h3DOXV88EC0BV7QZeM5khSZL2d+OGy4uSHDbzop25jHvWI0laZMYNiI8AX0/y6fb6TcD7JzMkSdL+bqwzl6raDLwReKAtb6yqK+baJ8nG9oHLW4dqL0uyNcmd7edhrZ4kFyfZkeTmJMcP7bOutb8zybqh+glJbmn7XNxma561D0nS9Iw9K3JV3V5VH2vL7WPscjmwZo/a+cC2qloJbGuvAU4HVrZlPXAJ/PDy2wbgJOBEYMNQWFwCvH1ovzV76UOSNCXPecr9cVXVV4Dde5TXApva+ibgDUP1zW06/+uAQ5McwWBa/61Vtbs9ULAVWNO2HVJV11VVAZv3ONaoPiRJUzKxcJnF4VV1X1u/Hzi8rR8J3DPUbmerzVXfOaI+Vx/PkmR9ku1Jtu/atWsf3o4kaZRph8sPtTOO2mvDCfZRVZdW1aqqWrVsmbPZSFIv0w6XB9olLdrPB1v9XuCooXbLW22u+vIR9bn6kCRNybTDZQsw88TXOuDzQ/Wz21Njq4FH2qWta4BTkxzWbuSfClzTtj2aZHV7SuzsPY41qg9J0pRM7IOQST4JnAwsTbKTwVNfHwA+leRc4NsM5isDuBo4A9gBPA6cA4OZAJK8F7ihtbuwzQ4A8E4GT6QdDHyhLczRhyRpSiYWLlX11lk2nTKibQHnzXKcjcDGEfXtwLEj6g+N6kOSND3zdkNfkrRwGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKm7eQmXJHcnuSXJTUm2t9rLkmxNcmf7eVirJ8nFSXYkuTnJ8UPHWdfa35lk3VD9hHb8HW3fTP9dStLiNZ9nLq+rquOqalV7fT6wrapWAtvaa4DTgZVtWQ9cAoMwAjYAJwEnAhtmAqm1efvQfmsm/3YkSTNeSJfF1gKb2vom4A1D9c01cB1waJIjgNOArVW1u6oeBrYCa9q2Q6rquqoqYPPQsSRJUzBf4VLA/0hyY5L1rXZ4Vd3X1u8HDm/rRwL3DO27s9Xmqu8cUZckTcmSeer356vq3iR/D9ia5K+GN1ZVJalJD6IF23qAo48+etLdSdKiMS9nLlV1b/v5IPA5BvdMHmiXtGg/H2zN7wWOGtp9eavNVV8+oj5qHJdW1aqqWrVs2bLn+7YkSc3UwyXJi5O8ZGYdOBW4FdgCzDzxtQ74fFvfApzdnhpbDTzSLp9dA5ya5LB2I/9U4Jq27dEkq9tTYmcPHUuSNAXzcVnscOBz7engJcAfVdUXk9wAfCrJucC3gTe39lcDZwA7gMeBcwCqaneS9wI3tHYXVtXutv5O4HLgYOALbZEkTcnUw6Wq7gJ+ZkT9IeCUEfUCzpvlWBuBjSPq24Fjn/dgJUn75IX0KLIkaYEwXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpuwUbLknWJPlWkh1Jzp/v8UjSYrIgwyXJAcDvAKcDxwBvTXLM/I5KkhaPBRkuwInAjqq6q6r+DrgSWDvPY5KkRWPJfA9gQo4E7hl6vRM4ac9GSdYD69vLx5J8awpjWyyWAt+Z70G8EOTD6+Z7CHomfzdnbEiPo/yDUcWFGi5jqapLgUvnexwLUZLtVbVqvsch7cnfzelYqJfF7gWOGnq9vNUkSVOwUMPlBmBlklcmOQg4C9gyz2OSpEVjQV4Wq6onk7wLuAY4ANhYVbfN87AWGy836oXK380pSFXN9xgkSQvMQr0sJkmaR4aLJKk7w0X7bG9T7CT5kSRXte3XJ1kx/VFqMUqyMcmDSW6dZXuSXNx+N29Ocvy0x7jQGS7aJ2NOsXMu8HBV/SRwEfDB6Y5Si9jlwJo5tp8OrGzLeuCSKYxpUTFctK/GmWJnLbCprX8GOCVJl48ES3Opqq8Au+doshbYXAPXAYcmOWI6o1scDBftq1FT7Bw5W5uqehJ4BHj5VEYnzW2c3189D4aLJKk7w0X7apwpdn7YJskS4KXAQ1MZnTQ3p4iaMMNF+2qcKXa2ADNTAp8JfKn81K5eGLYAZ7enxlYDj1TVffM9qIVkQU7/osmbbYqdJBcC26tqC3AZcEWSHQxurp41fyPWYpLkk8DJwNIkO4ENwIEAVfVx4GrgDGAH8DhwzvyMdOFy+hdJUndeFpMkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hosWhCQvT3JTW+5Pcu/Q64P2su+qJBc/j77fluRje2lzcpLX7msf7RhfTrKqrV+d5NA52r47yY/Nsf33ZyYaTfLYcxzHcUnOGHr9y6Nmxdbi5udctCBU1UPAcQBJLgAeq6oPz2xPsqTNbzZq3+3A9gkP8WTgMeBrPQ5WVWfspcm7gU8w+AzHMyQ5oKr+5fPo/jhgFYPPitA+07TnB2i1yHnmogUryeVJPp7keuBDSU5M8vUk30zytST/sLU7OcmftfUL2neBfDnJXUn+9SzHPifJXyf5BvBzQ/XXt++u+WaS/5nk8PY9Nv8K+DftTOoXRrUb0cfBSa5MckeSzwEHD227O8nSJC9O8udJ/jLJrUne0sb8CuDaJNe29o8l+UiSvwR+dvgsqG2/KMltSbYlWdZqw2dKS1ufBwEXAm9p7+Utw2duSVYk+VL7jpRtSY4e+ru4uP2535XkzH37W9X+wnDRQrcceG1V/Vvgr4BfqKrXAO8B/uss+/wj4DQGXyuwIcmBwxvb1Oz/hUGo/DyD77OZ8VVgdevjSuA/VNXdwMeBi6rquKr6X6PajRjHrwOPV9U/ZvAJ8xNGtFkD/G1V/UxVHQt8saouBv4WeF1Vva61ezFwfWv31T2O8WIGsyr8NPAXra+R2tcrvAe4qr2Xq/Zo8lFgU1W9GvhDYPhy4xEM/rx+CfjAbH1oYfCymBa6T1fVU239pcCmJCuBok0HMsKfV9UTwBNJHgQOZzAl+4yTgC9X1S6AJFcBP9W2LQeuagF0EPA3s/QxTrt/QvvHuapuTnLziDa3AB9J8kHgz1pwjfIU8NlZtv0AmAmJTwB/PEu7cfws8Ma2fgXwoaFtf1JVPwBuH3WmpoXFMxctdN8bWn8vcG37H/7rgR+dZZ8nhtaf4rn9J+yjwMeq6lXAO+boY9x2c6qqvwaOZxAy70vynlmafn8oZPd62PbzSZ7+N2KfxreH4T9XvzRugTNctJi8lKenVX/b8zjO9cA/bU+oHQi8aZY+1g3Vvwu8ZIx2w74C/DOAJMcCr96zQZJXMLh09gngtxgEzaj+5vIiBrNW0/qbuWx2N09fihu+RzLXsb/G0xOU/nNgtjMpLXCGixaTDwH/Lck3eR6XhNvU7BcAXwf+N3DH0OYLgE8nuRH4zlD9T4FfmbmhP0e7YZcAP57kDgY30W8c0eZVwDeS3MTgXsn7Wv1S4IszN/T34nvAiUluBX6x9QXwYeDX25/X0qH21wLHzNzQ3+NYvwGc0y7h/Rrwm2P0rwXIWZElSd155iJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpu/8PZRlraFFX9X0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRFMnavcvd4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e72bdc3f-3e59-4d81-8b66-831f88606b8d"
      },
      "source": [
        "sns.countplot(valid_df['is_duplicate'])\n",
        "plt.xlabel('Valid data distribution')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Valid data distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_-LHvVDugGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df[train_df['is_duplicate'] == 1]\n",
        "valid_data = valid_df[valid_df['is_duplicate'] == 1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10cH7StSurn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "520686da-fddf-4e96-9d87-d42ab0972f47"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>106969</td>\n",
              "      <td>147570</td>\n",
              "      <td>787.0</td>\n",
              "      <td>What is the best self help book you have read?...</td>\n",
              "      <td>What are the top self help books I should read?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>233239</td>\n",
              "      <td>71243</td>\n",
              "      <td>177376.0</td>\n",
              "      <td>What will be Hillary Clinton's policy towards ...</td>\n",
              "      <td>What will be Hilary Clinton's policy towards I...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11568</td>\n",
              "      <td>22332</td>\n",
              "      <td>22333.0</td>\n",
              "      <td>Which is the best book to study TENSOR for gen...</td>\n",
              "      <td>Which is the best book for tensor calculus?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... is_duplicate\n",
              "1   402555  ...          1.0\n",
              "3   150662  ...          1.0\n",
              "7   106969  ...          1.0\n",
              "11  233239  ...          1.0\n",
              "13   11568  ...          1.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AeZx1RnutBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f7ab8ae-54ab-47bc-85e6-f1f445599123"
      },
      "source": [
        "len(train_data), len(valid_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134141, 14857)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKdSgBanv3a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data[['question1', 'question2']]\n",
        "valid_data = valid_data[['question1', 'question2']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O82uUq1Av9a7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "73be5770-29c3-4854-a65b-ea8e58e525af"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the best self help book you have read?...</td>\n",
              "      <td>What are the top self help books I should read?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What will be Hillary Clinton's policy towards ...</td>\n",
              "      <td>What will be Hilary Clinton's policy towards I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Which is the best book to study TENSOR for gen...</td>\n",
              "      <td>Which is the best book for tensor calculus?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question1                                          question2\n",
              "1                 How do I control my horny emotions?                 How do you control your horniness?\n",
              "3                         What can one do after MBBS?                       What do i do after my MBBS ?\n",
              "7   What is the best self help book you have read?...    What are the top self help books I should read?\n",
              "11  What will be Hillary Clinton's policy towards ...  What will be Hilary Clinton's policy towards I...\n",
              "13  Which is the best book to study TENSOR for gen...        Which is the best book for tensor calculus?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mliL5MIguvIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_train_data = train_data.sample(50000)\n",
        "sample_valid_data = valid_data.sample(5000)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ywMJKNcvxs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_train_data.to_csv('train_ds.csv')\n",
        "sample_valid_data.to_csv('valid_ds.csv')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCdZEwhyNWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a9dbce07-898d-4469-aaa0-a875992d6774"
      },
      "source": [
        "!ls -lah"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 97M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 19 16:14 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 19 15:44 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jun 17 16:18 .config\n",
            "drwxr-xr-x 4 root root 4.0K Jun 19 15:54 glue_data\n",
            "-rw-r--r-- 1 root root  91M Jun 19 16:14 model.pt\n",
            "drwxr-xr-x 1 root root 4.0K Jun 17 16:18 sample_data\n",
            "-rw-r--r-- 1 root root 5.5M Jun 19 16:14 train_ds.csv\n",
            "-rw-r--r-- 1 root root 559K Jun 19 16:14 valid_ds.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gJPOjrPyOj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = data.get_tokenizer('spacy')\n",
        "TEXT = data.Field(tokenize=tokenizer, lower=True, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a6oFXK4ABTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = [(None, None), (\"source\", TEXT), (\"target\", TEXT)]\n",
        "\n",
        "train_dataset, valid_dataset = data.TabularDataset.splits(path='.',\n",
        "                                     train='train_ds.csv', validation='valid_ds.csv',\n",
        "                                     format='csv', skip_header=True, fields=fields)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXkLf7THAW2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9c874e66-bbfe-4bec-da77-11b402db4e4e"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation examples: {len(valid_dataset)}\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 50000\n",
            "Number of validation examples: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTYQSNmAe9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "650d3954-945b-4dfd-c76a-0df6129b3709"
      },
      "source": [
        "print(vars(train_dataset.examples[1]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': ['if', 'hillary', 'clinton', 'wins', 'the', 'presidency', ',', 'can', 'she', 'pardon', 'herself', 'for', 'previous', 'wrong', 'doings', '?'], 'target': ['if', 'hillary', 'clinton', 'is', 'president', ',', 'and', 'the', 'fbi', 'is', 'investigating', 'her', ',', 'can', 'she', 'influence', 'the', 'fbi', 'and/or', 'give', 'herself', 'a', 'presidential', 'pardon', '?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYsumXg3AkEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_dataset, min_freq=5)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRGTLo5WAtr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4f9a999-7af7-4720-f50e-8fbdfe1b4be7"
      },
      "source": [
        "print(f\"Number of tokens in vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens in vocabulary: 8142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BsdMYtZAzQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.source),\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm7D9E6GA_o_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88c641a0-2e0c-40ad-b274-f7c3cdb0386b"
      },
      "source": [
        "# sample checking\n",
        "temp = next(iter(train_iterator))\n",
        "temp.source.shape, temp.target.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29, 64]), torch.Size([27, 64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXLuQdqHBFbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, num_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, src):\n",
        "        # src => [seq_len, batch_size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded => [seq_len, batch_size, hidden_dim]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        # outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # hidden, cell => [num_layers * num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        hidden = hidden.view(self.n_layers, 2,  -1, self.hidden_dim)\n",
        "        cell = cell.view(self.n_layers, 2,  -1, self.hidden_dim)\n",
        "        # hidden, cell => [num_layers, num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        final_forward_hidden = hidden[:, 0, :, :]\n",
        "        final_backward_hidden = hidden[:, 1, :, :]\n",
        "        # final_hiddens => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        final_forward_cell = cell[:, 0, :, :]\n",
        "        final_backward_cell = cell[:, 1, :, :]\n",
        "        # final_cells => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        combined_hidden = torch.cat((final_forward_hidden, final_backward_hidden), dim=2)\n",
        "        combined_cell = torch.cat((final_forward_cell, final_backward_cell), dim=2)\n",
        "        # combined_hidden, combined_cell => [num_layers, batch_size, hidden_dim * 2]\n",
        "\n",
        "        decoder_initial_hidden = self.fc(combined_hidden)\n",
        "        decoder_initial_cell = self.fc(combined_cell)\n",
        "        # decoder_initial_states => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        return decoder_initial_hidden, decoder_initial_cell"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgkExAqJu2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input => [seq_len, batch_size, emb_dim]\n",
        "        #       => [1, batch_size, emb_dim]\n",
        "        # hidden => [num_layers, batch_size, hidden_dim]\n",
        "        # cell => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(input, (hidden, cell))\n",
        "        # output => [1, batch_size, hidden_dim]\n",
        "        # hidden => [num_layers, batch_size, hidden_dim]\n",
        "        # cell => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        logits = self.fc(self.dropout(output.squeeze(0)))\n",
        "        # logits => [batch_size, output_dim]\n",
        "\n",
        "        return logits, hidden, cell\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtDaN2auLgnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "    \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        # src => [seq_len, batch_size]\n",
        "        # trg => [trg_len, batch_size]\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.input_dim\n",
        "\n",
        "        # outputs: to store the predictions of the decoder\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "        # hidden, cell => [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        dec_inp = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            dec_inp_emb = self.encoder.embedding(dec_inp.unsqueeze(0))\n",
        "            # dec_inp_emb => [1, batch_size, emb_dim]\n",
        "            output, hidden, cell = self.decoder(dec_inp_emb, hidden, cell)\n",
        "\n",
        "            # save the output\n",
        "            outputs[t] = output\n",
        "\n",
        "            # to decide whether to use teacher force or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            dec_inp = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJBaAbUIZkim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
        "dec = Decoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKiL1QFkZ6-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "5081d7ec-a8f4-4839-fab0-019304f2029e"
      },
      "source": [
        "def init_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(8142, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=512, out_features=8142, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsffvAd9Z9HZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0dd3d8d5-8231-4134-fe16-86152496147c"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model)} trainable parameters')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 19917774 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKJVBVVYaA4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwwYilMhaIvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, criterion, optimizer, clip):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # keep the model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over train data\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.source\n",
        "        trg = batch.target\n",
        "        # src => [seq_len, batch_size]\n",
        "        # trg => [seq_len, batch_size]\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        output = model(src, trg)\n",
        "\n",
        "        # reshaping the output to make it compatible to cal. loss\n",
        "        # can also do without reshaping\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient clipping \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        # update the parameters of the model\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the loss\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBqPmArEaRHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    # keep the model in eval mode\n",
        "    model.eval()\n",
        "    \n",
        "    # do not calculate gradients\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # iterate over the data\n",
        "        for batch in iterator:\n",
        "            src = batch.source\n",
        "            trg = batch.target\n",
        "            # src => [seq_len, batch_size]\n",
        "            # trg => [seq_len, batch_size]\n",
        "\n",
        "            # forward pass\n",
        "            # make sure the teacher_forcing_ratio is 0 in eval\n",
        "            output = model(src, trg, 0)\n",
        "\n",
        "            # reshaping for loss calculation\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # loss\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # update loss\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UI1XDgZbdNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAPOg24bi5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "aced2a97-6db4-4a08-c1bc-971bf92da19f"
      },
      "source": [
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, criterion, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f\"Epoch {epoch + 1} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} |\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:.3f} | Valid PPL: {math.exp(valid_loss):7.3f} |\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Time: 3m 50.459569692611694s\n",
            "\tTrain Loss: 4.880 | Train PPL: 131.647 |\n",
            "\tValid Loss: 4.678 | Valid PPL: 107.600 |\n",
            "Epoch 2 | Time: 3m 50.4044885635376s\n",
            "\tTrain Loss: 4.148 | Train PPL:  63.304 |\n",
            "\tValid Loss: 4.338 | Valid PPL:  76.536 |\n",
            "Epoch 3 | Time: 3m 50.281089544296265s\n",
            "\tTrain Loss: 3.800 | Train PPL:  44.720 |\n",
            "\tValid Loss: 4.143 | Valid PPL:  62.983 |\n",
            "Epoch 4 | Time: 3m 49.98819971084595s\n",
            "\tTrain Loss: 3.555 | Train PPL:  34.998 |\n",
            "\tValid Loss: 4.039 | Valid PPL:  56.754 |\n",
            "Epoch 5 | Time: 3m 50.10717558860779s\n",
            "\tTrain Loss: 3.373 | Train PPL:  29.173 |\n",
            "\tValid Loss: 3.907 | Valid PPL:  49.751 |\n",
            "Epoch 6 | Time: 3m 51.846423625946045s\n",
            "\tTrain Loss: 3.232 | Train PPL:  25.321 |\n",
            "\tValid Loss: 3.859 | Valid PPL:  47.411 |\n",
            "Epoch 7 | Time: 3m 51.39446544647217s\n",
            "\tTrain Loss: 3.102 | Train PPL:  22.249 |\n",
            "\tValid Loss: 3.781 | Valid PPL:  43.841 |\n",
            "Epoch 8 | Time: 3m 51.10394048690796s\n",
            "\tTrain Loss: 3.018 | Train PPL:  20.458 |\n",
            "\tValid Loss: 3.723 | Valid PPL:  41.373 |\n",
            "Epoch 9 | Time: 3m 51.94336795806885s\n",
            "\tTrain Loss: 2.904 | Train PPL:  18.250 |\n",
            "\tValid Loss: 3.736 | Valid PPL:  41.929 |\n",
            "Epoch 10 | Time: 3m 51.546207427978516s\n",
            "\tTrain Loss: 2.831 | Train PPL:  16.958 |\n",
            "\tValid Loss: 3.693 | Valid PPL:  40.156 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVogxl-_dPzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}