{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Names.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1opZ4d/6dMtotJzSss3Md",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fgeneration/applications/generation/Generating%20Names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_djaw6xsObl4",
        "colab_type": "text"
      },
      "source": [
        "# Generating Names with LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVwRsMpDcdv",
        "colab_type": "text"
      },
      "source": [
        "Given a starting character, generate a name starting with that character. \n",
        "\n",
        "We’ll train LSTM character-level language model. That is, we’ll give the LSTM a huge chunk of names and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new name one character at a time.\n",
        "\n",
        "![arch](https://drive.google.com/uc?id=1G8Oh6WUeShjXSEWfMv45sCxsaio-fNnM)\n",
        "\n",
        "As a working example, suppose we only had a vocabulary of all alphabets in English, and wanted to train an RNN on the training sequence \"Jennie\". This training sequence is in fact a source of 5 separate training examples: \n",
        "1. The probability of `e` should be likely given the context of `J`, \n",
        "2. `n` should be likely in the context of `Je`, \n",
        "3. `n` should also be likely given the context of `Jen`,\n",
        "4. `i` should also be likely given the context of `Jenn`, \n",
        "and finally \n",
        "5. `e` should be likely given the context of `Jenni`.\n",
        "\n",
        "#### Resources\n",
        "\n",
        "- [Unreasonable effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "- [Language Modelling - ChunML](https://github.com/ChunML/NLP/blob/master/text_generation/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-Gg2T6Oh-G",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset I used is [Us Baby Names](https://www.kaggle.com/kaggle/us-baby-names?select=NationalNames.csv)  present in kaggle.\n",
        "\n",
        "I have downloaded the dataset and kept it in google drive for ease of use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C01kpHFqUaDO",
        "colab_type": "code",
        "outputId": "1ec798c0-6ee0-4959-adb8-27598bc871f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwx-dRFwUrmR",
        "colab_type": "code",
        "outputId": "0109f059-286b-4474-91e4-9ff933d92383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "datapath = './drive/My\\ Drive/NationalNames.csv.zip'\n",
        "!unzip {datapath}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./drive/My Drive/NationalNames.csv.zip\n",
            "  inflating: NationalNames.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9C7OmvtVFA9",
        "colab_type": "code",
        "outputId": "d51af119-6265-4020-ac2b-772caa021849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  NationalNames.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpguP1BGPNYi",
        "colab_type": "text"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Td-COYS3wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bAaJuFqzOoi",
        "colab_type": "code",
        "outputId": "f57b77df-6ef4-4d92-8063-c0048d757564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('NationalNames.csv')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Year</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Mary</td>\n",
              "      <td>1880</td>\n",
              "      <td>F</td>\n",
              "      <td>7065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Anna</td>\n",
              "      <td>1880</td>\n",
              "      <td>F</td>\n",
              "      <td>2604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Emma</td>\n",
              "      <td>1880</td>\n",
              "      <td>F</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Elizabeth</td>\n",
              "      <td>1880</td>\n",
              "      <td>F</td>\n",
              "      <td>1939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Minnie</td>\n",
              "      <td>1880</td>\n",
              "      <td>F</td>\n",
              "      <td>1746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id       Name  Year Gender  Count\n",
              "0   1       Mary  1880      F   7065\n",
              "1   2       Anna  1880      F   2604\n",
              "2   3       Emma  1880      F   2003\n",
              "3   4  Elizabeth  1880      F   1939\n",
              "4   5     Minnie  1880      F   1746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IKnco19zTci",
        "colab_type": "code",
        "outputId": "be276953-e443-4d21-f4b8-4eacd2b1929b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1825433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfdMLHeKQugu",
        "colab_type": "text"
      },
      "source": [
        "Since there are nearly 2 million values, I am considering the names which occur atleast 1000 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPVCWJcHQfNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df[df['Count'] > 1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NirxG_lYQoDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7c0fc49-31cc-4fa9-c3f1-bfd90091e5b0"
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNbwNvT0Q95P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "84012f19-f461-421b-8eb7-f8ef7e71e4eb"
      },
      "source": [
        "## Dropping other columns as they are not useful\n",
        "df2 = df2[['Name']]\n",
        "df2.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elizabeth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Minnie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Name\n",
              "0       Mary\n",
              "1       Anna\n",
              "2       Emma\n",
              "3  Elizabeth\n",
              "4     Minnie"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlJoE0EHPfM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df2['Name'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KBbR7mU0Vi5",
        "colab_type": "code",
        "outputId": "c27aafc6-e478-4146-d794-eb814f63c68c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Number of training examples: {len(X_train)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 50464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62d7mLBq0t7m",
        "colab_type": "code",
        "outputId": "ce96fb0e-206c-4e60-c56e-46f188aa7675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"input = {X_train[0]}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = Mary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkOl3VoyRVPn",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulary\n",
        "\n",
        "Since all names are not of equal length, we have to `pad` the shorter ones. For that $<pad>$ token is required. \n",
        "\n",
        "In order to indicate the end of a word $<eos>$ token is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6hjnwdESodZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab():\n",
        "    all_letters = string.ascii_letters\n",
        "    char2id = {}\n",
        "    char2id['<pad>'] = 0\n",
        "    char2id['<eos>'] = 1\n",
        "    for i, char in enumerate(all_letters):\n",
        "        char2id[char] = i + 2\n",
        "    return char2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boiNFZEdTGTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2id = build_vocab()\n",
        "id2char = {id: char for char, id in char2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUcPBSh_09CF",
        "colab_type": "code",
        "outputId": "99deba76-598e-4315-d555-b8dee59dec88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "char2id"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<eos>': 1,\n",
              " '<pad>': 0,\n",
              " 'A': 28,\n",
              " 'B': 29,\n",
              " 'C': 30,\n",
              " 'D': 31,\n",
              " 'E': 32,\n",
              " 'F': 33,\n",
              " 'G': 34,\n",
              " 'H': 35,\n",
              " 'I': 36,\n",
              " 'J': 37,\n",
              " 'K': 38,\n",
              " 'L': 39,\n",
              " 'M': 40,\n",
              " 'N': 41,\n",
              " 'O': 42,\n",
              " 'P': 43,\n",
              " 'Q': 44,\n",
              " 'R': 45,\n",
              " 'S': 46,\n",
              " 'T': 47,\n",
              " 'U': 48,\n",
              " 'V': 49,\n",
              " 'W': 50,\n",
              " 'X': 51,\n",
              " 'Y': 52,\n",
              " 'Z': 53,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnwYc4d3R1Qz",
        "colab_type": "text"
      },
      "source": [
        "## Dataset (For Loader)\n",
        "\n",
        "As discussed, for each input character in the sequence the target will be next character in the sequence. The dataset should return the `input_seq` as well as `target_seq`\n",
        "\n",
        "Three methods are compulsory when declaring a `dataset`:\n",
        "- **`__init__`**: Load all the data and calculate the length of the data\n",
        "- **`__getitem__`**: Return the requested datapoint. *Can perform all the data processing steps here*\n",
        "- **`__len__`**: Return the length of the dataset\n",
        "\n",
        "Since I am using Names for the generation problem, I will be creating a **`NamesDataset`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqzvYWsaS1Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NamesDataset(Dataset):\n",
        "    def __init__(self, names, char2id):  \n",
        "        self.input = names\n",
        "        self.length = len(names)\n",
        "        self.char2id = char2id\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        input_data = self.input[index]\n",
        "        input_seq, target_seq = self.preprocess(input_data)\n",
        "        return input_seq, target_seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def preprocess(self, input):\n",
        "        # convert the character input to numerical input by using vocabulary\n",
        "        input_seq = [self.char2id[input[li]] for li in range(len(input))]\n",
        "\n",
        "        # create the target seq by skipping the first element in the input and adding <eos> at the end\n",
        "        target_seq = [self.char2id[input[li]] for li in range(1, len(input))] + [self.char2id['<eos>']]\n",
        "        return torch.Tensor(input_seq), torch.Tensor(target_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v8FB3ldatiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's check the dataset\n",
        "temp_data = NamesDataset(X_train, char2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGcjlJREayTi",
        "colab_type": "code",
        "outputId": "f6fd9842-2a8c-48e4-e911-3ccaa06923ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp_data[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([28., 15., 15.,  2.]), tensor([15., 15.,  2.,  1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ycxjY7SVdRG",
        "colab_type": "text"
      },
      "source": [
        "Sorting the elements by their size will reduce the amount of padding required. In-order to do that, we can define a `collate_fn` which takes in the data and sort according the input length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PVaIntnU_oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "        return padded_seqs, lengths\n",
        "\n",
        "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    # seperate source and target sequences\n",
        "    src_seqs, trg_seqs = zip(*data)\n",
        "\n",
        "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
        "    src_seqs, src_lengths = merge(src_seqs)\n",
        "    trg_seqs, trg_lengths = merge(trg_seqs)\n",
        "\n",
        "    return src_seqs, trg_seqs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzFA6kfn_ZUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Lp1et3QTZC",
        "colab_type": "text"
      },
      "source": [
        "## Data Loader\n",
        "\n",
        "Data loader makes the dataset iterable with each iteration containing the `batch_size`. We have to pass the **`collate_fn`** while declaring the dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9hI3GDuVZbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loader(data, char2id, train=True, batch_size=BATCH_SIZE):\n",
        "    # build a custom dataset\n",
        "    dataset = NamesDataset(data, char2id)\n",
        "\n",
        "    # data loader for custom dataset\n",
        "    # this will return (src_seqs, trg_seqs) for each iteration\n",
        "    # please see collate_fn for details\n",
        "    if train:\n",
        "        shuffle=True\n",
        "    else:\n",
        "        shuffle=False\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=shuffle,\n",
        "                                              collate_fn=collate_fn)\n",
        "\n",
        "    return data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1xVZYYOWC-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = get_loader(X_train, char2id, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH4MSyYXmW5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_iter = iter(train_data_loader)\n",
        "src_seqs, trg_seqs = next(data_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av3EeK5qmfC1",
        "colab_type": "code",
        "outputId": "29f68070-1755-4f55-972e-bdc56680e369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "src_seqs.shape, trg_seqs.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 9]), torch.Size([64, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64yVn202Q0xw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f08ad50-493b-44f1-b143-20b98a43e107"
      },
      "source": [
        "src_seqs[0], trg_seqs[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([37, 16, 20,  6, 17,  9, 10, 15,  6]),\n",
              " tensor([16, 20,  6, 17,  9, 10, 15,  6,  1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwNkQLehQ5Or",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "The model we will be using is a Character LSTM i.e it takes characters as input and predicts a character over the distribution.\n",
        "\n",
        "![arch](https://drive.google.com/uc?id=1G8Oh6WUeShjXSEWfMv45sCxsaio-fNnM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5YOC_sKIUdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, emb_size, hidden_size, output_size, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, emb_size, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    \n",
        "    def forward(self, input, prev_state):\n",
        "        # input => [batch_size, seq_len]\n",
        "        # prev_state => (h, c)\n",
        "        #            => h - [1, batch_size, hid_dim]\n",
        "        #            => c - [1, batch_size, hid_dim]\n",
        "\n",
        "        embedded = self.embedding(input)\n",
        "        # embedded => [batch_size, seq_len, emb_size]\n",
        "\n",
        "        output, state = self.rnn(embedded, prev_state)\n",
        "        # output => [batch_size, seq_len, hid_dim]\n",
        "        # state => (h, c)\n",
        "        #           h => (n_layers, batch_size, hid_dim)\n",
        "        #           c => (n_layers, batch_size, hid_dim)\n",
        "    \n",
        "        logits = self.out(self.dropout(output))\n",
        "        # logits => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return logits, state\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # initial hidden state\n",
        "\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYtZohuuhEsV",
        "colab_type": "code",
        "outputId": "9d79c707-4f4b-44b6-f92b-bbb32e53a81e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "INPUT_DIM = len(char2id)\n",
        "EMBEDDING_DIM = 10\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = len(char2id)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = char2id['<pad>']\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
        "model"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(54, 10, padding_idx=0)\n",
              "  (rnn): LSTM(10, 256, batch_first=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (out): Linear(in_features=256, out_features=54, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G3gvofThgG5",
        "colab_type": "code",
        "outputId": "a02495fc-ae97-4547-9474-8c1dd2b558ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model)} trainable paramters')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 288850 trainable paramters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apbYk_dFRQTn",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer & Criterion\n",
        "\n",
        "We use the **`Adam`** optimizer as it shows better optimization compared to `SGD`.\n",
        "\n",
        "**`CrossEntropyLoss`**: This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class. It is useful when training a classification problem with C classes. Ignore the `<pad>` index as it does not contribute to loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CXZA1biGef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKXrADH4Uyl6",
        "colab_type": "text"
      },
      "source": [
        "## Generate Names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3LF-cTrHDxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model, initial_letter, n_letters, char2id, id2char, pad_token, eos_token, top_k=5):\n",
        "    model.eval()\n",
        "\n",
        "    # initial character of the word\n",
        "    word = initial_letter\n",
        "\n",
        "    state_h, state_c = model.init_hidden(1)\n",
        "\n",
        "    # convert the character to index    \n",
        "    choice = char2id[initial_letter]\n",
        "\n",
        "    # run the LSTM model for a maximum of `n_letters` steps\n",
        "    for _ in range(n_letters):\n",
        "        ix = torch.tensor([[choice]])\n",
        "\n",
        "        # forward pass\n",
        "        output, (state_h, state_c) = model(ix, (state_h, state_c))\n",
        "\n",
        "        # get the top_k values from the predictions\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "\n",
        "        # randomly choose from the top_k values\n",
        "        # if the max value is chosen all the time means it is greedy search\n",
        "        choice = np.random.choice(choices[0])\n",
        "\n",
        "        # if the choice indicates the <eos> token means, stop the loop\n",
        "        if choice == eos_token:\n",
        "            break\n",
        "        \n",
        "        # if the choice is <pad> token means, ignore it\n",
        "        if choice == pad_token:\n",
        "            continue\n",
        "    \n",
        "        # add the character to the name\n",
        "        word += id2char[choice]\n",
        "\n",
        "    print(f\"GENERATED NAME: {word}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWIZjQRYU1Px",
        "colab_type": "text"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIYDpskkoc4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    epoch_loss = 0\n",
        "    iteration = 0\n",
        "    for batch in iterator:\n",
        "        x, y = batch\n",
        "        # x => names - [batch_size, seq_len]\n",
        "        # y => targets: names shifted by 1 char and <eos> at the end - [batch_size, seq_len]\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        iteration += 1\n",
        "\n",
        "        # initialize hidden state\n",
        "        state_h, state_c = model.init_hidden(batch_size)    \n",
        "        # state_h => [1, batch_size, hid_dim]\n",
        "        # state_c => [1, batch_size, hid_dim]\n",
        "\n",
        "        # keep the model in train mode\n",
        "        model.train()\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "        # logits => [batch_size, seq_len, hid_dim]\n",
        "\n",
        "        # transpose the logits, so that it will be compatible to cal. loss\n",
        "        # transposed logits => [batch_size, hid_dim, seq_len]\n",
        "        #               y   => [batch_size, seq_len]\n",
        "        loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # detach the states, since the batches are not connected.\n",
        "        # otherwise states will carried over next batches and backward pass will take too much time\n",
        "        state_h = state_h.detach()\n",
        "        state_c = state_c.detach()\n",
        "\n",
        "        # clip the gradients above a certain value to handle explosion gradient problem\n",
        "        _ = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(), clip)\n",
        "        \n",
        "        # update the paramteres of the model\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # log the loss for every 100 iterations\n",
        "        if iteration % 100 == 0:\n",
        "            print(f'Iteration: {iteration}, Loss: {loss.item()}')\n",
        "        \n",
        "        # generate a word for every 500 iterations\n",
        "        if iteration % 500 == 0:\n",
        "            generate(model, 'J', 10, char2id, id2char, char2id['<pad>'], char2id['<eos>'], top_k=5)\n",
        "    \n",
        "    # return the loss\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kZDXnLuVLil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io--5nCnp-YK",
        "colab_type": "code",
        "outputId": "5769bc86-5924-4243-e429-c9b52a1cdbf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "MAX_CLIP_GRADIENT = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_data_loader, optimizer, criterion, MAX_CLIP_GRADIENT)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'Train Loss: {train_loss:.3f}')\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100, Loss: 2.567448139190674\n",
            "Iteration: 200, Loss: 2.2804269790649414\n",
            "Iteration: 300, Loss: 2.2448203563690186\n",
            "Iteration: 400, Loss: 2.035532236099243\n",
            "Iteration: 500, Loss: 2.0230836868286133\n",
            "GENERATED NAME: Jesronyelye\n",
            "Iteration: 600, Loss: 1.874259114265442\n",
            "Iteration: 700, Loss: 1.8168166875839233\n",
            "Epoch: 01 | Epoch Time: 0m 29.160451412200928s\n",
            "Train Loss: 2.156\n",
            "Iteration: 100, Loss: 1.7658997774124146\n",
            "Iteration: 200, Loss: 1.4835509061813354\n",
            "Iteration: 300, Loss: 1.4833662509918213\n",
            "Iteration: 400, Loss: 1.4772356748580933\n",
            "Iteration: 500, Loss: 1.4238742589950562\n",
            "GENERATED NAME: Jearrynt\n",
            "Iteration: 600, Loss: 1.3643320798873901\n",
            "Iteration: 700, Loss: 1.1794513463974\n",
            "Epoch: 02 | Epoch Time: 0m 29.020665645599365s\n",
            "Train Loss: 1.435\n",
            "Iteration: 100, Loss: 1.1719890832901\n",
            "Iteration: 200, Loss: 1.1589194536209106\n",
            "Iteration: 300, Loss: 1.280555248260498\n",
            "Iteration: 400, Loss: 1.1393224000930786\n",
            "Iteration: 500, Loss: 1.1151059865951538\n",
            "GENERATED NAME: Janobene\n",
            "Iteration: 600, Loss: 1.1660703420639038\n",
            "Iteration: 700, Loss: 1.1107678413391113\n",
            "Epoch: 03 | Epoch Time: 0m 28.976943492889404s\n",
            "Train Loss: 1.151\n",
            "Iteration: 100, Loss: 1.0677639245986938\n",
            "Iteration: 200, Loss: 1.0879329442977905\n",
            "Iteration: 300, Loss: 1.0044037103652954\n",
            "Iteration: 400, Loss: 1.0848485231399536\n",
            "Iteration: 500, Loss: 0.9727684855461121\n",
            "GENERATED NAME: Jesryy\n",
            "Iteration: 600, Loss: 0.9704950451850891\n",
            "Iteration: 700, Loss: 1.0194259881973267\n",
            "Epoch: 04 | Epoch Time: 0m 29.135944604873657s\n",
            "Train Loss: 1.039\n",
            "Iteration: 100, Loss: 0.964873194694519\n",
            "Iteration: 200, Loss: 0.9518548250198364\n",
            "Iteration: 300, Loss: 0.947180986404419\n",
            "Iteration: 400, Loss: 0.9293249249458313\n",
            "Iteration: 500, Loss: 1.0057947635650635\n",
            "GENERATED NAME: Joh\n",
            "Iteration: 600, Loss: 0.9843834042549133\n",
            "Iteration: 700, Loss: 0.9312548041343689\n",
            "Epoch: 05 | Epoch Time: 0m 29.23100209236145s\n",
            "Train Loss: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqVys3yiqVDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d5cc2ae-92d0-40b8-c11d-9b24d2009ab3"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abbGGSDkWP3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9eb5652-5ef9-4d01-a18b-9d3969c1ed30"
      },
      "source": [
        "for id in range(2, len(char2id)):\n",
        "    start_char = id2char[id]\n",
        "    print(f\"Name generated with {start_char}\")\n",
        "    generate(model, start_char, 10, char2id, id2char, char2id['<pad>'], char2id['<eos>'], top_k=5)\n",
        "    print(f\"--------------------------\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name generated with a\n",
            "GENERATED NAME: aylea\n",
            "--------------------------\n",
            "Name generated with b\n",
            "GENERATED NAME: bennarinnan\n",
            "--------------------------\n",
            "Name generated with c\n",
            "GENERATED NAME: cicahoraro\n",
            "--------------------------\n",
            "Name generated with d\n",
            "GENERATED NAME: daryescolie\n",
            "--------------------------\n",
            "Name generated with e\n",
            "GENERATED NAME: ehmol\n",
            "--------------------------\n",
            "Name generated with f\n",
            "GENERATED NAME: frayleys\n",
            "--------------------------\n",
            "Name generated with g\n",
            "GENERATED NAME: gughe\n",
            "--------------------------\n",
            "Name generated with h\n",
            "GENERATED NAME: havayda\n",
            "--------------------------\n",
            "Name generated with i\n",
            "GENERATED NAME: iridy\n",
            "--------------------------\n",
            "Name generated with j\n",
            "GENERATED NAME: janey\n",
            "--------------------------\n",
            "Name generated with k\n",
            "GENERATED NAME: kyliz\n",
            "--------------------------\n",
            "Name generated with l\n",
            "GENERATED NAME: lvebestheli\n",
            "--------------------------\n",
            "Name generated with m\n",
            "GENERATED NAME: megondarla\n",
            "--------------------------\n",
            "Name generated with n\n",
            "GENERATED NAME: nhiliphern\n",
            "--------------------------\n",
            "Name generated with o\n",
            "GENERATED NAME: oalvatta\n",
            "--------------------------\n",
            "Name generated with p\n",
            "GENERATED NAME: palrettertt\n",
            "--------------------------\n",
            "Name generated with q\n",
            "GENERATED NAME: qraydeigtny\n",
            "--------------------------\n",
            "Name generated with r\n",
            "GENERATED NAME: rooyetinall\n",
            "--------------------------\n",
            "Name generated with s\n",
            "GENERATED NAME: sirkenyro\n",
            "--------------------------\n",
            "Name generated with t\n",
            "GENERATED NAME: tola\n",
            "--------------------------\n",
            "Name generated with u\n",
            "GENERATED NAME: ussiliar\n",
            "--------------------------\n",
            "Name generated with v\n",
            "GENERATED NAME: vandetc\n",
            "--------------------------\n",
            "Name generated with w\n",
            "GENERATED NAME: wkumohalynn\n",
            "--------------------------\n",
            "Name generated with x\n",
            "GENERATED NAME: xuitnyenge\n",
            "--------------------------\n",
            "Name generated with y\n",
            "GENERATED NAME: yrokkurel\n",
            "--------------------------\n",
            "Name generated with z\n",
            "GENERATED NAME: zurenneryah\n",
            "--------------------------\n",
            "Name generated with A\n",
            "GENERATED NAME: Ambahhhl\n",
            "--------------------------\n",
            "Name generated with B\n",
            "GENERATED NAME: Brynthonyhl\n",
            "--------------------------\n",
            "Name generated with C\n",
            "GENERATED NAME: Codnando\n",
            "--------------------------\n",
            "Name generated with D\n",
            "GENERATED NAME: Danie\n",
            "--------------------------\n",
            "Name generated with E\n",
            "GENERATED NAME: Emman\n",
            "--------------------------\n",
            "Name generated with F\n",
            "GENERATED NAME: Finiso\n",
            "--------------------------\n",
            "Name generated with G\n",
            "GENERATED NAME: Gerodg\n",
            "--------------------------\n",
            "Name generated with H\n",
            "GENERATED NAME: Hunee\n",
            "--------------------------\n",
            "Name generated with I\n",
            "GENERATED NAME: Iderethette\n",
            "--------------------------\n",
            "Name generated with J\n",
            "GENERATED NAME: Jenryenthoe\n",
            "--------------------------\n",
            "Name generated with K\n",
            "GENERATED NAME: Kaiday\n",
            "--------------------------\n",
            "Name generated with L\n",
            "GENERATED NAME: Lullenaneet\n",
            "--------------------------\n",
            "Name generated with M\n",
            "GENERATED NAME: Maugerieato\n",
            "--------------------------\n",
            "Name generated with N\n",
            "GENERATED NAME: Nikiiah\n",
            "--------------------------\n",
            "Name generated with O\n",
            "GENERATED NAME: Omogiahanul\n",
            "--------------------------\n",
            "Name generated with P\n",
            "GENERATED NAME: Praceleslel\n",
            "--------------------------\n",
            "Name generated with Q\n",
            "GENERATED NAME: Qayro\n",
            "--------------------------\n",
            "Name generated with R\n",
            "GENERATED NAME: Ruseelyr\n",
            "--------------------------\n",
            "Name generated with S\n",
            "GENERATED NAME: Shonaolle\n",
            "--------------------------\n",
            "Name generated with T\n",
            "GENERATED NAME: Theomeeastt\n",
            "--------------------------\n",
            "Name generated with U\n",
            "GENERATED NAME: Uernann\n",
            "--------------------------\n",
            "Name generated with V\n",
            "GENERATED NAME: Varielinate\n",
            "--------------------------\n",
            "Name generated with W\n",
            "GENERATED NAME: Waldra\n",
            "--------------------------\n",
            "Name generated with X\n",
            "GENERATED NAME: Xiasoinhear\n",
            "--------------------------\n",
            "Name generated with Y\n",
            "GENERATED NAME: Yesreyth\n",
            "--------------------------\n",
            "Name generated with Z\n",
            "GENERATED NAME: Zua\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVGbt5VKqvE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}