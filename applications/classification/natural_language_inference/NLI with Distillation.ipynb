{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLI with Distillation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+XEfjHeAVaZxq6Ox7rNEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/natural_language_inference/NLI%20with%20Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bChD0BpGIMwF",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Inference\n",
        "\n",
        "The goal of natural language inference (NLI), a widely-studied natural language processing task, is to determine if one given statement (a premise) semantically entails another given statement (a hypothesis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rzAKQv4AUND",
        "colab_type": "text"
      },
      "source": [
        "# NLI with Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqHMZBSeAYcr",
        "colab_type": "text"
      },
      "source": [
        "**`Distillation`**: A technique you can use to compress a large model, called the `teacher`, into a smaller model, called the `student`.\n",
        "\n",
        "- [Medium blog on Distillation by Victor Sanh (Must Read)](https://medium.com/huggingface/distilbert-8cf3380435b5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXRju3STIRdA",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br_3ppk7qdRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data, datasets, vocab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7oz1RNmq5Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6HS9eAsKH_g",
        "colab_type": "text"
      },
      "source": [
        "## Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OONKSVWnKHQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e9352936-9ffd-42a1-f4a9-1e1a802611b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb9rKAsjKu9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "aeeb1e07-cec7-4e32-f514-d1429d01d6c9"
      },
      "source": [
        "!unzip \"./drive/My Drive/glove.6B.zip\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./drive/My Drive/glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf0ksB-Kzs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_file_path = \"./glove.6B.100d.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5ot8J7RL8Pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf927e78-8917-44b3-8340-8748aaf833eb"
      },
      "source": [
        "vectors = vocab.Vectors(glove_file_path, unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 398301/400001 [00:24<00:00, 17882.25it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j52oeQQcITPj",
        "colab_type": "text"
      },
      "source": [
        "## Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkiW8JTq8mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', lower = True)\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmZRkVrIUpf",
        "colab_type": "text"
      },
      "source": [
        "## SNLI (Stanford Natural Language Inference) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp_5khtprDGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SNLI.splits(TEXT, LABEL)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izph38KHrEvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9b462fc2-3571-45fd-aaf8-998d2a06579f"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 549367\n",
            "Number of validation examples: 9842\n",
            "Number of testing examples: 9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4GRwSiMrGtd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b32d5c67-4adf-40cd-9868-431111e6ade4"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'premise': ['a', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], 'hypothesis': ['a', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'label': 'neutral'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d5lFWxIc7H",
        "colab_type": "text"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4rIP6hRrIgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_FREQ = 10\n",
        "\n",
        "TEXT.build_vocab(train_data, min_freq = MIN_FREQ, vectors=vectors)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pStFCZ0rNFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b126375-d12f-46b7-f3a3-dedf623fd3f4"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 12193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNLkVCtrO5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f47e1a7-a5db-4d2c-ee7d-881f2e141634"
      },
      "source": [
        "print(LABEL.vocab.itos)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['entailment', 'contradiction', 'neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c64xop44rR1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a34ab796-1cb7-4767-a831-1f88b9492b28"
      },
      "source": [
        "print(LABEL.vocab.freqs.most_common())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('entailment', 183416), ('contradiction', 183187), ('neutral', 182764)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLUqRgO3IgAq",
        "colab_type": "text"
      },
      "source": [
        "## Data Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMDCqErSrT58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.premise),\n",
        "    device = device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-p90c-w2o9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ac91e32-b66b-41a5-a0a7-9080df92ce03"
      },
      "source": [
        "# sample check\n",
        "sample = next(iter(valid_iterator))\n",
        "sample.premise.shape, sample.hypothesis.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 128]), torch.Size([14, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nHooPDMIhuS",
        "colab_type": "text"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCoCN6smq32b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.linear = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, premise, hypothesis):\n",
        "        prem_embedded = self.dropout(self.embedding(premise))\n",
        "        hypo_embedded = self.dropout(self.embedding(hypothesis))\n",
        "        combined = torch.cat((prem_embedded, hypo_embedded), dim=0)\n",
        "        final = torch.sum(combined, dim=0)\n",
        "        outputs = self.linear(self.dropout(final))\n",
        "        return outputs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28xiyFYwt9cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "base_model = LogisticRegressionModel(\n",
        "    INPUT_DIM,\n",
        "    EMBEDDING_DIM,\n",
        "    OUTPUT_DIM,\n",
        "    DROPOUT).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUmhP-Nst_df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cb4ee30-b5ba-4f2a-93f6-c7411f10d823"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(base_model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,219,603 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krZMabTRuCn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6934389-093e-4c31-a224-eb943005ad53"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12193, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irzmhoHtuFSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "5fe9b9c3-34ac-4ab9-cf16-54ac2be0c744"
      },
      "source": [
        "base_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
              "        [-0.7534,  0.2218,  0.4468,  ...,  0.9045, -1.6214, -0.4485],\n",
              "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
              "        ...,\n",
              "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
              "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgswCKTuIEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3R-3G1ZuLVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "2ac8f138-b5d7-452e-c115-1f71c8e63608"
      },
      "source": [
        "print(base_model.embedding.weight.data)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
            "        ...,\n",
            "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
            "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
            "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz2iVmu2uOqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9d626c4f-e5bd-436d-9cd5-7eda3e0d6638"
      },
      "source": [
        "base_model"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionModel(\n",
              "  (embedding): Embedding(12193, 100)\n",
              "  (linear): Linear(in_features=100, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agVLjl0o-kbB",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Loss Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lpYiPHDuRyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(base_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oU_Mqs-rrk",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q42RQaffuV37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIPflAku-uCC",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAiMVa0muZos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        prem = batch.premise\n",
        "        hypo = batch.hypothesis\n",
        "        labels = batch.label\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(prem, hypo)\n",
        "        \n",
        "        # predictions => [batch size, output dim]\n",
        "        # labels => [batch size]\n",
        "    \n",
        "        loss = criterion(predictions, labels)            \n",
        "        acc = categorical_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGJ3t185-xBy",
        "colab_type": "text"
      },
      "source": [
        "### Validation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuuN8y7uuepn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            prem = batch.premise\n",
        "            hypo = batch.hypothesis\n",
        "            labels = batch.label\n",
        "                        \n",
        "            predictions = model(prem, hypo)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "                \n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9ZG2xVCupwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lY6dveh-1mV",
        "colab_type": "text"
      },
      "source": [
        "### Base Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awEcB93suuXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "2293488b-31b0-4e72-88e7-64cf60840395"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(base_model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(base_model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(base_model.state_dict(), 'base_model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 1.023 | Train Acc: 49.20%\n",
            "\t Val. Loss: 0.979 |  Val. Acc: 53.27%\n",
            "Epoch: 02 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.992 | Train Acc: 52.16%\n",
            "\t Val. Loss: 0.972 |  Val. Acc: 54.57%\n",
            "Epoch: 03 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.977 | Train Acc: 53.45%\n",
            "\t Val. Loss: 0.964 |  Val. Acc: 55.23%\n",
            "Epoch: 04 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.970 | Train Acc: 54.15%\n",
            "\t Val. Loss: 0.960 |  Val. Acc: 55.46%\n",
            "Epoch: 05 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.964 | Train Acc: 54.59%\n",
            "\t Val. Loss: 0.963 |  Val. Acc: 54.98%\n",
            "Epoch: 06 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.959 | Train Acc: 54.91%\n",
            "\t Val. Loss: 0.959 |  Val. Acc: 55.63%\n",
            "Epoch: 07 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.957 | Train Acc: 55.08%\n",
            "\t Val. Loss: 0.959 |  Val. Acc: 55.54%\n",
            "Epoch: 08 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.954 | Train Acc: 55.32%\n",
            "\t Val. Loss: 0.960 |  Val. Acc: 55.71%\n",
            "Epoch: 09 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.952 | Train Acc: 55.46%\n",
            "\t Val. Loss: 0.958 |  Val. Acc: 55.49%\n",
            "Epoch: 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.950 | Train Acc: 55.59%\n",
            "\t Val. Loss: 0.956 |  Val. Acc: 55.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CS7hBn4-6JV",
        "colab_type": "text"
      },
      "source": [
        "### Base Model - Test Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Qd74C1u2we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "424925b7-a97e-4f5e-b247-6e603f074544"
      },
      "source": [
        "base_model.load_state_dict(torch.load('base_model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(base_model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.962 |  Test Acc: 55.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrWH-9AHxkQ2",
        "colab_type": "text"
      },
      "source": [
        "# Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wr0riQjrXow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTMWithAttention(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, n_linear_layers, output_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pad_idx = pad_idx\n",
        "    \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, bidirectional=True, dropout=dropout)\n",
        "\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim * 2)\n",
        "        self.v = nn.Linear(hid_dim * 2, 1, bias=False)\n",
        "\n",
        "        d_model = hid_dim * 4\n",
        "        self.fcs = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(n_linear_layers)])\n",
        "        self.layer_norms = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(n_linear_layers)])\n",
        "        \n",
        "        self.out = nn.Linear(d_model, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def create_mask(self, seq):\n",
        "        # seq => [seq_len, batch_size]\n",
        "        \n",
        "        mask = (seq != self.pad_idx)\n",
        "        mask = mask.permute(1, 0)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "    def forward(self, premise, hypothesis):\n",
        "        # premise => [prem_seq_len, batch_size]\n",
        "        # hypothesis => [hypo_seq_len, batch_size]\n",
        "\n",
        "        # create input masks\n",
        "        prem_mask = self.create_mask(premise)\n",
        "        # prem_mask => [batch_size, prem_seq_len]\n",
        "        hypo_mask = self.create_mask(hypothesis)\n",
        "        # hypo_mask => [batch_size, hypo_seq_len]\n",
        "\n",
        "        embedded_prem = self.dropout(self.embedding(premise))\n",
        "        # embedded_prem => [prem_seq_len, batch_size, emb_dim]\n",
        "\n",
        "        embedded_hypo = self.dropout(self.embedding(hypothesis))\n",
        "        # embedded_hypo => [hypo_seq_len, batch_size, emb_dim]\n",
        "        \n",
        "        outputs_prem, (hidden_prem, cell_prem) = self.rnn(embedded_prem)\n",
        "        # outputs_prem => [prem_seq_len, batch_size, hid_dim * 2]\n",
        "        # hidden_prem, cell_prem => [n_layers * num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        outputs_hypo, (hidden_hypo, cell_hypo) = self.rnn(embedded_hypo)\n",
        "        # outputs_hypo => [hypo_seq_len, batch_size, hid_dim * 2]\n",
        "        # hidden_hypo, cell_hypo => [n_layers * num_dir, batch_size, hidden_dim]\n",
        "        \n",
        "        # weighted representation through attention\n",
        "        weighted_prem = self.dropout(self.attention(outputs_prem, prem_mask))\n",
        "        weighted_hypo = self.dropout(self.attention(outputs_hypo, hypo_mask))\n",
        "        # weighted => [batch_size, hid_dim * 2]\n",
        "\n",
        "        hidden = torch.cat((weighted_prem, weighted_hypo), dim=-1)\n",
        "        # hidden => [batch_size, hidden_dim * 4]\n",
        "        #        => [batch_size, d_model]\n",
        "\n",
        "        for fc, norm in zip(self.fcs, self.layer_norms):\n",
        "            hidden_ = fc(hidden)\n",
        "            hidden_ = self.dropout(hidden_)\n",
        "            # residual connection\n",
        "            hidden = hidden + F.relu(hidden_)\n",
        "            # layer normalization\n",
        "            hidden = norm(hidden)\n",
        "        \n",
        "        logits = self.out(hidden)\n",
        "        # logits => [batch_size, output_dim]\n",
        "\n",
        "        return logits\n",
        "    \n",
        "    def attention(self, outputs, mask=None):\n",
        "        # outputs => [seq_len, batch_size, hidden_dim * 2]\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        batch_size, seq_len, _ = outputs.shape\n",
        "\n",
        "        outputs_ = outputs.permute(1, 0, 2)\n",
        "        # outputs_ => [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        energy = torch.tanh(self.attn(outputs_))\n",
        "        # energy => [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        attention_energy = self.v(energy).squeeze(2)\n",
        "        # attention_energy => [batch_size, seq_len]\n",
        "\n",
        "        if mask is not None:\n",
        "            attention_energy = attention_energy.masked_fill(mask == 0, -1e10)\n",
        "            # attention_energy => [batch_size, seq_len]\n",
        "\n",
        "        scores = F.softmax(attention_energy, dim=-1)\n",
        "        # scores => [batch_size, seq_len]\n",
        "\n",
        "        scores = scores.unsqueeze(1)\n",
        "        # scores => [batch_size, 1, seq_len]\n",
        "\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "        # outputs => [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        weighted = torch.bmm(scores, outputs)\n",
        "        # weighted => [batch_size, 1, hidden_dim * 2]\n",
        "\n",
        "        weighted = weighted.squeeze(1)\n",
        "        # weighted => [batch_size, hidden_dim * 2]\n",
        "\n",
        "        return weighted"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAVQerriyVJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 200\n",
        "N_LSTM_LAYERS = 2\n",
        "N_FC_LAYERS = 3\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "teacher_model = BiLSTMWithAttention(\n",
        "    INPUT_DIM,\n",
        "    EMBEDDING_DIM,\n",
        "    HIDDEN_DIM,\n",
        "    N_LSTM_LAYERS,\n",
        "    N_FC_LAYERS,\n",
        "    OUTPUT_DIM,\n",
        "    DROPOUT,\n",
        "    PAD_IDX).to(device)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5o676I3NJ4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5fbe679-6b8e-4067-f968-f10f22c6df70"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(teacher_model):,} trainable parameters')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,756,103 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvinSJ0OM8gX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df6d8ac0-1db5-4f44-a9f4-28b7bafe509e"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12193, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9twua_rJM-ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "22db0ca9-5ccb-4707-ca65-16eedf20dcb3"
      },
      "source": [
        "teacher_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
              "        [-0.7534,  0.2218,  0.4468,  ...,  0.9045, -1.6214, -0.4485],\n",
              "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
              "        ...,\n",
              "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
              "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULf61Z2CNDVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgr2WcePNeqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "7823ba2b-1dbd-4695-c203-4bbd5ae05114"
      },
      "source": [
        "print(teacher_model.embedding.weight.data)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
            "        ...,\n",
            "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
            "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
            "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLpFEhJdTWJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "73c549dd-090d-4ea3-cb8f-aa324e868944"
      },
      "source": [
        "teacher_model"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMWithAttention(\n",
              "  (embedding): Embedding(12193, 100, padding_idx=1)\n",
              "  (rnn): LSTM(100, 200, num_layers=2, dropout=0.3, bidirectional=True)\n",
              "  (attn): Linear(in_features=400, out_features=400, bias=True)\n",
              "  (v): Linear(in_features=400, out_features=1, bias=False)\n",
              "  (fcs): ModuleList(\n",
              "    (0): Linear(in_features=800, out_features=800, bias=True)\n",
              "    (1): Linear(in_features=800, out_features=800, bias=True)\n",
              "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
              "  )\n",
              "  (layer_norms): ModuleList(\n",
              "    (0): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
              "    (2): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (out): Linear(in_features=800, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xU-1_ufImzd",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Loss Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_CBFECq5ELz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(teacher_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hj3DBlXIsem",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsiQ8E-c58nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7BmVMOpIu12",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvZlF5IL6CGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        prem = batch.premise\n",
        "        hypo = batch.hypothesis\n",
        "        labels = batch.label\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(prem, hypo)\n",
        "        \n",
        "        # predictions => [batch size, output dim]\n",
        "        # labels => [batch size]\n",
        "    \n",
        "        loss = criterion(predictions, labels)            \n",
        "        acc = categorical_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcsZeyJFIwuq",
        "colab_type": "text"
      },
      "source": [
        "### Validation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liLiDHMQ6NJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            prem = batch.premise\n",
        "            hypo = batch.hypothesis\n",
        "            labels = batch.label\n",
        "                        \n",
        "            predictions = model(prem, hypo)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "                \n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YniTStu6P46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOIF6KqaIzPk",
        "colab_type": "text"
      },
      "source": [
        "### Teacher Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejXIgRQe6R6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "643317ec-dfd5-43cc-864c-cbb4e0e35b82"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(teacher_model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(teacher_model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 7m 24s\n",
            "\tTrain Loss: 0.573 | Train Acc: 76.66%\n",
            "\t Val. Loss: 0.552 |  Val. Acc: 78.64%\n",
            "Epoch: 02 | Epoch Time: 7m 25s\n",
            "\tTrain Loss: 0.547 | Train Acc: 77.90%\n",
            "\t Val. Loss: 0.541 |  Val. Acc: 79.03%\n",
            "Epoch: 03 | Epoch Time: 7m 24s\n",
            "\tTrain Loss: 0.527 | Train Acc: 78.86%\n",
            "\t Val. Loss: 0.523 |  Val. Acc: 79.66%\n",
            "Epoch: 04 | Epoch Time: 7m 24s\n",
            "\tTrain Loss: 0.509 | Train Acc: 79.61%\n",
            "\t Val. Loss: 0.531 |  Val. Acc: 79.71%\n",
            "Epoch: 05 | Epoch Time: 7m 25s\n",
            "\tTrain Loss: 0.495 | Train Acc: 80.29%\n",
            "\t Val. Loss: 0.544 |  Val. Acc: 79.54%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N47RTdF6I1Mh",
        "colab_type": "text"
      },
      "source": [
        "### Teacher Model - Test Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrF2ajUt6WwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4da4b021-8b2d-4ab4-fed9-c90c616a08f0"
      },
      "source": [
        "teacher_model.load_state_dict(torch.load('teacher_model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(teacher_model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.540 |  Test Acc: 78.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpXdJhkx7zt",
        "colab_type": "text"
      },
      "source": [
        "# Distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2leyQbR4rzZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLIWithDistillation(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.linear = nn.Linear(emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, premise, hypothesis):\n",
        "        prem_embedded = self.dropout(self.embedding(premise))\n",
        "        hypo_embedded = self.dropout(self.embedding(hypothesis))\n",
        "        combined = torch.cat((prem_embedded, hypo_embedded), dim=0)\n",
        "        final = torch.sum(combined, dim=0)\n",
        "        logits = self.linear(self.dropout(final))\n",
        "        return logits"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pib200-2tldf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "distil_model = NLIWithDistillation(\n",
        "    INPUT_DIM,\n",
        "    EMBEDDING_DIM,\n",
        "    OUTPUT_DIM,\n",
        "    DROPOUT).to(device)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0y9VQpHyF2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad4cafd0-8bf7-40f9-d2c0-9ec9bda21216"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(distil_model):,} trainable parameters')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,219,603 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0L27eLNySMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a84cc824-5614-4c24-9b4c-6cfbc47d2e8e"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12193, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdMcExb9yWP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "af875a1e-9c6e-4da1-aeab-3a49eb1d507e"
      },
      "source": [
        "distil_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
              "        [-0.7534,  0.2218,  0.4468,  ...,  0.9045, -1.6214, -0.4485],\n",
              "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
              "        ...,\n",
              "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
              "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIAz0515ybTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distil_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6j94zSsyhcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "62ab7c62-402c-40f2-b0ce-f64d8f53228e"
      },
      "source": [
        "print(distil_model.embedding.weight.data)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
            "        ...,\n",
            "        [-0.3962, -0.0070,  0.4369,  ..., -0.3295,  0.1764,  0.0092],\n",
            "        [ 0.0882, -0.3188,  0.4663,  ...,  0.8881,  0.5180, -0.1170],\n",
            "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46W4cvi4ymfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "09766561-790a-4bcc-8ca9-100ca839bde8"
      },
      "source": [
        "distil_model"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NLIWithDistillation(\n",
              "  (embedding): Embedding(12193, 100)\n",
              "  (linear): Linear(in_features=100, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4naEwMs_au3",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Loss Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEC26C2iyu6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(distil_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "KD_loss = nn.KLDivLoss(reduction='batchmean')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rf0E4sF_e_t",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IynyzoPyyuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4H16Ob_kwC",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsmNY67vy3i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, teacher_model, iterator, optimizer, criterion, temperature=2.0, alpha_ce=0.5, alpha_teacher=0.5):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        prem = batch.premise\n",
        "        hypo = batch.hypothesis\n",
        "        labels = batch.label\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        student_logits = model(prem, hypo)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(prem, hypo)\n",
        "        \n",
        "        # student_logits => [batch size, output dim]\n",
        "        # teacher_logits => [batch size, output dim]\n",
        "        # labels => [batch size]\n",
        "    \n",
        "        teacher_loss = KD_loss(input=F.log_softmax(student_logits/temperature, dim=-1),\n",
        "                       target=F.softmax(teacher_logits/temperature, dim=-1))\n",
        "        \n",
        "        prediction_loss = criterion(student_logits, labels)            \n",
        "\n",
        "        loss = alpha_ce * prediction_loss + alpha_teacher * teacher_loss\n",
        "        \n",
        "        acc = categorical_accuracy(student_logits, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toArgi4u_noN",
        "colab_type": "text"
      },
      "source": [
        "### Validation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YN1jiIny8qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, teacher_model, iterator, criterion, temperature=2.0, alpha_ce=0.5, alpha_teacher=0.5):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            prem = batch.premise\n",
        "            hypo = batch.hypothesis\n",
        "            labels = batch.label\n",
        "            \n",
        "            student_logits = model(prem, hypo)\n",
        "        \n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher_model(prem, hypo)\n",
        "            \n",
        "            # student_logits => [batch size, output dim]\n",
        "            # teacher_logits => [batch size, output dim]\n",
        "            # labels => [batch size]\n",
        "        \n",
        "            teacher_loss = KD_loss(input=F.log_softmax(student_logits/temperature, dim=-1),\n",
        "                        target=F.softmax(teacher_logits/temperature, dim=-1)) * (temperature ** 2)\n",
        "            \n",
        "            prediction_loss = criterion(student_logits, labels)            \n",
        "\n",
        "            loss = alpha_ce * prediction_loss + alpha_teacher * teacher_loss\n",
        "            \n",
        "            acc = categorical_accuracy(student_logits, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIVBvDgUzA9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yy-_02-_t5i",
        "colab_type": "text"
      },
      "source": [
        "#### Load the pre-trained teacher model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qiuwIyCzsH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42eef686-e2a5-4cc1-8613-ff451d1fd859"
      },
      "source": [
        "teacher_model.load_state_dict(torch.load('teacher_model.pt'))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cMvVc8H_x7L",
        "colab_type": "text"
      },
      "source": [
        "### Distillation - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqlv1VMWzET2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "0e64ba2a-bd30-45d0-c5d4-fb97605339db"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(distil_model, teacher_model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(distil_model, teacher_model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(distil_model.state_dict(), 'distil_model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.638 | Train Acc: 55.26%\n",
            "\t Val. Loss: 1.103 |  Val. Acc: 55.75%\n",
            "Epoch: 02 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.636 | Train Acc: 55.41%\n",
            "\t Val. Loss: 1.108 |  Val. Acc: 55.63%\n",
            "Epoch: 03 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.634 | Train Acc: 55.53%\n",
            "\t Val. Loss: 1.108 |  Val. Acc: 55.91%\n",
            "Epoch: 04 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.632 | Train Acc: 55.73%\n",
            "\t Val. Loss: 1.104 |  Val. Acc: 55.77%\n",
            "Epoch: 05 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.631 | Train Acc: 55.81%\n",
            "\t Val. Loss: 1.097 |  Val. Acc: 55.79%\n",
            "Epoch: 06 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.630 | Train Acc: 55.91%\n",
            "\t Val. Loss: 1.105 |  Val. Acc: 55.74%\n",
            "Epoch: 07 | Epoch Time: 2m 17s\n",
            "\tTrain Loss: 0.630 | Train Acc: 55.93%\n",
            "\t Val. Loss: 1.101 |  Val. Acc: 56.05%\n",
            "Epoch: 08 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.629 | Train Acc: 56.02%\n",
            "\t Val. Loss: 1.107 |  Val. Acc: 55.81%\n",
            "Epoch: 09 | Epoch Time: 2m 17s\n",
            "\tTrain Loss: 0.628 | Train Acc: 56.13%\n",
            "\t Val. Loss: 1.099 |  Val. Acc: 55.89%\n",
            "Epoch: 10 | Epoch Time: 2m 16s\n",
            "\tTrain Loss: 0.628 | Train Acc: 56.20%\n",
            "\t Val. Loss: 1.110 |  Val. Acc: 55.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpQPVxVv_3EQ",
        "colab_type": "text"
      },
      "source": [
        "### Distillation - Test Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFE9CCI8zMUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "790ce8c8-c046-406d-aafb-d5990b49cf0c"
      },
      "source": [
        "distil_model.load_state_dict(torch.load('distil_model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(distil_model, teacher_model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.105 |  Test Acc: 55.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-uaXBsdI3f4",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njr-MMuL6ZRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(premise, hypothesis, text_field, label_field, model, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    if isinstance(premise, str):\n",
        "        premise = text_field.tokenize(premise)\n",
        "    \n",
        "    if isinstance(hypothesis, str):\n",
        "        hypothesis = text_field.tokenize(hypothesis)\n",
        "    \n",
        "    if text_field.lower:\n",
        "        premise = [t.lower() for t in premise]\n",
        "        hypothesis = [t.lower() for t in hypothesis]\n",
        "\n",
        "    # numericalize  \n",
        "    premise = [text_field.vocab.stoi[t] for t in premise]\n",
        "    hypothesis = [text_field.vocab.stoi[t] for t in hypothesis]\n",
        "    \n",
        "    # convert into tensors\n",
        "    premise = torch.LongTensor(premise).unsqueeze(1).to(device)\n",
        "    # premise => [prem_len, 1]\n",
        "    hypothesis = torch.LongTensor(hypothesis).unsqueeze(1).to(device)\n",
        "    # hypothesis => [hypo_len, 1]\n",
        "\n",
        "    prediction = model(premise, hypothesis)\n",
        "    prediction = prediction.argmax(dim=-1).item()\n",
        "\n",
        "    return label_field.vocab.itos[prediction]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdvGdOs86uSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "174aed1a-7adb-464b-a8ce-dce1979e6c3f"
      },
      "source": [
        "premise = 'A woman selling bamboo sticks talking to two men on a loading dock.'\n",
        "hypothesis = 'There are at least three people on a loading dock.'\n",
        "\n",
        "inference(premise, hypothesis, TEXT, LABEL, distil_model, device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'entailment'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x0aRzqWGyy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eed43120-a447-4f05-9e27-e9df193a7345"
      },
      "source": [
        "premise = 'A woman selling bamboo sticks talking to two men on a loading dock.'\n",
        "hypothesis = 'A woman is selling bamboo sticks to help provide for her family.'\n",
        "\n",
        "inference(premise, hypothesis, TEXT, LABEL, distil_model, device)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FhxZwvGzXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54e41b06-62db-4645-e9c5-98834f2647be"
      },
      "source": [
        "premise = 'A woman selling bamboo sticks talking to two men on a loading dock.'\n",
        "hypothesis = ' A woman is not taking money for any of her sticks.'\n",
        "\n",
        "inference(premise, hypothesis, TEXT, LABEL, distil_model, device)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'contradiction'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mUZOqRqKYct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}