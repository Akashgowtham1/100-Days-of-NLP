{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document Classification with HAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwKywDzwPg5FPmQn6qRz2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/Document%20Classification%20with%20HAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcHbtSW07kih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "409d10a8-48c9-4d82-f26d-b4229cb5e9f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCf3yQy9MPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3e466168-084d-40de-ee87-3816da721773"
      },
      "source": [
        "!unzip \"./drive/My Drive/glove.6B.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./drive/My Drive/glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JVHsKkCTODb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "e7c16f1c-6ec9-4c4a-fa69-f17b9f32ebf4"
      },
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\n",
        "# !wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Clothing_Shoes_and_Jewelry_5.json.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-07 13:25:33--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2460495 (2.3M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Musical_Instruments_5.json.gz’\n",
            "\n",
            "reviews_Musical_Ins 100%[===================>]   2.35M   858KB/s    in 2.8s    \n",
            "\n",
            "2020-06-07 13:25:36 (858 KB/s) - ‘reviews_Musical_Instruments_5.json.gz’ saved [2460495/2460495]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhM4lAUyTTus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3d606be1-ff50-4949-b244-f78844c4b423"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.300d.txt\t\t\t  sample_data\n",
            "glove.6B.100d.txt  glove.6B.50d.txt\n",
            "glove.6B.200d.txt  reviews_Musical_Instruments_5.json.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28mb_5jMTcd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip reviews_Musical_Instruments_5.json.gz\n",
        "# !gunzip reviews_Clothing_Shoes_and_Jewelry_5.json.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahn_MYFCTyEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "378d7084-6c30-4d87-c097-edc19b4f10a0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.300d.txt\t\t       sample_data\n",
            "glove.6B.100d.txt  glove.6B.50d.txt\n",
            "glove.6B.200d.txt  reviews_Musical_Instruments_5.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrUq9qnFcVJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "58896b0c-f940-43bc-d6c7-7ba07dade770"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnEnmahjSYmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiP09GF-xbJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "409a6e0b-d491-4705-c4e0-9eccff523168"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "datafile = 'reviews_Musical_Instruments_5.json'\n",
        "# datafile = 'reviews_Clothing_Shoes_and_Jewelry_5.json'\n",
        "glove_path = './glove.6B.50d.txt'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAb8uNyFxhn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(datafile, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for line in lines[:-1]:\n",
        "    data = json.loads(line)\n",
        "    texts.append(data[\"reviewText\"].lower())\n",
        "    labels.append(int(data[\"overall\"]) - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyce9W30xiyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bf516fac-4507-449c-e0d1-c88ea6620b34"
      },
      "source": [
        "train_data, valid_data, train_label, valid_label = train_test_split(\n",
        "        texts, labels, train_size=0.8, random_state=1\n",
        "    )\n",
        "\n",
        "print(f\"Number of training data examples: {len(train_label)}\")\n",
        "print(f\"Number of validation data examples: {len(valid_label)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training data examples: 8208\n",
            "Number of validation data examples: 2053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY_Jqqupxpvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label = np.array(train_label, dtype=\"int32\")\n",
        "valid_label = np.array(valid_label, dtype=\"int32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUE3E_Xhxr-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HANPreprocessor:\n",
        "    \"\"\"\n",
        "    Preprocessor to prepare the data for Hierarchical Attention Networks.\n",
        "    It will tokenize a document into sentences and sentences into tokens\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_vocab, min_freq, percentile, tokenizer):\n",
        "        self.max_vocab = max_vocab\n",
        "        self.min_freq = min_freq\n",
        "        self.percentile = percentile\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = None\n",
        "\n",
        "    def _make_sentences(self, texts):\n",
        "        texts_sents = [sent_tokenize(text) for text in texts]\n",
        "        print(f\"Sample sentences: {texts_sents[0]}\")\n",
        "        return texts_sents\n",
        "    \n",
        "    def tokenize(self, texts):\n",
        "        print(f\"Processing {len(texts)} documents\")\n",
        "        texts_sents = self._make_sentences(texts)\n",
        "        all_sents = [s for sent in texts_sents for s in sent]\n",
        "\n",
        "        texts_length = [0] + [len(s) for s in texts_sents]\n",
        "        range_idx = [sum(texts_length[: i + 1]) for i in range(len(texts_length))]\n",
        "\n",
        "        print(f\"Tokenizing {len(all_sents)} sentences\")\n",
        "        sents_tokens = self.tokenizer(all_sents)\n",
        "\n",
        "        # calculating lengths of tokens in each sentence for padding purposes\n",
        "        sents_length = [len(s) for s in sents_tokens]\n",
        "\n",
        "        if self.vocab is None:\n",
        "            self.vocab = Vocab.create(sents_tokens, max_vocab=self.max_vocab, min_freq=self.min_freq)\n",
        "\n",
        "        sents_nums = [self.vocab.numericalize(s) for s in sents_tokens]\n",
        "\n",
        "        # group sentences into documents\n",
        "        texts_nums = [sents_nums[range_idx[i]: range_idx[i + 1]] for i in range(len(range_idx[:-1]))]\n",
        "\n",
        "        # compute max lengths for padding purposes\n",
        "        self.maxlen_sent = int(np.quantile(sents_length, q=self.percentile))\n",
        "        self.maxlen_doc = int(np.quantile(texts_length[1:], q=self.percentile))\n",
        "\n",
        "        print(\"Padding sentences and documents...\")\n",
        "        self.pad_token = self.vocab.stoi['xxpad']\n",
        "\n",
        "        padded_texts = [pad_nested_sequences(r, self.maxlen_sent, self.maxlen_doc, self.pad_token) for r in texts_nums]\n",
        "        return np.stack(padded_texts, axis=0)\n",
        "    \n",
        "    def transform(self, texts):\n",
        "        return self.tokenize(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPvqbph4xwcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(texts):\n",
        "    tokens = Tokenizer().process_all(texts)\n",
        "    print(f\"sentence: {texts[0]}\")\n",
        "    print(f\"tokens: {tokens[0]}\")\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxu3nk_fxy1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(seq, max_len, pad_idx):\n",
        "    if len(seq) > max_len:\n",
        "        return np.array(seq[:max_len]).astype(\"int32\")\n",
        "    else:\n",
        "        res = np.zeros(max_len, dtype=\"int32\") + pad_idx\n",
        "        res[:len(seq)] = seq\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bajOzj6x03C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_nested_sequences(seq, maxlen_sent, maxlen_doc, pad_idx):\n",
        "    if len(seq) == 0:\n",
        "        return np.array([[pad_idx] * maxlen_sent] * maxlen_doc).astype(\"int32\")\n",
        "\n",
        "    # pad the sentences in all docs\n",
        "    seq = [pad_sequences(s, maxlen_sent, pad_idx) for s in seq]\n",
        "\n",
        "    # padding the documents\n",
        "    if len(seq) > maxlen_doc:\n",
        "        return np.array(seq[:maxlen_doc])\n",
        "    else:\n",
        "        res = np.array([[pad_idx] * maxlen_sent] * maxlen_doc).astype(\"int32\")\n",
        "        res[:len(seq)] = seq\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfGHiG5D11Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_embeddings_matrix(vocab, glove_path, emb_dim=50):\n",
        "    embeddings = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    \n",
        "    print(\"creating word embeddings\")\n",
        "\n",
        "    # instead of zeros, initialize the embedding for missing words as mean value\n",
        "    mean_word_vector = np.mean(list(embeddings.values()), axis=0)\n",
        "    num_words = len(vocab.itos)\n",
        "    embeddings_matrix = np.zeros((num_words, emb_dim))\n",
        "    found_words = 0\n",
        "    for i, word in enumerate(vocab.itos):\n",
        "        embedding_vector = embeddings.get(word)\n",
        "\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "            found_words += 1\n",
        "        else:\n",
        "            embeddings_matrix[i] = mean_word_vector\n",
        "    \n",
        "    print(f\"Embeddings found for {(found_words / num_words) * 100} % of the words\")\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EuR5WENx3W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB = 5000\n",
        "MIN_FREQ = 5\n",
        "PERCENTILE = 0.8\n",
        "BATCH_SIZE = 32\n",
        "processor = HANPreprocessor(MAX_VOCAB, MIN_FREQ, PERCENTILE, tokenizer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeVkNuk4x6i_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "156e6e2a-fac1-4264-d790-165a38b51de2"
      },
      "source": [
        "train_seq = processor.transform(train_data)\n",
        "valid_seq = processor.transform(valid_data)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 8208 documents\n",
            "Sample sentences: ['this mxl studio 24 usb microphone is a decent choice for those needing a portable or a good quality studio microphone.', 'we professionally produce instructional videos, both at our shop and at customer locations, and often need to voice over footage.', 'this mic will replace theblue microphones snowball usb microphone (textured white)we use in studio and also themxl mics mxl-studio 1 usb condenser microphone, cardioidwe had previously used for off-site recording.pros -* good voice quality; cleanly captures spoken voices* good physical quality; this is beefy mic that feels very well made* looks professional; while not important to the functionality, it makes a good impression on our customers* long usb cord; allows for placement away from pc* headphone jack; \"real time monitor\", handy to listen to live recording and playback* travels well; includes a protective travel case that fits all of componentscons -* no pop-filter included; normally i wouldn\\'t mention this but the instructions include a warning the condenser mics are susceptible to water damage (like from breath moisture) and a pop-filter is \"essential\".', \"we boughtnady mpf-6 6-inch clamp on microphone pop filter* left channel; only brings in audio on the left channel, had to compensate in my editing softwaremisc -* since we do not do music recording of any type, i can't comment on the mic's performance in that area* software; studio control gui (downloadable) can be launched to control some of the finer functions of the microphone, but the interface is not intuitive and my editing software (sony vegas pro) gives me better control for what we dothe mxl studio 24 mic more than meets our needs (which may be different from yours).recommended!cfh\"]\n",
            "Tokenizing 42003 sentences\n",
            "sentence: this mxl studio 24 usb microphone is a decent choice for those needing a portable or a good quality studio microphone.\n",
            "tokens: ['this', 'mxl', 'studio', '24', 'usb', 'microphone', 'is', 'a', 'decent', 'choice', 'for', 'those', 'needing', 'a', 'portable', 'or', 'a', 'good', 'quality', 'studio', 'microphone', '.']\n",
            "Padding sentences and documents...\n",
            "Processing 2053 documents\n",
            "Sample sentences: [\"i'm very pleased with this purchase.\", 'the cables are flexible, quiet and no pops or loss of signal.', 'not much else to say.', 'buy them.']\n",
            "Tokenizing 10294 sentences\n",
            "sentence: i'm very pleased with this purchase.\n",
            "tokens: ['i', \"'m\", 'very', 'pleased', 'with', 'this', 'purchase', '.']\n",
            "Padding sentences and documents...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKbQmMnw5Lko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e46c90a4-b1e0-4c42-c53d-d027bc78dbb8"
      },
      "source": [
        "emb_weights = build_embeddings_matrix(processor.vocab, glove_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating word embeddings\n",
            "Embeddings found for 96.74000000000001 % of the words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjo9Ad5Zx8Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = TensorDataset(\n",
        "    torch.from_numpy(train_seq).long(),\n",
        "    torch.from_numpy(train_label).long()\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cig7ELox-hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_set = TensorDataset(\n",
        "    torch.from_numpy(valid_seq).long(),\n",
        "    torch.from_numpy(valid_label).long()\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d31NHVZKOG-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedded_dropout(embed, words, dropout=0.1, scale=None):\n",
        "    if dropout:\n",
        "        mask = embed.weight.data.new().resize_((embed.weight.size(0), 1))\n",
        "        mask = mask.bernoulli_(1 - dropout).expand_as(embed.weight) / (1 - dropout)\n",
        "        masked_embed_weight = mask * embed.weight\n",
        "    else:\n",
        "        masked_embed_weight = embed.weight\n",
        "    \n",
        "    if scale:\n",
        "        masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
        "    padding_idx = embed.padding_idx\n",
        "\n",
        "    emb = F.embedding(\n",
        "        words,\n",
        "        masked_embed_weight,\n",
        "        padding_idx,\n",
        "        embed.max_norm,\n",
        "        embed.norm_type,\n",
        "        embed.scale_grad_by_freq,\n",
        "        embed.sparse\n",
        "    )\n",
        "\n",
        "    return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B6127V_XIq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, x, dropout=0.5):\n",
        "        if not dropout:\n",
        "            return x\n",
        "        mask = x.data.new(1, x.shape[1], x.shape[2])\n",
        "        mask = mask.bernoulli_(1 - dropout) / (1 - dropout)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L75bOIrUyKOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        # inp => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        energy = torch.tanh(self.attn(inp))\n",
        "        # energy => [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        attention = F.softmax(self.v(energy), dim=1)\n",
        "        # attention => [batch_size, seq_len, 1]\n",
        "\n",
        "        return attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiVdaVtgyPHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class WordAttention(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, emb_weights, pad_idx, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(emb_weights).float())\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.word_attn = Attention(hidden_dim * 2)\n",
        "        self.lockdrop = LockedDropout()\n",
        "\n",
        "    def forward(self, inp, hidden, emb_dropout=0.1, lock_dropout=0.5):\n",
        "        # inp => [batch_size, seq_len]\n",
        "        # hidden => [num_dir * num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        # embedded = self.embedding(inp)\n",
        "        embedded = embedded_dropout(self.embedding, inp, dropout=emb_dropout)\n",
        "        # embedded => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        if lock_dropout:\n",
        "            embedded = self.lockdrop(embedded, lock_dropout)\n",
        "\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        # output => [batch_size, seq_len, hidden_dim * num_dir]\n",
        "        #        => [batch_size, seq_len, hidden_dim * 2]\n",
        "        # hidden => [num_dir * n_layers, batch_size, hidden_dim]\n",
        "\n",
        "        attention = self.word_attn(output)\n",
        "        # attention => [batch_size, seq_len, 1]\n",
        "\n",
        "        # output => [batch_size, seq_len, hid_dim * 2]\n",
        "        weighted = torch.sum(attention * output, dim=1)\n",
        "        # weighted => [batch_size, hidden_dim * 2]\n",
        "\n",
        "        attention = attention.permute(0, 2, 1)\n",
        "        # attention => [batch_size, 1, seq_len]\n",
        "\n",
        "        weighted = weighted.unsqueeze(1)\n",
        "        # weighted => [batch_size, 1, hidden_dim * 2]\n",
        "\n",
        "        return attention, weighted, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3spmb7HyySRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceAttention(nn.Module):\n",
        "    def __init__(self, word_hidden_dim, sent_hidden_dim, pad_idx, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn = nn.GRU(word_hidden_dim * 2, sent_hidden_dim, bidirectional=True)\n",
        "        self.sent_attn = Attention(sent_hidden_dim * 2)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        # inp => [batch_size, seq_len, word_hid_dim * 2]\n",
        "\n",
        "        output, hidden = self.rnn(inp)\n",
        "        # output => [batch_size, seq_len, sent_hid_dim * 2]\n",
        "        # hidden => [num_layers * num_dir, batch_size, sent_hid_dim]\n",
        "\n",
        "        attention = self.sent_attn(output)\n",
        "        # attention => [batch_size, seq_len, 1]\n",
        "\n",
        "        # output => [batch_size, seq_len, hid_dim * 2]\n",
        "        weighted = torch.sum(attention * output, dim=1)\n",
        "        # weighted => [batch_size, hidden_dim * 2]\n",
        "\n",
        "        attention = attention.permute(0, 2, 1)\n",
        "        # attention => [batch_size, 1, seq_len]\n",
        "\n",
        "        return attention, weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A33I7fGpyVLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class HierarchicalAttention(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, emb_weights, word_hid_dim, sent_hid_dim, pad_idx, output_dim, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.word_hid_dim = word_hid_dim\n",
        "        self.device = device\n",
        "        self.word_attention = WordAttention(input_dim, emb_dim, emb_weights, pad_idx, word_hid_dim)\n",
        "        self.sent_attention = SentenceAttention(word_hid_dim, sent_hid_dim, pad_idx, dropout)\n",
        "\n",
        "        self.fc = nn.Linear(sent_hid_dim * 2, output_dim)\n",
        "    \n",
        "    def forward(self, inp, emb_dropout=0.1, lock_dropout=0.5):\n",
        "        # inp => [batch_size, max_sents, max_words]\n",
        "        \n",
        "        batch_size = inp.shape[0]\n",
        "        inp = inp.permute(1, 0 , 2)\n",
        "        # inp => [max_sents, batch_size, max_words]\n",
        "\n",
        "        # initialize word rnn hiddens state\n",
        "        hidden = torch.nn.Parameter(torch.zeros(2, batch_size, self.word_hid_dim)).to(self.device)\n",
        "\n",
        "        word_attentions, sents_reps = [], []\n",
        "\n",
        "        for sent in inp:\n",
        "            word_attn, sent_rep, hidden = self.word_attention(sent, hidden, emb_dropout, lock_dropout)\n",
        "            word_attentions.append(word_attn)\n",
        "            sents_reps.append(sent_rep)\n",
        "        \n",
        "        sents = torch.cat(sents_reps, 1)\n",
        "        # sents => [batch_size, max_sents, word_hid_dim * 2]\n",
        "\n",
        "        word_attns = torch.cat(word_attentions, 1)\n",
        "        # word_attns => [batch_size, max_sents, max_words]\n",
        "\n",
        "        sent_attn, doc_rep = self.sent_attention(sents)\n",
        "        sent_attn = sent_attn.squeeze(1)\n",
        "        # sent_attn => [batch_size, max_sents]\n",
        "        # doc_rep => [batch_size, sent_hid_dim * 2]\n",
        "\n",
        "        logits = self.fc(doc_rep)\n",
        "        # logits => [batch_size, 5]\n",
        "\n",
        "        return logits, sent_attn, word_attns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCDA3ZrUyY2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(processor.vocab.itos)\n",
        "emb_dim = 50\n",
        "word_hid_dim = 32\n",
        "sent_hid_dim = 32\n",
        "pad_idx = processor.pad_token\n",
        "output_dim = 5\n",
        "dropout = 0.5\n",
        "model = HierarchicalAttention(input_dim, emb_dim, emb_weights, word_hid_dim, sent_hid_dim, pad_idx, output_dim, dropout, device)\n",
        "model = model.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GiPX5MEfPEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "47c59a5d-6dd4-4922-f32d-913226c38fd7"
      },
      "source": [
        "def init_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HierarchicalAttention(\n",
              "  (word_attention): WordAttention(\n",
              "    (embedding): Embedding(5000, 50, padding_idx=1)\n",
              "    (rnn): GRU(50, 32, batch_first=True, bidirectional=True)\n",
              "    (word_attn): Attention(\n",
              "      (attn): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (v): Linear(in_features=64, out_features=1, bias=False)\n",
              "    )\n",
              "    (lockdrop): LockedDropout()\n",
              "  )\n",
              "  (sent_attention): SentenceAttention(\n",
              "    (rnn): GRU(64, 32, bidirectional=True)\n",
              "    (sent_attn): Attention(\n",
              "      (attn): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (v): Linear(in_features=64, out_features=1, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHTvA0eyvb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXUnn77iyyiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, criterion, optimizer, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        inp, labels = batch\n",
        "        inp = inp.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits, _, _ = model(inp)\n",
        "        # logits => [batch_size, 5]\n",
        "        # labels => [batch_size]\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        top_k = logits.topk(1, 1)[1]\n",
        "        true_k = labels.view(len(labels), 1).expand_as(top_k)\n",
        "        correct_count += top_k.eq(true_k).float().sum().item()\n",
        "        total_count += len(logits)\n",
        "        \n",
        "    \n",
        "    accuracy = float(correct_count) / float(total_count)\n",
        "    return epoch_loss / len(iterator), accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQVQ42C-y8ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            inp, labels = batch\n",
        "            inp = inp.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # keep the emb_dropout, lock_dropout to 0 \n",
        "            logits, _, _ = model(inp, 0, 0)\n",
        "            # logits => [batch_size, 5]\n",
        "            # labels => [batch_size]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            top_k = logits.topk(1, 1)[1]\n",
        "            true_k = labels.view(len(labels), 1).expand_as(top_k)\n",
        "            correct_count += top_k.eq(true_k).float().sum().item()\n",
        "            total_count += len(logits)\n",
        "    \n",
        "    accuracy = float(correct_count) / float(total_count)\n",
        "    return epoch_loss / len(iterator), accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xDOmqqNy-fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF3UJw7hzAKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "e0227a5f-1885-4f80-a1e4-edc6c4ce6a86"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, CLIP)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.937 | Train Acc: 67.57%\n",
            "\t Val. Loss: 0.865 |  Val. Acc: 67.17%\n",
            "Epoch: 02 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.831 | Train Acc: 69.08%\n",
            "\t Val. Loss: 0.873 |  Val. Acc: 67.36%\n",
            "Epoch: 03 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.767 | Train Acc: 70.39%\n",
            "\t Val. Loss: 0.878 |  Val. Acc: 67.12%\n",
            "Epoch: 04 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.722 | Train Acc: 71.61%\n",
            "\t Val. Loss: 0.910 |  Val. Acc: 63.08%\n",
            "Epoch: 05 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.684 | Train Acc: 73.31%\n",
            "\t Val. Loss: 0.896 |  Val. Acc: 66.29%\n",
            "Epoch: 06 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.655 | Train Acc: 74.05%\n",
            "\t Val. Loss: 0.952 |  Val. Acc: 65.81%\n",
            "Epoch: 07 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.623 | Train Acc: 75.02%\n",
            "\t Val. Loss: 1.032 |  Val. Acc: 65.17%\n",
            "Epoch: 08 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.621 | Train Acc: 75.41%\n",
            "\t Val. Loss: 1.012 |  Val. Acc: 66.49%\n",
            "Epoch: 09 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.608 | Train Acc: 76.05%\n",
            "\t Val. Loss: 1.075 |  Val. Acc: 66.59%\n",
            "Epoch: 10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.590 | Train Acc: 76.29%\n",
            "\t Val. Loss: 1.041 |  Val. Acc: 63.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIncKOrOoiqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f396d17-bad5-4d5d-fc8b-dbc043ba18a2"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwBxp9v9tmcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import IPython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3865ZyYm_ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(document, processor, model, device):\n",
        "    sentences = processor._make_sentences([document])\n",
        "    inp = processor.transform([document])\n",
        "    print(f\"inp shape: {inp.shape}\")\n",
        "    inp = torch.LongTensor(inp).to(device)\n",
        "    logits, sent_attn, word_attn = model(inp, 0, 0)\n",
        "    return logits, sentences, sent_attn, word_attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE44fTiGz16R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5d45f812-d1ba-43b5-fdb6-fd69efea152f"
      },
      "source": [
        "idx = 143\n",
        "valid_data[idx], valid_label[idx]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"this is a fun pick.  i play a lot with my fingers and thumb and thought i'd give this a try.  its great!  i love the tone of this pick striking strings.  i love the way it transmits the feel of the strings.  more organic than plastic picks.  yes it might crumble on you if you play too hard.  i think if you play as hard with this pick as you would with your thumb you'll be fine.  its a lot of fun and for such a little price can open your playing to different tones for your instrument.  worth a try.\",\n",
              " 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cbFYRc3oxqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "ce3f35c5-4234-4f60-a3c9-6ecc5e8a0729"
      },
      "source": [
        "logits, sentences, sent_attn, word_attn = classify(valid_data[idx], processor, model, device)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample sentences: ['this is a fun pick.', \"i play a lot with my fingers and thumb and thought i'd give this a try.\", 'its great!', 'i love the tone of this pick striking strings.', 'i love the way it transmits the feel of the strings.', 'more organic than plastic picks.', 'yes it might crumble on you if you play too hard.', \"i think if you play as hard with this pick as you would with your thumb you'll be fine.\", 'its a lot of fun and for such a little price can open your playing to different tones for your instrument.', 'worth a try.']\n",
            "Processing 1 documents\n",
            "Sample sentences: ['this is a fun pick.', \"i play a lot with my fingers and thumb and thought i'd give this a try.\", 'its great!', 'i love the tone of this pick striking strings.', 'i love the way it transmits the feel of the strings.', 'more organic than plastic picks.', 'yes it might crumble on you if you play too hard.', \"i think if you play as hard with this pick as you would with your thumb you'll be fine.\", 'its a lot of fun and for such a little price can open your playing to different tones for your instrument.', 'worth a try.']\n",
            "Tokenizing 10 sentences\n",
            "sentence: this is a fun pick.\n",
            "tokens: ['this', 'is', 'a', 'fun', 'pick', '.']\n",
            "Padding sentences and documents...\n",
            "inp shape: (1, 10, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mFjVX2VpBHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "50051014-a43e-49d7-ef53-9974c97ed013"
      },
      "source": [
        "print(logits.shape)\n",
        "logits"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3802, -2.7388, -0.9391,  0.5919,  2.0912]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXosGxPUmYpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b33060b8-c509-4458-8ec6-b3a7b12035e8"
      },
      "source": [
        "print(sent_attn.shape)\n",
        "sent_attn"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0969, 0.1094, 0.1054, 0.1086, 0.1159, 0.1075, 0.0730, 0.0808, 0.1096,\n",
              "         0.0929]], device='cuda:0', grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzvKgrGMrVTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_sent_attn(sents, sents_attns, cmap=\"Greens\"):\n",
        "    cmap = matplotlib.cm.get_cmap(cmap)\n",
        "    template = '<font face=\"monospace\" \\nsize=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
        "    colored_doc = \"\"\n",
        "    sents_attns = sents_attns.squeeze(0).cpu().detach().numpy()\n",
        "    for sent, sent_w in zip(sents, sents_attns):\n",
        "        sent = ' '.join([t for t in sent.split() if t!='xxpad'])\n",
        "        if len(sent) > 0:\n",
        "            color = matplotlib.colors.rgb2hex(cmap(sent_w)[:3])\n",
        "            colored_doc += template.format(color, \"&nbsp\" + sent + \"&nbsp\") + \"</br>\"\n",
        "    return colored_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTDJGWd7rm_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_attn_html = plot_sent_attn(sentences[0], sent_attn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZupR-pRsdIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b51722da-2349-4798-d3ac-e5ed3c5f98fd"
      },
      "source": [
        "IPython.display.HTML(sent_attn_html)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e9f7e5\">&nbspthis is a fun pick.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbspi play a lot with my fingers and thumb and thought i'd give this a try.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e4\">&nbspits great!&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbspi love the tone of this pick striking strings.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e7f6e2\">&nbspi love the way it transmits the feel of the strings.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbspmore organic than plastic picks.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #edf8e9\">&nbspyes it might crumble on you if you play too hard.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ecf8e8\">&nbspi think if you play as hard with this pick as you would with your thumb you'll be fine.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e7f6e3\">&nbspits a lot of fun and for such a little price can open your playing to different tones for your instrument.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eaf7e6\">&nbspworth a try.&nbsp</span></br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-etcsQbGm2jM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22cc0541-5f46-433d-cafc-ad808cefc86a"
      },
      "source": [
        "word_attn.shape"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W5K79Q9sztr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_word_attn(sentences, word_attn, cmap):\n",
        "    word_attn = word_attn.squeeze(0).cpu().detach().numpy()\n",
        "    cmap = matplotlib.cm.get_cmap(cmap)\n",
        "    template = '<font face=\"monospace\" \\nsize=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
        "    colored_doc = \"\"\n",
        "    for sent, sent_w in zip(sentences, word_attn):\n",
        "        sent_len, pad_count = len(sent.split()), 0\n",
        "        for t, w in zip(sent.split(), sent_w):\n",
        "            if t == 'xxpad':\n",
        "                pad_count+=1\n",
        "                continue\n",
        "            color = matplotlib.colors.rgb2hex(cmap(w)[:3])\n",
        "            colored_doc += template.format(color, \"&nbsp\" + t + \"&nbsp\")\n",
        "        if pad_count != sent_len:\n",
        "            colored_doc += \"</br>\"\n",
        "    return colored_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC6wJxPXtKf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_attn_html = plot_word_attn(sentences[0], word_attn, 'Greens')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFYqtGietbFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e37bf628-967e-4393-9ede-327a728cb379"
      },
      "source": [
        "IPython.display.HTML(word_attn_html)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e4\">&nbspthis&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e0f3db\">&nbspis&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #d3eecd\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #d5efcf\">&nbspfun&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eef8ea\">&nbsppick.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f6fcf4\">&nbspi&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f6fcf4\">&nbspplay&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf2\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf1\">&nbsplot&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf1\">&nbspwith&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspmy&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faef\">&nbspfingers&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspand&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e6f5e1\">&nbspthumb&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspand&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faf0\">&nbspthought&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspi'd&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #dbf1d6\">&nbspgive&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faef\">&nbspthis&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f3faf0\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbsptry.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #edf8ea\">&nbspits&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ecf8e8\">&nbspgreat!&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspi&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbsplove&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspthe&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbsptone&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspof&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspthis&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbsppick&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspstriking&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspstrings.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f3faf0\">&nbspi&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f3faf0\">&nbsplove&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspthe&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ed\">&nbspway&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e2f4dd\">&nbspit&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbsptransmits&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e1f3dc\">&nbspthe&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #dcf2d7\">&nbspfeel&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faef\">&nbspof&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9eb\">&nbspthe&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faf0\">&nbspstrings.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ecf8e8\">&nbspmore&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f3faf0\">&nbsporganic&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faef\">&nbspthan&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #caeac3\">&nbspplastic&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbsppicks.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faf0\">&nbspyes&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e7f6e3\">&nbspit&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ecf8e8\">&nbspmight&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspcrumble&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf1\">&nbspon&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ebf7e7\">&nbspyou&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ebf7e7\">&nbspif&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspyou&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #edf8ea\">&nbspplay&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #dff3da\">&nbsptoo&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #def2d9\">&nbsphard.&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #edf8ea\">&nbspi&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e2f4dd\">&nbspthink&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #ebf7e7\">&nbspif&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspyou&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faf0\">&nbspplay&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e3\">&nbspas&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e8f6e4\">&nbsphard&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f6fcf4\">&nbspwith&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f6fcf4\">&nbspthis&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f5fbf2\">&nbsppick&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f2faef\">&nbspas&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf2\">&nbspyou&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e7f6e3\">&nbspwould&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf2\">&nbspwith&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf1\">&nbspyour&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e9f7e5\">&nbspthumb&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f4fbf1\">&nbspyou'll&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ed\">&nbspbe&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e6f5e1\">&nbspits&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbsplot&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspof&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspfun&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspand&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspfor&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ed\">&nbspsuch&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbsplittle&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspprice&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9eb\">&nbspcan&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #eff9ec\">&nbspopen&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ec\">&nbspyour&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ed\">&nbspplaying&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbspto&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f0f9ed\">&nbspdifferent&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #f1faee\">&nbsptones&nbsp</span></br><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #e5f5e0\">&nbspworth&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #d9f0d3\">&nbspa&nbsp</span><font face=\"monospace\" \n",
              "size=\"3\"; span class=\"barcode\"; style=\"color: black; background-color: #cfecc9\">&nbsptry.&nbsp</span></br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RubUDvtfHX73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}