{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QQP Classification with Siamese.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYmUfEFPevlvTTkyF1yQ3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/QQP%20Classification%20with%20Siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAj-bxTdkYkt",
        "colab_type": "code",
        "outputId": "2bbacdf4-a948-490a-882a-acd4200dbcb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "TASK_DATA_DIR = 'glue_data/QQP'\n",
        "!test -d glue_data || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git glue_data\n",
        "!test -d $TASK_DATA_DIR || python glue_data/download_glue_data.py --data_dir glue_data --tasks=QQP\n",
        "!ls -alh $TASK_DATA_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'glue_data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "total 104M\n",
            "drwxr-xr-x 3 root root 4.0K Jun 12 16:29 .\n",
            "drwxr-xr-x 4 root root 4.0K Jun 12 16:29 ..\n",
            "-rw-r--r-- 1 root root 5.6M Jun 12 16:29 dev.tsv\n",
            "drwxr-xr-x 2 root root 4.0K Jun 12 16:29 original\n",
            "-rw-r--r-- 1 root root  49M Jun 12 16:29 test.tsv\n",
            "-rw-r--r-- 1 root root  50M Jun 12 16:29 train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6qQ5koukpli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils import shuffle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teblZgYCgPPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsYQsO6lgbUP",
        "colab_type": "code",
        "outputId": "7b92f1e3-05ac-409e-dd10-c7ca77673cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAATlnfelkFJ",
        "colab_type": "code",
        "outputId": "31c14090-11cd-4152-bf69-93b9800e846e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "train_df = pd.read_csv(TASK_DATA_DIR + '/train.tsv', sep='\\t', error_bad_lines=False)\n",
        "valid_df = pd.read_csv(TASK_DATA_DIR + '/dev.tsv', sep='\\t', error_bad_lines=False)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133273</td>\n",
              "      <td>213221</td>\n",
              "      <td>213222.0</td>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360472</td>\n",
              "      <td>364011</td>\n",
              "      <td>490273.0</td>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183004</td>\n",
              "      <td>279958</td>\n",
              "      <td>279959.0</td>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... is_duplicate\n",
              "0  133273  ...          0.0\n",
              "1  402555  ...          1.0\n",
              "2  360472  ...          0.0\n",
              "3  150662  ...          1.0\n",
              "4  183004  ...          0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8-XRyOlmTn",
        "colab_type": "code",
        "outputId": "ed480ed0-304f-4ce3-f49f-d9bdb4628414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f\"Training df shape: {train_df.shape}\")\n",
        "print(f\"Validation df shape: {valid_df.shape}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training df shape: (363192, 6)\n",
            "Validation df shape: (40372, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a3yy6iznwSY",
        "colab_type": "text"
      },
      "source": [
        "### Simple Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5lPRjfzmngO",
        "colab_type": "code",
        "outputId": "d3550b78-e366-46a7-f20d-238eee54e9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "sns.countplot(train_df.is_duplicate)\n",
        "plt.xlabel('Number of duplicate questions in training data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of duplicate questions in training data')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtjJZtfaoptv",
        "colab_type": "code",
        "outputId": "c9fab550-c6d2-4ea3-fc9e-b843e58fc938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "sns.countplot(valid_df.is_duplicate)\n",
        "plt.xlabel('Number of duplicate questions in validation data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of duplicate questions in validation data')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoKz9czcn1FV",
        "colab_type": "text"
      },
      "source": [
        "Remove the unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D3KBuNynQSQ",
        "colab_type": "code",
        "outputId": "009346aa-9043-4921-b25f-cc7816925e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df = train_df.drop(columns=['id', 'qid1', 'qid2'])\n",
        "valid_df = valid_df.drop(columns=['id', 'qid1', 'qid2'])\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0  How is the life of a math student? Could you d...  ...          0.0\n",
              "1                How do I control my horny emotions?  ...          1.0\n",
              "2       What causes stool color to change to yellow?  ...          0.0\n",
              "3                        What can one do after MBBS?  ...          1.0\n",
              "4  Where can I find a power outlet for my laptop ...  ...          0.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4P8s3-toItn",
        "colab_type": "code",
        "outputId": "a1d89d8a-e4a8-42ce-9f91-92cdeeb28dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f\"Percentage of Question pairs that are not Similar (is_duplicate = 0): {100 - round(train_df['is_duplicate'].mean()*100, 2)}%\")\n",
        "print(f\"Percentage of Question pairs that are Similar (is_duplicate = 1): {round(train_df['is_duplicate'].mean()*100, 2)}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Question pairs that are not Similar (is_duplicate = 0): 63.06%\n",
            "Percentage of Question pairs that are Similar (is_duplicate = 1): 36.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl9Ftp1Dpjxk",
        "colab_type": "code",
        "outputId": "ead0149e-e55e-4c46-d867-099215956eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df['q1_length'] = train_df['question1'].apply(lambda x: len(str(x)))\n",
        "train_df['q2_length'] = train_df['question2'].apply(lambda x: len(str(x)))\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>q1_length</th>\n",
              "      <th>q2_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... q2_length\n",
              "0  How is the life of a math student? Could you d...  ...        55\n",
              "1                How do I control my horny emotions?  ...        34\n",
              "2       What causes stool color to change to yellow?  ...        49\n",
              "3                        What can one do after MBBS?  ...        28\n",
              "4  Where can I find a power outlet for my laptop ...  ...       121\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGvpdzksqUUe",
        "colab_type": "code",
        "outputId": "7c80a1f6-0677-4598-a4c5-8ba2b6ea3b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_df.q1_length.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59.622042886407186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBW47HbRq12J",
        "colab_type": "code",
        "outputId": "404ca607-e066-44f2-81d1-b311d6021404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_df.q2_length.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.173357342672745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-woDUP1gsAy",
        "colab_type": "code",
        "outputId": "77c44895-9702-4642-bb2d-e17799845ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "train_df = train_df.drop(['q1_length', 'q2_length'], axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0  How is the life of a math student? Could you d...  ...          0.0\n",
              "1                How do I control my horny emotions?  ...          1.0\n",
              "2       What causes stool color to change to yellow?  ...          0.0\n",
              "3                        What can one do after MBBS?  ...          1.0\n",
              "4  Where can I find a power outlet for my laptop ...  ...          0.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtOEpnHBu5X6",
        "colab_type": "text"
      },
      "source": [
        "### Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNvX0-C95Pqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(texts):\n",
        "    tokens = Tokenizer().process_all(texts)\n",
        "    print(f\"sentence: {texts[0]}\")\n",
        "    print(f\"tokens: {tokens[0]}\")\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSqp1FPW089d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QQPProcessor:\n",
        "    def __init__(self, max_vocab, min_freq, tokenizer):\n",
        "        self.max_vocab = max_vocab\n",
        "        self.min_freq = min_freq\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = None\n",
        "    \n",
        "    def tokenize(self, question1, question2):\n",
        "        all_texts = []\n",
        "        for q1, q2 in zip(question1, question2):\n",
        "            all_texts.append(q1)\n",
        "            all_texts.append(q2)\n",
        "        start_time = time.time()\n",
        "        sents_tokens = self.tokenizer(all_texts)\n",
        "        end_time = time.time()\n",
        "        print(f\"Tokenization took: {end_time - start_time} secs\")\n",
        "        if self.vocab is None:\n",
        "            print(f\"Building vocabulary\")\n",
        "            self.vocab = Vocab.create(sents_tokens, max_vocab=self.max_vocab, min_freq=self.min_freq)\n",
        "        \n",
        "        sents_nums = [self.vocab.numericalize(s) for s in sents_tokens]\n",
        "\n",
        "        question1_seq, question2_seq = [], []\n",
        "        for i in range(0, len(sents_nums), 2):\n",
        "            question1_seq.append(sents_nums[i])\n",
        "            question2_seq.append(sents_nums[i+1])\n",
        "\n",
        "        return question1_seq, question2_seq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEsgDJ5W5URM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_vocab = 5000\n",
        "min_freq = 5\n",
        "\n",
        "processor = QQPProcessor(max_vocab, min_freq, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdaqP-aW5YXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = shuffle(train_df)\n",
        "\n",
        "train_question1 = train_df.question1.values[:50000]\n",
        "train_question2 = train_df.question2.values[:50000]\n",
        "train_labels = train_df.is_duplicate.values[:50000]\n",
        "\n",
        "val_question1 = valid_df.question1.values[:2000]\n",
        "val_question2 = valid_df.question2.values[:2000]\n",
        "val_labels = valid_df.is_duplicate.values[:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePBn67Gg7VBU",
        "colab_type": "code",
        "outputId": "f85c9cc1-db3b-427c-ee5a-0bcf0cf01692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f\"Training samples: {len(train_question1)}\")\n",
        "print(f\"Validation samples: {len(val_question1)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training samples: 50000\n",
            "Validation samples: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT9WJPKi7TDD",
        "colab_type": "code",
        "outputId": "7de1d3ba-9541-4932-a260-53569a5ff2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_q1_seq, train_q2_seq = processor.tokenize(train_question1, train_question2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: What is the top speed of bus rapid transit on dedicated lanes?\n",
            "tokens: ['xxmaj', 'what', 'is', 'the', 'top', 'speed', 'of', 'bus', 'rapid', 'transit', 'on', 'dedicated', 'lanes', '?']\n",
            "Tokenization took: 13.463430166244507 secs\n",
            "Building vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lde7W7rd5uyo",
        "colab_type": "code",
        "outputId": "90827e41-4a52-4e5b-c85c-0910b841f050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(train_question1[0])\n",
        "train_q1_seq[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is the top speed of bus rapid transit on dedicated lanes?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 11, 12, 10, 250, 429, 19, 4090, 0, 3430, 30, 0, 0, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW6Np2b06Mnb",
        "colab_type": "code",
        "outputId": "c1d4e614-74a9-458d-9520-7bac155e081a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(train_question2[0])\n",
        "train_q2_seq[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is the top speed of ZX-6R?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 11, 12, 10, 250, 429, 19, 6, 0, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CsmYdXUWlod",
        "colab_type": "code",
        "outputId": "fb7700cd-18c8-451d-dd18-ea0216fa23bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "val_q1_seq, val_q2_seq = processor.tokenize(val_question1, val_question2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: Why are African-Americans so beautiful?\n",
            "tokens: ['xxmaj', 'why', 'are', 'xxmaj', 'african', '-', 'xxmaj', 'americans', 'so', 'beautiful', '?']\n",
            "Tokenization took: 1.2879095077514648 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3exqCA9p6Xlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "        return padded_seqs, lengths\n",
        "\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    q1_seqs, q2_seqs, labels = zip(*data)\n",
        "\n",
        "    q1_seqs, q1_lengths = merge(q1_seqs)\n",
        "    q2_seqs, q2_lengths = merge(q2_seqs)\n",
        "    labels = torch.FloatTensor(labels)\n",
        "    return q1_seqs.transpose(0, 1), q1_lengths, q2_seqs.transpose(0, 1), q2_lengths, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IieVQM88995y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuoraDataset(Dataset):\n",
        "    def __init__(self, question1, question2, is_duplicate):\n",
        "        self.question1 = question1\n",
        "        self.question2 = question2\n",
        "        self.label = is_duplicate\n",
        "\n",
        "        assert len(question1) == len(question2)\n",
        "        self.length = len(is_duplicate)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        q1_seq = torch.Tensor(self.question1[index])\n",
        "        q2_seq = torch.Tensor(self.question2[index])\n",
        "        label = self.label[index]\n",
        "        return q1_seq, q2_seq, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nroEkVX7DvRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = QuoraDataset(train_q1_seq, train_q2_seq, train_labels)\n",
        "val_dataset = QuoraDataset(val_q1_seq, val_q2_seq, val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E5ND1qOEDJo",
        "colab_type": "code",
        "outputId": "21fca935-af3c-467d-93ab-c62ad5078c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "train_dataset[23]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   5.,   11.,   42.,   10.,   91.,   66.,   15.,    0.,    6.,    0.,\n",
              "         1325.,   21.,  500.,   54.,    5., 2535.,   34.,    6.,    0.,    9.]),\n",
              " tensor([   5., 2535.,    6.,    0.,    5., 1325.,   88.,    5., 3955., 3356.,\n",
              "         3613.,    9.]),\n",
              " 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OUpY_-VE45l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fDY5sH7EKcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loader(q1_data, q2_data, label_data, train=True, batch_size=BATCH_SIZE):\n",
        "    dataset = QuoraDataset(q1_data, q2_data, label_data)\n",
        "\n",
        "    if train:\n",
        "        shuffle = True\n",
        "    else:\n",
        "        shuffle = False\n",
        "    \n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu8pX-CKE3Oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_loader(train_q1_seq, train_q2_seq, train_labels)\n",
        "val_loader = get_loader(val_q1_seq, val_q2_seq, val_labels, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIb0tvUlFA0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_batch, q1_len, q2_batch, q2_len, trg = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radShSdtFGNu",
        "colab_type": "code",
        "outputId": "43e50d3b-1e75-4976-dcb9-792ba98bef35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(q1_batch.shape)\n",
        "print(len(q1_len))\n",
        "print(q2_batch.shape)\n",
        "print(len(q2_len))\n",
        "print(trg.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([48, 64])\n",
            "64\n",
            "torch.Size([60, 64])\n",
            "64\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhdWyPkyFb8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, output_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, num_layers=num_layers, bidirectional=True)\n",
        "        self.fc_1 = nn.Linear(hidden_dim * 5, hidden_dim)\n",
        "        self.fc_2 = nn.Linear(hidden_dim, 50)\n",
        "        self.fc_3 = nn.Linear(50, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.ln_1 = nn.LayerNorm(hidden_dim)\n",
        "        self.ln_2 = nn.LayerNorm(50)\n",
        "        self.bn_1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn_2 = nn.BatchNorm1d(50)\n",
        "    \n",
        "    def forward(self, q1, q1_lengths, q2, q2_lengths):\n",
        "        # q1 => [q1_seq_len, batch_size]\n",
        "        # q1_lengths => [batch_size]\n",
        "        # q2 => [q2_seq_len, batch_size]\n",
        "        # q2_lengths => [batch_size]\n",
        "\n",
        "        q1_embed = self.dropout(self.embedding(q1))\n",
        "        q2_embed = self.dropout(self.embedding(q2))\n",
        "        # q1_embed => [q1_seq_len, batch_size, emb_dim]\n",
        "        # q2_embed => [q2_seq_len, batch_size, emb_dim]\n",
        "\n",
        "        q1_packed = nn.utils.rnn.pack_padded_sequence(q1_embed, q1_lengths)\n",
        "\n",
        "        _, q1_hidden = self.rnn(q1_packed)\n",
        "        q1_hidden = q1_hidden.view(self.num_layers, 2, -1, self.hidden_dim)\n",
        "        # q1_hidden => [num_layers, num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        q1_final_layer_hidden = q1_hidden[-1, :, :, :]\n",
        "        # q1_final_layer_hidden => [num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        q1_representation = q1_final_layer_hidden[0] + q1_final_layer_hidden[1]\n",
        "        # q1_representation => [batch_size, hidden_dim]\n",
        "\n",
        "        q1_representation = self.dropout(q1_representation)\n",
        "        # q1_representation => [batch_size, hidden_dim]\n",
        "\n",
        "        _, q2_hidden = self.rnn(q2_embed)\n",
        "        q2_hidden = q2_hidden.view(self.num_layers, 2, -1, self.hidden_dim)\n",
        "        # q2_hidden => [num_layers, num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        q2_final_layer_hidden = q2_hidden[-1, :, :, :]\n",
        "        # q2_final_layer_hidden => [num_dir, batch_size, hidden_dim]\n",
        "\n",
        "        q2_representation = q2_final_layer_hidden[0] + q2_final_layer_hidden[1]\n",
        "        # q2_representation => [batch_size, hidden_dim]\n",
        "\n",
        "        q2_representation = self.dropout(q2_representation)\n",
        "        # q2_representation => [batch_size, hidden_dim]\n",
        "\n",
        "        diff = q1_representation - q2_representation\n",
        "        # diff => [batch_size, hidden_dim]\n",
        "\n",
        "        add = q1_representation + q2_representation\n",
        "        # add => [batch_size, hidden_dim]\n",
        "        \n",
        "        mul = q1_representation * q2_representation\n",
        "        # mul => [batch_size, hidden_dim]\n",
        "\n",
        "        concat = torch.cat((q1_representation, q2_representation), dim=-1)\n",
        "        # concat => [batch_size, hidden_dim * 2]\n",
        "\n",
        "        combined = torch.cat((diff, add, mul, concat), dim=-1)\n",
        "        # combined => [batch_size, hidden_dim * 5]\n",
        "\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, hidden_dim * 5]\n",
        "\n",
        "        out_1 = self.bn_1(self.ln_1(self.dropout(torch.relu(self.fc_1(combined)))))\n",
        "        # out_1 => [batch_size, hidden_dim]\n",
        "\n",
        "        out_2 = self.bn_2(self.ln_2(self.dropout(torch.relu(self.fc_2(out_1)))))\n",
        "        # out_2 => [batch_size, 50]\n",
        "\n",
        "        logits = self.fc_3(out_2)\n",
        "        # logits => [batch_size, 1]\n",
        "\n",
        "        return logits "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64MfVlkiSTXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(processor.vocab.itos)\n",
        "emb_dim = 100\n",
        "hidden_dim = 200\n",
        "dropout = 0.3\n",
        "output_dim = 1\n",
        "num_layers = 2\n",
        "\n",
        "model = RNN(input_dim, emb_dim, hidden_dim, num_layers, output_dim, dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fcIJfHdSpeI",
        "colab_type": "code",
        "outputId": "17988757-a927-4e82-ecca-e3d15a783781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(5000, 100)\n",
              "  (rnn): GRU(100, 200, num_layers=2, bidirectional=True)\n",
              "  (fc_1): Linear(in_features=1000, out_features=200, bias=True)\n",
              "  (fc_2): Linear(in_features=200, out_features=50, bias=True)\n",
              "  (fc_3): Linear(in_features=50, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (ln_1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "  (ln_2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
              "  (bn_1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn_2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IepuasgSqVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFc3mNNTb0y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvf-fGEETD_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(device, model, iterator, criterion, optimizer, clip):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        q1, q1_len, q2, q2_len, labels = batch\n",
        "        q1, q2, labels = q1.to(device), q2.to(device), labels.to(device)\n",
        "        logits = model(q1, q1_len, q2, q2_len).squeeze()\n",
        "        # logits => [batch_size]\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        acc = binary_accuracy(logits, labels)\n",
        "        train_acc += acc.item()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    return train_loss / len(iterator), train_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrSg2XMnUk8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(device, model, iterator, criterion):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    eval_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            q1, q1_len, q2, q2_len, labels = batch\n",
        "            q1, q2, labels = q1.to(device), q2.to(device), labels.to(device)\n",
        "\n",
        "            logits = model(q1, q1_len, q2, q2_len).squeeze()\n",
        "            # logits => [batch_size]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            eval_loss += loss.item()\n",
        "            acc = binary_accuracy(logits, labels)\n",
        "            eval_acc += acc.item()\n",
        "\n",
        "    return eval_loss / len(iterator), eval_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIx-3X3NU2YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxvK8LEYVG0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(device, model, train_loader, criterion, optimizer, CLIP)\n",
        "    val_loss, val_acc = evaluate(device, model, val_loader, criterion)\n",
        "    end_time = time.time()\n",
        "    elapsed_mins, elapsed_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f\"Epoch: {epoch + 1} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f} | Val Loss: {val_loss:.3f} | Val Acc: {val_acc * 100:.2f} | Time: {elapsed_mins}m {elapsed_secs}s\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrzJMF3HX4p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}