{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORba36O7GiAcvl06b6pWlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec121882ddf3408aadcb7393c3c88400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60c12c0da2564e2394362a8cf8965b7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9aa65b1249034651a556693838b41e06",
              "IPY_MODEL_4e06cddc65f5422e94cda395192d7661"
            ]
          }
        },
        "60c12c0da2564e2394362a8cf8965b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9aa65b1249034651a556693838b41e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00524e5d63c943a9ad6be06463de6acc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f91ee10b575b48439ba644739e45065c"
          }
        },
        "4e06cddc65f5422e94cda395192d7661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8cf92e6416d4b7ca3a4000aabeeed1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.91MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f46befdf20b74b5ba492275090dbad38"
          }
        },
        "00524e5d63c943a9ad6be06463de6acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f91ee10b575b48439ba644739e45065c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8cf92e6416d4b7ca3a4000aabeeed1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f46befdf20b74b5ba492275090dbad38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75b2683ccae543eb98490f5a55b9ace2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_553e15bc4413470aab3c2cc9d9a20ae5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4e490129d4c406ea82a5ea8e1128539",
              "IPY_MODEL_ea9c7a47733d47faa9ea8e26f05cc228"
            ]
          }
        },
        "553e15bc4413470aab3c2cc9d9a20ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4e490129d4c406ea82a5ea8e1128539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08a81e343cc440f899cf79fd69cb6ec8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64a29a7d32b34474aef45be97fdcba95"
          }
        },
        "ea9c7a47733d47faa9ea8e26f05cc228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_210b7c29ccfa40ee9404db758825b065",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_509a601adc6a4922bf7020aa735ba171"
          }
        },
        "08a81e343cc440f899cf79fd69cb6ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64a29a7d32b34474aef45be97fdcba95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "210b7c29ccfa40ee9404db758825b065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "509a601adc6a4922bf7020aa735ba171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/architectures/architectures/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCM3SFjKJNGz",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2 Model \n",
        "\n",
        "The GPT-2 utilizes a 12-layer Decoder Only Transformer architecture. \n",
        "\n",
        "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.\n",
        "\n",
        "Go through the following resources:\n",
        "\n",
        "- [Illustrated GPT-2 by Jay Alammar](http://jalammar.github.io/illustrated-gpt2/)\n",
        "\n",
        "- [Annotated GPT-2](https://amaarora.github.io/2020/02/18/annotatedGPT2.html)\n",
        "\n",
        "- [GPT-2 Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjInKceigEeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3dv0UIAlbp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv1D(nn.Module):\n",
        "    def __init__(self, nx, nf):\n",
        "        super().__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = nn.Parameter(w)\n",
        "        self.bias = nn.Parameter(torch.zeros(nf))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x => [batch_size, seq_len, d_model(nx)]\n",
        "\n",
        "        # reshape the output to following size\n",
        "        size_out = x.size()[:-1] + (self.nf, )\n",
        "        # size_out => [batch_size, seq_len, nf]\n",
        "\n",
        "        # x = W.x + b\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(*size_out)\n",
        "        # x => [batch_size, seq_len, nf]\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY0H0WZ5mak9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dropout, d_model=768, dff=768*4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c_fc = Conv1D(d_model, dff)\n",
        "        self.c_proj = Conv1D(dff, d_model)\n",
        "        self.act = F.gelu\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        x = self.act(self.c_fc(x))\n",
        "        # x => [batch_size, seq_len, dff]\n",
        "        \n",
        "        x = self.c_proj(self.dropout(x))\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzFeMRMCnn3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "        self.c_attn = Conv1D(d_model, d_model * 3)\n",
        "        self.scale = scale\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.c_proj = Conv1D(d_model, d_model)\n",
        "    \n",
        "    def split_heads(self, x):\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        # new_shape => [batch_size, seq_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(*new_shape)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        # x => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _attn(self, q, k, v, attn_mask=None):\n",
        "        # q, k, v => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1))\n",
        "        # q   => [batch_size, n_heads, seq_len, head_dim]\n",
        "        # k^t => [batch_size, n_heads, head_dim, seq_len]\n",
        "        # scores => [batch_size, n_heads, seq_len, seq_len]\n",
        "\n",
        "        if self.scale:\n",
        "            scores = scores / math.sqrt(v.size(-1))\n",
        "        nd, ns = scores.size(-2), scores.size(-1)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            scores = scores + attn_mask\n",
        "        scores = self.softmax(scores)\n",
        "        scores = self.dropout(scores)\n",
        "        # scores => [batch_size, n_heads, seq_len, seq_len]\n",
        "        # v      => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        outputs = torch.matmul(scores, v)\n",
        "        # outputs => [batch_size, n_heads, seq_len, head_dim]\n",
        "        \n",
        "        return outputs\n",
        "    \n",
        "    def merge_heads(self, x):\n",
        "        # x => [batch_size, n_heads, seq_len, head_dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        # x => [batch_size, seq_len, n_heads, head_dim]\n",
        "\n",
        "        new_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        # new_shape => [batch_size, seq_len, d_model]\n",
        "        \n",
        "        return x.view(*new_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "        \n",
        "        x = self.c_attn(x)\n",
        "        # x => [batch_size, seq_len, d_model * 3]\n",
        "\n",
        "        q, k, v = x.split(self.d_model, dim=-1)\n",
        "        # q, k, v => [batch_size, seq_len, d_model]\n",
        "\n",
        "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
        "        # q, k, v => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        out = self._attn(q, k, v)\n",
        "        # out => [batch_size, n_heads, seq_len, head_dim]\n",
        "\n",
        "        out = self.merge_heads(out)\n",
        "        # out => [batch_size, seq_len, d_model]\n",
        "\n",
        "        out = self.c_proj(out)\n",
        "        # out => [batch_size, seq_len, d_model]\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo09Q9oArkYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = Attention(d_model, n_head, d_head=64, n_ctx=1024, bias=True, scale=False)\n",
        "        self.feedforward = FeedForward(dropout, d_model, d_model*4)\n",
        "        self.ln_1 = nn.LayerNorm(d_model)\n",
        "        self.ln_2 = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x => [batch_size, seq_len, d_model]\n",
        "\n",
        "        # self-attention and layer normalization\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "\n",
        "        # feed forward network and layer normalization\n",
        "        x = x + self.feedforward(self.ln_2(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eilzd49_r7vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_clones(module, n):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])\n",
        "\n",
        "\n",
        "class GPT2(nn.Module):\n",
        "    def __init__(self, n_layers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_layers = n_layers\n",
        "        block = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n",
        "        self.h = _get_clones(block, n_layers)\n",
        "        self.wte = nn.Embedding(vcb_sz, d_model)\n",
        "        self.wpe = nn.Embedding(n_ctx, d_model)\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.ln_f = nn.LayerNorm(d_model)\n",
        "        self.out = nn.Linear(d_model, vcb_sz, bias=False)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.init_weights()\n",
        "    \n",
        "    def init_weights(self):\n",
        "        self.out.weight = self.wte.weight\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "    \n",
        "    def forward(self, src, labels=None, pos_ids=None):\n",
        "        # src => [batch_size, seq_len]\n",
        "\n",
        "        # create positional vectors if not present\n",
        "        if pos_ids is None:\n",
        "            pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
        "            # pos_ids => [1, seq_len]\n",
        "        \n",
        "        inp = self.drop((self.wte(src) + self.wpe(pos_ids)))\n",
        "        # inp => [batch_size, seq_len, d_model]\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            inp = self.h[i](inp)\n",
        "        \n",
        "        # final layer normalization\n",
        "        inp = self.ln_f(inp)\n",
        "\n",
        "        # prediction layer\n",
        "        logits = self.out(inp)\n",
        "        # logits => [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        outputs = (logits, ) + (inp, )\n",
        "\n",
        "        if labels is not None:\n",
        "            # ignore the last token (<eos>)\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "\n",
        "            # ignore the starting label (<sos>)\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "            outputs = (loss, ) + outputs\n",
        "            # outputs => (loss, logits, inp_representation)\n",
        "\n",
        "            return outputs\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8e2QjhX-5yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0eff6052-4521-4af9-b358-e19cc93dba3c"
      },
      "source": [
        "# load pretrained_weights from hugging face\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 17:04:40--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.40.190\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.40.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548118077 (523M) [application/octet-stream]\n",
            "Saving to: ‘gpt2-pytorch_model.bin.1’\n",
            "\n",
            "gpt2-pytorch_model. 100%[===================>] 522.73M  75.3MB/s    in 7.5s    \n",
            "\n",
            "2020-06-08 17:04:48 (69.8 MB/s) - ‘gpt2-pytorch_model.bin.1’ saved [548118077/548118077]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiGrzpSqsz_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "953a9f00-e814-4540-eb1b-d64d802235de"
      },
      "source": [
        "model = GPT2()\n",
        "\n",
        "model_dict = model.state_dict()\n",
        "state_dict = torch.load('./gpt2-pytorch_model.bin')\n",
        "\n",
        "old_keys = []\n",
        "new_keys = []\n",
        "\n",
        "for key in state_dict.keys():\n",
        "    # The hugging face state dict references the feedforward network as mlp, \n",
        "    # need to replace to `feedforward` be able to reuse these weights\n",
        "    if \"mlp\" in key:\n",
        "        new_key = key.replace(\"mlp\", \"feedforward\")\n",
        "        new_keys.append(new_key)\n",
        "        old_keys.append(key)\n",
        "\n",
        "for old_key, new_key in zip(old_keys, new_keys):\n",
        "    state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
        "\n",
        "model_dict.update(pretrained_dict)\n",
        "model.load_state_dict(model_dict)\n",
        "model.eval()\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2(\n",
              "  (h): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (c_proj): Conv1D()\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (wte): Embedding(50257, 768)\n",
              "  (wpe): Embedding(1024, 768)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (out): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  (loss_fn): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LV9BKKtCptc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "00f6ca0c-cf67-4fd0-e810-d2a2887240a4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=1c7977ac6d8bb9be8539ecce03fe2208ed2100ed06722188116cec74a21c066e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.92 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9tiGre7At0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "ec121882ddf3408aadcb7393c3c88400",
            "60c12c0da2564e2394362a8cf8965b7f",
            "9aa65b1249034651a556693838b41e06",
            "4e06cddc65f5422e94cda395192d7661",
            "00524e5d63c943a9ad6be06463de6acc",
            "f91ee10b575b48439ba644739e45065c",
            "c8cf92e6416d4b7ca3a4000aabeeed1f",
            "f46befdf20b74b5ba492275090dbad38",
            "75b2683ccae543eb98490f5a55b9ace2",
            "553e15bc4413470aab3c2cc9d9a20ae5",
            "e4e490129d4c406ea82a5ea8e1128539",
            "ea9c7a47733d47faa9ea8e26f05cc228",
            "08a81e343cc440f899cf79fd69cb6ec8",
            "64a29a7d32b34474aef45be97fdcba95",
            "210b7c29ccfa40ee9404db758825b065",
            "509a601adc6a4922bf7020aa735ba171"
          ]
        },
        "outputId": "a8bd5cd6-6087-4939-e935-6847e8c8843e"
      },
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec121882ddf3408aadcb7393c3c88400",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75b2683ccae543eb98490f5a55b9ace2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2mezKyiAwmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(context, ntok=20):\n",
        "    for _ in range(ntok):\n",
        "        out = model(context)\n",
        "        logits = out[:, -1, :]\n",
        "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = np.NINF\n",
        "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
        "        context = torch.cat([context, next_tok.unsqueeze(-1)], dim=-1)\n",
        "    return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7t0qIrJBL9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "639b1586-b1d4-4b4d-b643-6c751a5a79bd"
      },
      "source": [
        "context = torch.tensor([tokenizer.encode(\"The world is \")])\n",
        "out = generate(context, ntok=15)\n",
        "tokenizer.decode(out[0])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The world is full of surprises.\\n\\n\\n\\n\\n\\n\\n\\n\\n\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9w5h0yOC0Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa3527fc-088f-4dc0-a67b-da2a63dc659d"
      },
      "source": [
        "context = torch.tensor([tokenizer.encode(\"The world is \")])\n",
        "out = generate(context, ntok=15)\n",
        "tokenizer.decode(out[0])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The world is so rich in its own country, it is poor, it is. in'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzw61n4UH-tS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68adeabc-295e-4bce-cda8-205fe005dd20"
      },
      "source": [
        "context = torch.tensor([tokenizer.encode(\"The planet earth is \")])\n",
        "out = generate(context, ntok=15)\n",
        "tokenizer.decode(out[0])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The planet earth is a beautiful place where you live, you have your heart. is my is'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    }
  ]
}