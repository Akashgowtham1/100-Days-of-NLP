{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1R4rlXVDmdP7mkAkui1C6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/master/embeddings/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0AavVJHEQCW",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec\n",
        "\n",
        "Word2Vec is one of the most popular pretrained word embeddings developed by Google. Word2Vec is trained on the Google News dataset (about 100 billion words).\n",
        "\n",
        "The architecture of Word2Vec is really simple. Itâ€™s a feed-forward neural network with just one hidden layer. Hence, it is sometimes referred to as a Shallow Neural Network architecture.\n",
        "\n",
        "Depending on the way the embeddings are learned, Word2Vec is classified into two approaches:\n",
        "\n",
        "- Continuous Bag-of-Words (CBOW)\n",
        "- Skip-gram model\n",
        "\n",
        "Continuous Bag-of-Words (CBOW) model learns the focus word given the neighboring words whereas the Skip-gram model learns the neighboring words given the focus word. \n",
        "\n",
        "There are a lot of online material available to explain the concept about Word Embeddings. I can't explain any better than that. So my focus here will be on, how to use pre-trained word embeddings. I will provide relevant resources to look into more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vvaprKcEz6M",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [Word Embeddings - Sebastian Ruder](https://ruder.io/word-embeddings-1/)\n",
        "- [Skip Gram Model - Chris McCormick](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
        "- [Learning Word Embeddings Andrew NG](https://www.youtube.com/watch?v=xtPXjvwCt64)\n",
        "- [Word2Vec Andrew NG](https://www.youtube.com/watch?v=jak0sKPoKu8)\n",
        "- [Stanford NLP Lecture 1](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=1)\n",
        "- [Word2Vec Paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
        "- [Google Word2Vec](https://code.google.com/archive/p/word2vec/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12CunrKHFBRq",
        "colab_type": "text"
      },
      "source": [
        "There are many libraries available which support Word2Vec based models natively. Pretrained models are also available. Covering each and everything will be overwhelming. So I will provide the usage with the prominent library:\n",
        "- [Gensim](https://radimrehurek.com/gensim/models/word2vec.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TkuWZw_FuEi",
        "colab_type": "text"
      },
      "source": [
        "# Gensim\n",
        "\n",
        "Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.\n",
        "\n",
        "Gensim includes streamed parallelized implementations of fastText,word2vec and doc2vec algorithms, as well as latent semantic analysis (LSA, LSI, SVD), non-negative matrix factorization (NMF), latent Dirichlet allocation (LDA), tf-idf and random projections. [source](https://en.wikipedia.org/wiki/Gensim)\n",
        "\n",
        "References:\n",
        "\n",
        "- [How to download Pretrained word embeddings in gensim](https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html)\n",
        "\n",
        "- [Using Fasttext in gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L8nSfazpjG2",
        "colab_type": "text"
      },
      "source": [
        "### Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxAQpviF_LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpr72_8yGBh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1WtN1yHiOLf",
        "colab_type": "code",
        "outputId": "0a1d4616-763d-46af-bbb6-d0f0f11ba80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  wiki-news-300d-1M.vec  wiki-news-300d-1M.vec.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_ST59K-mKPq",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Pretrained Word2Vec model\n",
        "\n",
        "I am using the model downloaded from fasttext. You can download any of the word vectors provided by fasttext [here](https://fasttext.cc/docs/en/english-vectors.html).\n",
        "\n",
        "Fasttext provides pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives. We also distribute three new word analogy datasets, for French, Hindi and Polish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqat9s2O4Jbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGHomaz64ODt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Ii9VaX4O2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J46tGgrGiKjD",
        "colab_type": "code",
        "outputId": "caaeb449-cd0c-40c4-a93e-f831018eab37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# loading the model\n",
        "model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9RoZKUpiaid",
        "colab_type": "code",
        "outputId": "9fbcba1d-816f-45fa-cde7-cbb48b05d924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model['hello'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvT9r0bCjuTK",
        "colab_type": "code",
        "outputId": "5437ef18-59c7-4b14-ac29-552d56dd4dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model['hello'][:50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.192 ,  0.1544,  0.0467,  0.0592,  0.1369, -0.0772, -0.0384,\n",
              "        0.0537,  0.1435, -0.1353, -0.053 , -0.0668,  0.0185,  0.0873,\n",
              "        0.0903,  0.1663,  0.0035, -0.2102,  0.201 , -0.0249, -0.0279,\n",
              "       -0.3241, -0.0066, -0.0264, -0.1628, -0.1094, -0.0882,  0.0097,\n",
              "        0.1228,  0.0059, -0.051 ,  0.0649,  0.1577,  0.0174,  0.0991,\n",
              "        0.1328, -0.0586,  0.1814, -0.0098,  0.1877,  0.0518, -0.0697,\n",
              "       -0.0629, -0.1981, -0.1373, -0.0811, -0.0631, -0.0639,  0.1244,\n",
              "       -0.0247], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zndwYcDTkH8n",
        "colab_type": "text"
      },
      "source": [
        "### Word Similarity\n",
        "\n",
        "Here, we will see how similar are two words to each other "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHbyP_7Qjwdn",
        "colab_type": "code",
        "outputId": "ea5f0978-4adf-4afe-c0d5-eb842c944459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(f'Similarity between night and nights: {model.similarity(\"night\", \"nights\")}')\n",
        "print(f'Similarity between reb and blue: {model.similarity(\"red\", \"blue\")}')\n",
        "print(f'Similarity between hello and heyy: {model.similarity(\"hello\", \"heyy\")}')\n",
        "print(f'Similarity between king and queen: {model.similarity(\"king\", \"queen\")}')\n",
        "print(f'Similarity between london and moscow: {model.similarity(\"london\", \"moscow\")}')\n",
        "print(f'Similarity between car and bike: {model.similarity(\"car\", \"bike\")}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between night and nights: 0.7854782938957214\n",
            "Similarity between reb and blue: 0.8833013772964478\n",
            "Similarity between hello and heyy: 0.56700599193573\n",
            "Similarity between king and queen: 0.7638539671897888\n",
            "Similarity between london and moscow: 0.5399850606918335\n",
            "Similarity between car and bike: 0.6203061938285828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBtmv9w7leny",
        "colab_type": "text"
      },
      "source": [
        "### Most Similar Words\n",
        "\n",
        "Here, we will ask our model to find the words which are most similar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUXUFvfClhZo",
        "colab_type": "code",
        "outputId": "f0fa7148-1ff1-41b0-cc9b-5e2f1d90fcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "similar = model.most_similar(\"january\")\n",
        "for i in similar:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('december', 0.8822824954986572)\n",
            "('november', 0.8583322763442993)\n",
            "('october', 0.857945442199707)\n",
            "('july', 0.8488935232162476)\n",
            "('february', 0.8297372460365295)\n",
            "('june', 0.8287782669067383)\n",
            "('september', 0.817267656326294)\n",
            "('feb', 0.7887735366821289)\n",
            "('april', 0.7763540744781494)\n",
            "('jan', 0.7581983804702759)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7uhLs35l5c8",
        "colab_type": "text"
      },
      "source": [
        "### Odd-One-Out\n",
        "\n",
        "Here, we ask our model to give us the word that does not belong to the list!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIvzN9_Pl8I_",
        "colab_type": "code",
        "outputId": "c3f2ee73-20af-42e4-9e30-a526752d2e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cereal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWYfNmVPqU1D",
        "colab_type": "text"
      },
      "source": [
        "### Analogy difference\n",
        "\n",
        "Which word is to women as king is to queen?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tgeGJLzp1p6",
        "colab_type": "code",
        "outputId": "43c84971-2b6f-49f1-8fcd-22ab177a1172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"women\", \"king\"], negative=[\"queen\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('men', 0.7986569404602051),\n",
              " ('people', 0.6009145975112915),\n",
              " ('woman', 0.5940523147583008),\n",
              " ('Men', 0.5867083668708801),\n",
              " ('minorities', 0.5796009302139282),\n",
              " ('soldiers', 0.5783532857894897),\n",
              " ('man', 0.5754462480545044),\n",
              " ('Women', 0.5716798305511475),\n",
              " ('husbands', 0.5706273913383484),\n",
              " ('persons', 0.5616658926010132)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKFkFB-qqfbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrA2eUl_qsNz",
        "colab_type": "code",
        "outputId": "ed66efa6-5151-4470-b641-c3815531ea67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "analogy('japan', 'japanese', 'china')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chinese'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIA6Rpm1ukjl",
        "colab_type": "text"
      },
      "source": [
        "# Training Word2Vec Models\n",
        "\n",
        "You can train your own custom Word2Vec model for your data using Gensim/Fasttext. Please refer to the following links for training Word2Vec:\n",
        "\n",
        "- [Training using Gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py)\n",
        "\n",
        "- [Training Using Fasttext](https://fasttext.cc/docs/en/unsupervised-tutorial.html)\n",
        "\n",
        "- [Blog using Gensim for training](https://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XsK3oRMzaRs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NelGqFgGy3oM",
        "colab_type": "text"
      },
      "source": [
        "# Visualizations (Will be added soon !!)"
      ]
    }
  ]
}